<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo,Typora,">










<meta name="description" content="ä½¿ç”¨BERTåŠå¹´å¤šäº†ï¼Œä¸€ç›´ç”¨çš„æ˜¯Huggingfaceçš„pytorchä»£ç ï¼Œæœ€è¿‘æ¯•ä¸šæŠ½ç©ºè·Ÿç€Googleå®˜æ–¹Tensorflowä»£ç æ•²äº†ä¸€éï¼Œä¸ºäº†èƒ½å¤Ÿåšåˆ°æ·±å…¥ç†è§£å¹¶å¤ç°ï¼Œåœ¨è¿™é‡Œè¯¦ç»†åˆ†æBERTçš„å®˜æ–¹ä»£ç ã€‚äº‰å–åšåˆ°ï¼Œèƒ½å¤Ÿç†è§£åå¤ç°å‡ºæ¥ã€‚ä¸Šè½¦ğŸš—ğŸš—ğŸš—  tokenization.pyè¿™æ˜¯å¯¹BERTè¾“å…¥è¿›è¡Œåˆ†è¯çš„ä»£ç éƒ¨åˆ†ï¼Œæˆ‘ä»¬å…ˆç»˜åˆ¶å‡º tokenization.py æ–‡ä»¶çš„ç»“æ„ï¼Œç„¶åé€ä¸ªå‡½æ•°é€è¡Œåˆ†æ">
<meta name="keywords" content="Hexo,Typora">
<meta property="og:type" content="article">
<meta property="og:title" content="bert-squad-tf">
<meta property="og:url" content="https://1024er.github.io/bert-squad-tf/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="ä½¿ç”¨BERTåŠå¹´å¤šäº†ï¼Œä¸€ç›´ç”¨çš„æ˜¯Huggingfaceçš„pytorchä»£ç ï¼Œæœ€è¿‘æ¯•ä¸šæŠ½ç©ºè·Ÿç€Googleå®˜æ–¹Tensorflowä»£ç æ•²äº†ä¸€éï¼Œä¸ºäº†èƒ½å¤Ÿåšåˆ°æ·±å…¥ç†è§£å¹¶å¤ç°ï¼Œåœ¨è¿™é‡Œè¯¦ç»†åˆ†æBERTçš„å®˜æ–¹ä»£ç ã€‚äº‰å–åšåˆ°ï¼Œèƒ½å¤Ÿç†è§£åå¤ç°å‡ºæ¥ã€‚ä¸Šè½¦ğŸš—ğŸš—ğŸš—  tokenization.pyè¿™æ˜¯å¯¹BERTè¾“å…¥è¿›è¡Œåˆ†è¯çš„ä»£ç éƒ¨åˆ†ï¼Œæˆ‘ä»¬å…ˆç»˜åˆ¶å‡º tokenization.py æ–‡ä»¶çš„ç»“æ„ï¼Œç„¶åé€ä¸ªå‡½æ•°é€è¡Œåˆ†æ">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703180643549.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703180540319.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703013613264.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190702234605092.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190702200034350.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703184633330.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190704121235449.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703085937162.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190702102852057.png">
<meta property="og:updated_time" content="2019-07-04T19:08:55.543Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="bert-squad-tf">
<meta name="twitter:description" content="ä½¿ç”¨BERTåŠå¹´å¤šäº†ï¼Œä¸€ç›´ç”¨çš„æ˜¯Huggingfaceçš„pytorchä»£ç ï¼Œæœ€è¿‘æ¯•ä¸šæŠ½ç©ºè·Ÿç€Googleå®˜æ–¹Tensorflowä»£ç æ•²äº†ä¸€éï¼Œä¸ºäº†èƒ½å¤Ÿåšåˆ°æ·±å…¥ç†è§£å¹¶å¤ç°ï¼Œåœ¨è¿™é‡Œè¯¦ç»†åˆ†æBERTçš„å®˜æ–¹ä»£ç ã€‚äº‰å–åšåˆ°ï¼Œèƒ½å¤Ÿç†è§£åå¤ç°å‡ºæ¥ã€‚ä¸Šè½¦ğŸš—ğŸš—ğŸš—  tokenization.pyè¿™æ˜¯å¯¹BERTè¾“å…¥è¿›è¡Œåˆ†è¯çš„ä»£ç éƒ¨åˆ†ï¼Œæˆ‘ä»¬å…ˆç»˜åˆ¶å‡º tokenization.py æ–‡ä»¶çš„ç»“æ„ï¼Œç„¶åé€ä¸ªå‡½æ•°é€è¡Œåˆ†æ">
<meta name="twitter:image" content="https://1024er.github.io/bert-squad-tf/image-20190703180643549.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://1024er.github.io/bert-squad-tf/">





  <title>bert-squad-tf | Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://1024er.github.io/bert-squad-tf/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">bert-squad-tf</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-04T00:00:00+08:00">
                2019-07-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog-System/" itemprop="url" rel="index">
                    <span itemprop="name">Blog System</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog-System/Hexo/" itemprop="url" rel="index">
                    <span itemprop="name">Hexo</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>ä½¿ç”¨BERTåŠå¹´å¤šäº†ï¼Œä¸€ç›´ç”¨çš„æ˜¯Huggingfaceçš„pytorchä»£ç ï¼Œæœ€è¿‘æ¯•ä¸šæŠ½ç©ºè·Ÿç€Googleå®˜æ–¹Tensorflowä»£ç æ•²äº†ä¸€éï¼Œä¸ºäº†èƒ½å¤Ÿåšåˆ°æ·±å…¥ç†è§£å¹¶å¤ç°ï¼Œåœ¨è¿™é‡Œè¯¦ç»†åˆ†æBERTçš„å®˜æ–¹ä»£ç ã€‚äº‰å–åšåˆ°ï¼Œèƒ½å¤Ÿç†è§£åå¤ç°å‡ºæ¥ã€‚ä¸Šè½¦ğŸš—ğŸš—ğŸš—</p>
<hr>
<h6 id="tokenization-py"><a href="#tokenization-py" class="headerlink" title="tokenization.py"></a>tokenization.py</h6><p>è¿™æ˜¯å¯¹BERTè¾“å…¥è¿›è¡Œåˆ†è¯çš„ä»£ç éƒ¨åˆ†ï¼Œæˆ‘ä»¬å…ˆç»˜åˆ¶å‡º tokenization.py æ–‡ä»¶çš„ç»“æ„ï¼Œç„¶åé€ä¸ªå‡½æ•°é€è¡Œåˆ†æã€‚</p>
<p><img src="/bert-squad-tf/image-20190703180643549.png" alt="image-20190703180643549"></p>
<p>Bert çš„åˆ†è¯ä½¿ç”¨ FullTokenizerï¼ŒåŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼š</p>
<ul>
<li>ä½¿ç”¨ BasicTokenizer æ ¹æ®ç¬¦å·åˆ†è¯ï¼Œå­—æ¯å¤§å°å†™å¤„ç†ï¼Œå¾—åˆ° tokens<ul>
<li>ç»Ÿä¸€ unicode ç¼–ç ï¼Œå¹¶å»é™¤æ— æ•ˆå­—ç¬¦ã€æ§åˆ¶å­—ç¬¦ï¼Œç»Ÿä¸€ç©ºç™½å­—ç¬¦</li>
<li>ä¸­æ–‡åˆ†è¯æ”¯æŒ</li>
<li>å¤„ç†å¤§å°å†™ï¼Œå»é™¤éŸ³èŠ‚ç¬¦</li>
<li>æ ¹æ®ç¬¦å·åˆ†è¯</li>
<li>ç©ºæ ¼åˆ†è¯</li>
</ul>
</li>
<li>ä½¿ç”¨ WordpieceTokenizer åˆ†è¯ï¼Œå¾—åˆ° sub_tokens<ul>
<li>ä½¿ç”¨ wordpiece æ–¹å¼åˆ†è¯ï¼Œä½¿ç”¨æœ€é•¿åŒ¹é…ä¼˜å…ˆçš„æ–¹å¼ï¼Œä½¿ç”¨ â€œ##â€å‰ç¼€</li>
</ul>
</li>
</ul>
<p>è¡¥å……å‚è€ƒï¼š*</p>
<p>â€‹    <em>unicodedata.category() çš„è¿”å›å€¼å¯ä»¥å‚è€ƒ <a href="https://www.compart.com/en/unicode/category" target="_blank" rel="noopener">https://www.compart.com/en/unicode/category</a></em></p>
<p>â€‹    <em>ASCIIç è¡¨å¯ä»¥å‚è€ƒ <a href="https://zh.wikipedia.org/wiki/Unicodeå­—ç¬¦åˆ—è¡¨#åŸºæœ¬æ‹‰ä¸å­—æ¯" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Unicodeå­—ç¬¦åˆ—è¡¨#åŸºæœ¬æ‹‰ä¸å­—æ¯</a></em></p>
<p><strong>caseæ£€æŸ¥</strong></p>
<ul>
<li><p>validate_case_matches_checkpoint</p>
<p>è¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯æ£€æŸ¥ä¼ å…¥å‚æ•° do_lower_caseï¼ˆæ˜¯å¦å¤§å°å†™æ•æ„Ÿï¼‰ å’Œ è¦åŠ è½½çš„æ¨¡å‹ æ˜¯æ˜¯å¦åŒ¹é…ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate_case_matches_checkpoint</span><span class="params">(do_lower_case, init_checkpoint)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> init_checkpoint: <span class="comment"># è¾“å…¥åˆæ³•æ€§åˆ¤æ–­</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  </span><br><span class="line">	<span class="comment"># ä½¿ç”¨æ‡’æƒ°æ¨¡å¼æ¥åŒ¹é…æ¨¡å‹çš„åç§°</span></span><br><span class="line">  <span class="comment"># æ¯”å¦‚ï¼šinit_checkpoint = /root/bert/uncased_L-12_H-768_A-12/bert_model.ckpt</span></span><br><span class="line">  <span class="comment"># åŒ¹é…å model_name = uncased_L-12_H-768_A-12</span></span><br><span class="line">  m = re.match(<span class="string">"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt"</span>, init_checkpoint) </span><br><span class="line">  <span class="keyword">if</span> m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  model_name = m.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Google æä¾›çš„é¢„è®­ç»ƒå¥½çš„æ¨¡å‹åç§°é›†åˆ</span></span><br><span class="line">  lower_models = [</span><br><span class="line">      <span class="string">"uncased_L-24_H-1024_A-16"</span>, <span class="string">"uncased_L-12_H-768_A-12"</span>,</span><br><span class="line">      <span class="string">"multilingual_L-12_H-768_A-12"</span>, <span class="string">"chinese_L-12_H-768_A-12"</span></span><br><span class="line">  ]</span><br><span class="line">  cased_models = [</span><br><span class="line">      <span class="string">"cased_L-12_H-768_A-12"</span>, <span class="string">"cased_L-24_H-1024_A-16"</span>,</span><br><span class="line">      <span class="string">"multi_cased_L-12_H-768_A-12"</span></span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">  is_bad_config = <span class="literal">False</span></span><br><span class="line">  <span class="comment"># è¦åŠ è½½çš„æ¨¡å‹å¤§å°å†™ä¸æ•æ„Ÿï¼Œè€Œä¼ å…¥çš„å‚æ•°æ˜¯å¤§å°å†™æ•æ„Ÿ</span></span><br><span class="line">  <span class="keyword">if</span> model_name <span class="keyword">in</span> lower_models <span class="keyword">and</span> <span class="keyword">not</span> do_lower_case:</span><br><span class="line">    is_bad_config = <span class="literal">True</span></span><br><span class="line">    ...</span><br><span class="line">	<span class="comment"># è¦åŠ è½½çš„æ¨¡å‹å¤§å°å†™æ•æ„Ÿï¼Œè€Œä¼ å…¥çš„å‚æ•°æ˜¯å¤§å°å†™ä¸æ•æ„Ÿ</span></span><br><span class="line">  <span class="keyword">if</span> model_name <span class="keyword">in</span> cased_models <span class="keyword">and</span> do_lower_case:</span><br><span class="line">    is_bad_config = <span class="literal">True</span></span><br><span class="line">    ...</span><br><span class="line">  <span class="comment"># ä¸ä¸€è‡´å°±æŠ›å¼‚å¸¸</span></span><br><span class="line">  <span class="keyword">if</span> is_bad_config:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(...)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>ç¼–ç è½¬æ¢</strong></p>
<ul>
<li><p>convert_to_unicode</p>
<p>å°†è¾“å…¥ text è½¬æˆç»Ÿä¸€çš„ unicode ç¼–ç ã€‚è¿™é‡Œéœ€è¦åŒºåˆ†ï¼š</p>
<ul>
<li><p>python3 æœ‰ä¸¤ç§è¡¨ç¤ºå­—ç¬¦åºåˆ—çš„ç±»å‹ï¼šbytes å’Œ strã€‚å‰è€…çš„å®ä¾‹åŒ…å«åŸå§‹çš„8ä½å€¼ï¼›åè€…çš„å®ä¾‹åŒ…å«Unicodeå­—ç¬¦ã€‚</p>
</li>
<li><p>python2 ä¸­ä¹Ÿæœ‰ä¸¤ç§è¡¨ç¤ºå­—ç¬¦åºåˆ—çš„ç±»å‹ï¼Œåˆ†åˆ«å«åš str å’Œ unicodeã€‚ä¸ python3 ä¸åŒçš„æ˜¯ï¼Œstr çš„å®ä¾‹åŒ…å«åŸå§‹çš„8ä½å€¼ï¼Œè€Œ unicode çš„å®ä¾‹æ‰åŒ…å« Unicode å­—ç¬¦ã€‚</p>
</li>
<li><p>python ä¸­ï¼Œä½¿ç”¨ unicode ç±»å‹ä½œä¸ºç¼–ç çš„åŸºç¡€ç±»å‹ï¼š</p>
<p>â€‹     decode               encode</p>
<p>str â€”â€”â€”â€”-&gt; unicode â€”â€”â€”â€”-&gt;str</p>
<ul>
<li>Unicode æ˜¯ã€Œå­—ç¬¦é›†ã€UTF-8 æ˜¯ã€Œç¼–ç è§„åˆ™ã€</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_to_unicode</span><span class="params">(text)</span>:</span></span><br><span class="line">  <span class="string">"""Converts `text` to Unicode (if it's not already), assuming utf-8 input."""</span></span><br><span class="line">  <span class="keyword">if</span> six.PY3:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, bytes):</span><br><span class="line">      <span class="keyword">return</span> text.decode(<span class="string">"utf-8"</span>, <span class="string">"ignore"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">elif</span> six.PY2:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text.decode(<span class="string">"utf-8"</span>, <span class="string">"ignore"</span>)</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, unicode):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">"Not running on Python2 or Python 3?"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>printable_text</p>
<p>å°† text è½¬æ¢æˆæ›´é€‚åˆæ‰“å°çš„ str æ ¼å¼ï¼Œä¾› print / tf.logging è¿™æ ·çš„å‡½æ•°ä½¿ç”¨ã€‚è¿™äº›å‡½æ•°çš„æŒ‡å®šè¾“å…¥æ ¼å¼éƒ½æ˜¯ str æ ¼å¼ï¼Œæ ¼å¼ä¹‹é—´çš„å·®å¼‚è§convert_to_unicode ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printable_text</span><span class="params">(text)</span>:</span> </span><br><span class="line">  <span class="string">"""Returns text encoded in a way suitable for print or `tf.logging`."""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># These functions want `str` for both Python2 and Python3, but in one case</span></span><br><span class="line">  <span class="comment"># it's a Unicode string and in the other it's a byte string.</span></span><br><span class="line">  <span class="keyword">if</span> six.PY3:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, bytes):</span><br><span class="line">      <span class="keyword">return</span> text.decode(<span class="string">"utf-8"</span>, <span class="string">"ignore"</span>) <span class="comment"># **de**code</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">elif</span> six.PY2:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, unicode):</span><br><span class="line">      <span class="keyword">return</span> text.encode(<span class="string">"utf-8"</span>) <span class="comment"># **en**code</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">"Not running on Python2 or Python 3?"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>è¯å…¸æ„å»ºå’Œè½¬æ¢</strong></p>
<ul>
<li><p>load_vocab</p>
<p>åŠ è½½è¯å…¸æ–‡ä»¶ï¼Œå­˜å…¥åˆ° OrderedDict {token: index}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_vocab</span><span class="params">(vocab_file)</span>:</span></span><br><span class="line">  <span class="string">"""Loads a vocabulary file into a dictionary."""</span></span><br><span class="line">  vocab = collections.OrderedDict()</span><br><span class="line">  index = <span class="number">0</span></span><br><span class="line">  <span class="keyword">with</span> tf.gfile.GFile(vocab_file, <span class="string">"r"</span>) <span class="keyword">as</span> reader:</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">      token = convert_to_unicode(reader.readline())</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> token: <span class="comment"># å½“ token == '' æ—¶å€™</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      token = token.strip()</span><br><span class="line">      vocab[token] = index</span><br><span class="line">      index += <span class="number">1</span></span><br><span class="line">  <span class="keyword">return</span> vocab <span class="comment"># uncased_L-12_H-768_A-12æ¨¡å‹çš„ len(vocab)=30522</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>convert_by_vocab / convert_tokens_to_ids / convert_ids_to_tokens</p>
<p>æ ¹æ®æ­¤è¯è¡¨ï¼Œå®ç° token å’Œ id ä¹‹é—´çš„äº’è½¬</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_by_vocab</span><span class="params">(vocab, items)</span>:</span></span><br><span class="line">  output = []</span><br><span class="line">  <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">    output.append(vocab[item])</span><br><span class="line">  <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_tokens_to_ids</span><span class="params">(vocab, tokens)</span>:</span> <span class="comment"># vocab</span></span><br><span class="line">  <span class="keyword">return</span> convert_by_vocab(vocab, tokens)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_ids_to_tokens</span><span class="params">(inv_vocab, ids)</span>:</span> <span class="comment"># inv_vocab!</span></span><br><span class="line">  <span class="keyword">return</span> convert_by_vocab(inv_vocab, ids)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>å­—ç¬¦å¤„ç†</strong></p>
<ul>
<li><p>_is_whitespace / _is_control / _is_punctuation<br>æ˜¯å¦æ˜¯ ç©ºç™½ç¬¦ã€æ§åˆ¶ç¬¦ã€æ ‡ç‚¹ç¬¦</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_is_whitespace</span><span class="params">(char)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> char == <span class="string">" "</span> <span class="keyword">or</span> char == <span class="string">"\t"</span> <span class="keyword">or</span> char == <span class="string">"\n"</span> <span class="keyword">or</span> char == <span class="string">"\r"</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  cat = unicodedata.category(char)</span><br><span class="line">  <span class="keyword">if</span> cat == <span class="string">"Zs"</span>: <span class="comment"># "Zs" è¡¨ç¤º Space Separator</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_is_control</span><span class="params">(char)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> char == <span class="string">"\t"</span> <span class="keyword">or</span> char == <span class="string">"\n"</span> <span class="keyword">or</span> char == <span class="string">"\r"</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">  cat = unicodedata.category(char)</span><br><span class="line">  <span class="keyword">if</span> cat <span class="keyword">in</span> (<span class="string">"Cc"</span>, <span class="string">"Cf"</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_is_punctuation</span><span class="params">(char)</span>:</span></span><br><span class="line">  cp = ord(char)</span><br><span class="line">  <span class="comment"># æ‰€æœ‰é å­—æ¯/æ•°å­— çš„ASCIIå­—ç¬¦ï¼Œ**æ³¨æ„ï¼šæ²¡æœ‰åŒ…æ‹¬ç©ºæ ¼ç¬¦å·**</span></span><br><span class="line">  <span class="keyword">if</span> ((cp &gt;= <span class="number">33</span> <span class="keyword">and</span> cp &lt;= <span class="number">47</span>) <span class="keyword">or</span> (cp &gt;= <span class="number">58</span> <span class="keyword">and</span> cp &lt;= <span class="number">64</span>) <span class="keyword">or</span></span><br><span class="line">      (cp &gt;= <span class="number">91</span> <span class="keyword">and</span> cp &lt;= <span class="number">96</span>) <span class="keyword">or</span> (cp &gt;= <span class="number">123</span> <span class="keyword">and</span> cp &lt;= <span class="number">126</span>)):</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="comment"># æ‰€æœ‰ unicode ä¸­åˆ†ç±»ä¸º punctuation çš„å­—ç¬¦</span></span><br><span class="line">  cat = unicodedata.category(char)</span><br><span class="line">  <span class="keyword">if</span> cat.startswith(<span class="string">"P"</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>åˆ†è¯</strong></p>
<ul>
<li><p>whitespace_tokenize</p>
<p>æ¸…ç†textå‰åçš„ç©ºæ ¼ç±»ç¬¦å·ï¼Œç„¶åæ ¹æ®ç©ºæ ¼åˆ†è¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">whitespace_tokenize</span><span class="params">(text)</span>:</span></span><br><span class="line">  text = text.strip()</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> text:</span><br><span class="line">    <span class="keyword">return</span> []</span><br><span class="line">  tokens = text.split()</span><br><span class="line">  <span class="keyword">return</span> tokens</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>BasicTokenizer ç±»</strong> </p>
<p>å®ç°ç®€å•çš„åˆ†è¯åŠŸèƒ½ï¼šæ ¹æ®ç¬¦å·åˆ†è¯ï¼Œå­—æ¯å¤§å°å†™å¤„ç†ã€‚</p>
<p>æµç¨‹ï¼šç»Ÿä¸€ unicode ç¼–ç ï¼Œå¹¶å»é™¤æ— æ•ˆå­—ç¬¦ã€æ§åˆ¶å­—ç¬¦ï¼Œç»Ÿä¸€ç©ºç™½å­—ç¬¦ -&gt; ä¸­æ–‡åˆ†è¯æ”¯æŒ -&gt; å»é™¤å¤šä½™ç©ºæ ¼ -&gt; å¤„ç†å¤§å°å†™ï¼Œå»é™¤éŸ³èŠ‚ç¬¦ -&gt; æ ¹æ®ç¬¦å·åˆ†è¯ -&gt;  ç©ºæ ¼åˆ†è¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicTokenizer</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, do_lower_case=True)</span>:</span></span><br><span class="line">    self.do_lower_case = do_lower_case</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ç»Ÿä¸€ç¼–ç ï¼Œè¿‡æ»¤å­—ç¬¦ï¼Œä¸­æ–‡å¤„ç†ï¼Œcase å¤„ç†ï¼Œç¬¦å·åˆ†è¯</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="comment"># ç»Ÿä¸€ä¸º unicode ç¼–ç ï¼Œå¹¶å»é™¤æ— æ•ˆå­—ç¬¦ã€æ§åˆ¶å­—ç¬¦ï¼Œå°†ç©ºç™½å­—ç¬¦ç»Ÿä¸€ä¸ºå•ä¸ªç©ºæ ¼</span></span><br><span class="line">    text = convert_to_unicode(text)</span><br><span class="line">    text = self._clean_text(text)</span><br><span class="line"></span><br><span class="line">    text = self._tokenize_chinese_chars(text) <span class="comment"># ä¸­æ–‡æ”¯æŒ</span></span><br><span class="line"></span><br><span class="line">    orig_tokens = whitespace_tokenize(text) <span class="comment"># å»é™¤å¤šä½™ç©ºç™½ç¬¦</span></span><br><span class="line">    split_tokens = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> orig_tokens:</span><br><span class="line">      <span class="keyword">if</span> self.do_lower_case: <span class="comment"># å¤§å°å†™å¤„ç†</span></span><br><span class="line">        token = token.lower()</span><br><span class="line">        token = self._run_strip_accents(token) <span class="comment"># å»é™¤éŸ³èŠ‚ç¬¦</span></span><br><span class="line">      split_tokens.extend(self._run_split_on_punc(token)) <span class="comment"># æ ¹æ®ç¬¦å·åˆ†è¯</span></span><br><span class="line"></span><br><span class="line">    output_tokens = whitespace_tokenize(<span class="string">" "</span>.join(split_tokens)) </span><br><span class="line">    <span class="keyword">return</span> output_tokens</span><br><span class="line"></span><br><span class="line">  <span class="comment"># å°†éŸ³èŠ‚å­—ç¬¦è½¬æˆç»„åˆå­—ç¬¦è¡¨ç¤ºå†å»é™¤</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_run_strip_accents</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Strips accents from a piece of text."""</span></span><br><span class="line">    <span class="comment"># åœ¨Unicodeä¸­ï¼ŒæŸäº›å­—ç¬¦èƒ½å¤Ÿç”¨å¤šä¸ªåˆæ³•çš„ç¼–ç è¡¨ç¤º</span></span><br><span class="line">    <span class="comment"># normalize() ç¬¬ä¸€ä¸ªå‚æ•°æŒ‡å®šå­—ç¬¦ä¸²æ ‡å‡†åŒ–çš„æ–¹å¼</span></span><br><span class="line">    <span class="comment"># NFCè¡¨ç¤ºå­—ç¬¦åº”è¯¥æ˜¯æ•´ä½“ç»„æˆ(æ¯”å¦‚å¯èƒ½çš„è¯å°±ä½¿ç”¨å•ä¸€ç¼–ç )ï¼Œå¦‚ 'ï¬'</span></span><br><span class="line">    <span class="comment"># è€ŒNFDè¡¨ç¤ºå­—ç¬¦åº”è¯¥åˆ†è§£ä¸ºå¤šä¸ªç»„åˆå­—ç¬¦è¡¨ç¤ºï¼Œå¦‚ 'fi'</span></span><br><span class="line">    text = unicodedata.normalize(<span class="string">"NFD"</span>, text)</span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> text:</span><br><span class="line">      cat = unicodedata.category(char)</span><br><span class="line">      <span class="keyword">if</span> cat == <span class="string">"Mn"</span>: <span class="comment"># Nonspacing Mark</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      output.append(char)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span>.join(output)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># æ ¹æ®æ ‡ç‚¹ç¬¦æ¥åˆ†è¯</span></span><br><span class="line">  <span class="comment"># ä¾‹å¦‚ï¼š"anti-labor" =&gt; ['anti', '-', 'labor']</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_run_split_on_punc</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Splits punctuation on a piece of text."""</span></span><br><span class="line">    chars = list(text)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    start_new_word = <span class="literal">True</span></span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">while</span> i &lt; len(chars):</span><br><span class="line">      char = chars[i]</span><br><span class="line">      <span class="keyword">if</span> _is_punctuation(char): </span><br><span class="line">        output.append([char]) <span class="comment"># æ ‡ç‚¹ä¹Ÿå­˜</span></span><br><span class="line">        start_new_word = <span class="literal">True</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> start_new_word:</span><br><span class="line">          output.append([])</span><br><span class="line">        start_new_word = <span class="literal">False</span></span><br><span class="line">        output[<span class="number">-1</span>].append(char)</span><br><span class="line">      i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">""</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> output]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_tokenize_chinese_chars</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Adds whitespace around any CJK character."""</span></span><br><span class="line">    <span class="comment"># CJK: Chinese Japanese Korean</span></span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> text:</span><br><span class="line">      cp = ord(char)</span><br><span class="line">      <span class="keyword">if</span> self._is_chinese_char(cp):</span><br><span class="line">        output.append(<span class="string">" "</span>)</span><br><span class="line">        output.append(char)</span><br><span class="line">        output.append(<span class="string">" "</span>) <span class="comment"># å¤šä½™çš„ç©ºæ ¼é€šè¿‡åé¢çš„ whitespace_tokenize æµç¨‹å»é™¤</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        output.append(char)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span>.join(output)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_is_chinese_char</span><span class="params">(self, cp)</span>:</span></span><br><span class="line">    <span class="string">"""Checks whether CP is the codepoint of a CJK character."""</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    <span class="keyword">if</span> ((cp &gt;= <span class="number">0x4E00</span> <span class="keyword">and</span> cp &lt;= <span class="number">0x9FFF</span>) <span class="keyword">or</span> ...:  <span class="comment">#</span></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># å»é™¤æ— æ•ˆå­—ç¬¦ã€æ§åˆ¶å­—ç¬¦ï¼Œå°†ç©ºç™½å­—ç¬¦ç»Ÿä¸€ä¸ºå•ä¸ªç©ºæ ¼</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_clean_text</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Performs invalid character removal and whitespace cleanup on text."""</span></span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> text:</span><br><span class="line">      cp = ord(char)</span><br><span class="line">      <span class="comment"># 0 è¡¨ç¤º NULL</span></span><br><span class="line">      <span class="comment"># invalid character ä¼šè½¬æ¢æˆ Unicode çš„REPLACEMENT CHARACTER(0xFFFD)</span></span><br><span class="line">      <span class="keyword">if</span> cp == <span class="number">0</span> <span class="keyword">or</span> cp == <span class="number">0xfffd</span> <span class="keyword">or</span> _is_control(char):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      <span class="keyword">if</span> _is_whitespace(char):</span><br><span class="line">        output.append(<span class="string">" "</span>)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        output.append(char)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span>.join(output)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>WordpieceTokenizer ç±»</strong></p>
<p>ä½¿ç”¨ wordpiece æ–¹å¼åˆ†è¯ï¼Œä½¿ç”¨æœ€é•¿åŒ¹é…ä¼˜å…ˆçš„æ–¹å¼ï¼Œä½¿ç”¨ â€œ##â€å‰ç¼€ã€‚</p>
<font color="red">è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼šæœªç™»å½•è¯ä¼šä¸ä¼šå½±å“å°†æ¥ answer çš„å®šä½ï¼Ÿï¼Ÿ</font>

<p>æˆ‘çš„å›ç­”ï¼šä¸ä¼šï¼Œæ²¡æ‰¾çš„è¯æ›¿æ¢ä¸º â€˜[UNK]â€™ åè¿˜æ˜¯ä¸€ä¸ªposition çš„å ä½ï¼Œè¿˜æ˜¯å¯¹é½çš„ã€‚åœ¨é¢„æµ‹é˜¶æ®µå¦‚æœè¦è¾“å‡ºï¼Œè¾“å‡ºå¯¹åº”ä½ç½®åŸæ¥çš„ tokenã€‚è¿™ä¸€å¤„ç†å¯ä»¥å‚è§ run_squad.py ä¸­çš„ get_final_text()ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordpieceTokenizer</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Runs WordPiece tokenziation."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab, unk_token=<span class="string">"[UNK]"</span>, max_input_chars_per_word=<span class="number">200</span>)</span>:</span></span><br><span class="line">    self.vocab = vocab</span><br><span class="line">    self.unk_token = unk_token</span><br><span class="line">    self.max_input_chars_per_word = max_input_chars_per_word</span><br><span class="line">	</span><br><span class="line">  <span class="comment"># ç»Ÿä¸€ç¼–ç ï¼Œæœ€é•¿åŒ¹é…ä¼˜å…ˆï¼Œæœªç™»å½•tokenä½¿ç”¨'[UNK]'æ›¿ä»£</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""greedy **longest**-match-first</span></span><br><span class="line"><span class="string">    	For example:</span></span><br><span class="line"><span class="string">        input = "unaffable"</span></span><br><span class="line"><span class="string">        output = ["un", "##aff", "##able"]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    text = convert_to_unicode(text)</span><br><span class="line"></span><br><span class="line">    output_tokens = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> whitespace_tokenize(text):</span><br><span class="line">      chars = list(token)</span><br><span class="line">      <span class="keyword">if</span> len(chars) &gt; self.max_input_chars_per_word:</span><br><span class="line">        output_tokens.append(self.unk_token)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">      is_bad = <span class="literal">False</span> <span class="comment"># æ˜¯å¦æ˜¯æœªç™»å½•token</span></span><br><span class="line">      start = <span class="number">0</span></span><br><span class="line">      sub_tokens = []</span><br><span class="line">      <span class="keyword">while</span> start &lt; len(chars):</span><br><span class="line">        end = len(chars)</span><br><span class="line">        cur_substr = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> start &lt; end:</span><br><span class="line">          substr = <span class="string">""</span>.join(chars[start:end])</span><br><span class="line">          <span class="keyword">if</span> start &gt; <span class="number">0</span>:</span><br><span class="line">            substr = <span class="string">"##"</span> + substr</span><br><span class="line">          <span class="keyword">if</span> substr <span class="keyword">in</span> self.vocab:</span><br><span class="line">            cur_substr = substr</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">          end -= <span class="number">1</span> <span class="comment"># **longest**-match-first</span></span><br><span class="line">        <span class="keyword">if</span> cur_substr <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># å‡ºç°æœªç™»å½•tokenï¼Œç»ˆæ­¢æµç¨‹</span></span><br><span class="line">          is_bad = <span class="literal">True</span></span><br><span class="line">          <span class="keyword">break</span></span><br><span class="line">        sub_tokens.append(cur_substr)</span><br><span class="line">        start = end <span class="comment"># å¯»æ‰¾ä¸‹ä¸€ä¸ª token</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> is_bad: <span class="comment"># æœªç™»å½•tokenä½¿ç”¨'[UNK]'æ›¿ä»£</span></span><br><span class="line">        output_tokens.append(self.unk_token)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        output_tokens.extend(sub_tokens)</span><br><span class="line">    <span class="keyword">return</span> output_tokens</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>FullTokenizerr ç±»</strong></p>
<p>æµç¨‹ï¼štext -&gt; ä½¿ç”¨ BasicTokenizer æ ¹æ®ç¬¦å·åˆ†è¯ï¼Œå­—æ¯å¤§å°å†™å¤„ç†ï¼Œå¾—åˆ° tokens -&gt; ä½¿ç”¨ WordpieceTokenizer åˆ†è¯ï¼Œå¾—åˆ° sub_tokens</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FullTokenizer</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Runs end-to-end tokenziation."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_file, do_lower_case=True)</span>:</span></span><br><span class="line">    self.vocab = load_vocab(vocab_file) <span class="comment"># &#123;token: index&#125;</span></span><br><span class="line">    self.inv_vocab = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.vocab.items()&#125; <span class="comment"># &#123;index: token&#125;</span></span><br><span class="line">    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)</span><br><span class="line">    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    split_tokens = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> self.basic_tokenizer.tokenize(text):</span><br><span class="line">      <span class="keyword">for</span> sub_token <span class="keyword">in</span> self.wordpiece_tokenizer.tokenize(token):</span><br><span class="line">        split_tokens.append(sub_token)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> split_tokens</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">convert_tokens_to_ids</span><span class="params">(self, tokens)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> convert_by_vocab(self.vocab, tokens)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">convert_ids_to_tokens</span><span class="params">(self, ids)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> convert_by_vocab(self.inv_vocab, ids)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h6 id="modeling-py"><a href="#modeling-py" class="headerlink" title="modeling.py"></a>modeling.py</h6><p>è¿™æ˜¯å¯¹BERTæ¨¡å‹çš„ä»£ç éƒ¨åˆ†ï¼Œæˆ‘ä»¬å…ˆç»˜åˆ¶å‡º modeling.py æ–‡ä»¶çš„ç»“æ„ï¼Œç„¶åé€ä¸ªå‡½æ•°é€è¡Œåˆ†æã€‚</p>
<p><img src="/bert-squad-tf/image-20190703180540319.png" alt="image-20190703180540319"></p>
<ul>
<li><p>create_initializer</p>
<p>ä»æˆªæ–­çš„æ­£æ€åˆ†å¸ƒä¸­è¾“å‡ºéšæœºå€¼ã€‚ç”Ÿæˆçš„å€¼æœä»å…·æœ‰æŒ‡å®šå¹³å‡å€¼å’Œæ ‡å‡†åå·®çš„æ­£æ€åˆ†å¸ƒï¼Œå¦‚æœç”Ÿæˆçš„å€¼å¤§äºå¹³å‡å€¼2ä¸ªæ ‡å‡†åå·®çš„å€¼åˆ™ä¸¢å¼ƒé‡é€‰ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_initializer</span><span class="params">(initializer_range=<span class="number">0.02</span>)</span>:</span></span><br><span class="line">  <span class="string">"""Creates a `truncated_normal_initializer` with the given range."""</span></span><br><span class="line">  <span class="keyword">return</span> tf.truncated_normal_initializer(stddev=initializer_range)</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_assignment_map_from_checkpoint </p>
<p>å¯¹é½å½“å‰æ¨¡å‹å’Œ checkpointï¼Œç¡®å®šå“ªäº›å˜é‡å¯ä»¥é€šè¿‡ checkpoint åˆå§‹åŒ–</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_assignment_map_from_checkpoint</span><span class="params">(tvars, init_checkpoint)</span>:</span></span><br><span class="line">  <span class="string">"""Compute the union of the current variables and checkpoint variables."""</span></span><br><span class="line">  assignment_map = &#123;&#125;</span><br><span class="line">  initialized_variable_names = &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Returns dict of all trainable variables in the model.</span></span><br><span class="line">  name_to_variable = collections.OrderedDict()</span><br><span class="line">  <span class="keyword">for</span> var <span class="keyword">in</span> tvars:</span><br><span class="line">    name = var.name <span class="comment"># ä¾‹ 'bert/embeddings/word_embeddings:0'</span></span><br><span class="line">    m = re.match(<span class="string">"^(.*):\\d+$$"</span>, name)</span><br><span class="line">    <span class="keyword">if</span> m <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      name = m.group(<span class="number">1</span>) <span class="comment"># ä¾‹ 'bert/embeddings/word_embeddings'</span></span><br><span class="line">    name_to_variable[name] = var</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Returns list of all variables in the checkpoint.</span></span><br><span class="line">  init_vars = tf.train.list_variables(init_checkpoint) </span><br><span class="line">	</span><br><span class="line">  <span class="comment"># æŸ¥æ‰¾é‚£äº›æ¨¡å‹ä¸­çš„å‚æ•°å¯ä»¥ä½¿ç”¨ checkpoint åˆå§‹åŒ–</span></span><br><span class="line">  assignment_map = collections.OrderedDict()</span><br><span class="line">  <span class="keyword">for</span> x <span class="keyword">in</span> init_vars:</span><br><span class="line">    (name, var) = (x[<span class="number">0</span>], x[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">not</span> <span class="keyword">in</span> name_to_variable:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    assignment_map[name] = name</span><br><span class="line">    initialized_variable_names[name] = <span class="number">1</span></span><br><span class="line">    initialized_variable_names[name + <span class="string">":0"</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (assignment_map, initialized_variable_names)</span><br></pre></td></tr></table></figure>
</li>
<li><p>create_attention_mask_from_input_mask</p>
<p>è¿™ä¸ªå‡½æ•°æœ‰ç‚¹ç»•ã€‚æˆ‘ä»¬ä¸ç”¨ç®¡ batch_size å¯èƒ½æ›´å®¹æ˜“ç†è§£ä¸€äº›ã€‚</p>
<p>å¯¹äºä¸€ä¸ª from_seq_length çš„è¾“å…¥ï¼Œæˆ‘ä»¬ä»å®ƒçš„æ¯ä¸ªä½ç½®å» attend ç›®æ ‡åºåˆ—ä¸­çš„æ²¡æœ‰è¢« mask æ‰çš„ä½ç½®ã€‚</p>
<p>[1, to_seq_length] * [from_seq_length, 1] =&gt; [from_seq_length, to_seq_length]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_attention_mask_from_input_mask</span><span class="params">(from_tensor, to_mask)</span>:</span></span><br><span class="line">  <span class="string">"""Create 3D attention mask from a 2D tensor mask.</span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].</span></span><br><span class="line"><span class="string">    to_mask: int32 Tensor of shape [batch_size, to_seq_length].</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    float Tensor of shape [batch_size, from_seq_length, to_seq_length].</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  from_shape = get_shape_list(from_tensor, expected_rank=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">  batch_size = from_shape[<span class="number">0</span>]</span><br><span class="line">  from_seq_length = from_shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  to_shape = get_shape_list(to_mask, expected_rank=<span class="number">2</span>)</span><br><span class="line">  to_seq_length = to_shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  to_mask = tf.cast(</span><br><span class="line">      tf.reshape(to_mask, [batch_size, <span class="number">1</span>, to_seq_length]), tf.float32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># We don't actually care if we attend *from* padding tokens (only *to* padding)</span></span><br><span class="line">  <span class="comment"># tokens so we create a tensor of all ones.</span></span><br><span class="line">  broadcast_ones = tf.ones(</span><br><span class="line">      shape=[batch_size, from_seq_length, <span class="number">1</span>], dtype=tf.float32) <span class="comment"># ä» from_seq çš„æ¯ä¸ªä½ç½®å» attend to_seq</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Here we broadcast along two dimensions to create the mask.</span></span><br><span class="line">  mask = broadcast_ones * to_mask</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> mask</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>shape ç›¸å…³</strong></p>
<ul>
<li><p>get_shape_list</p>
<p>è¿”å› tensor çš„ç»´åº¦ä¿¡æ¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_shape_list</span><span class="params">(tensor, expected_rank=None, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Returns a list of the shape of tensor, preferring static dimensions."""</span></span><br><span class="line">  ...</span><br><span class="line">  shape = tensor.shape.as_list() </span><br><span class="line"></span><br><span class="line">  non_static_indexes = []</span><br><span class="line">  <span class="keyword">for</span> (index, dim) <span class="keyword">in</span> enumerate(shape):</span><br><span class="line">    <span class="keyword">if</span> dim <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># åŠ¨æ€ç»´åº¦</span></span><br><span class="line">      non_static_indexes.append(index)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> non_static_indexes: <span class="comment"># ä¸å­˜åœ¨åŠ¨æ€ç»´åº¦</span></span><br><span class="line">    <span class="keyword">return</span> shape</span><br><span class="line">	<span class="comment"># åŠ¨æ€ç»´åº¦æ ¹æ®å®é™… tensor çš„å¯¹åº”ç»´åº¦æ¥å¡«å……</span></span><br><span class="line">  dyn_shape = tf.shape(tensor)</span><br><span class="line">  <span class="keyword">for</span> index <span class="keyword">in</span> non_static_indexes:</span><br><span class="line">    shape[index] = dyn_shape[index]</span><br><span class="line">  <span class="keyword">return</span> shape</span><br></pre></td></tr></table></figure>
</li>
<li><p>reshape_to_matrix / reshape_from_matrix</p>
<p>reshape_to_matrix å°†è¶…è¿‡2é˜¶çš„ tensor è½¬æˆ2é˜¶ï¼Œreshape_from_matrix æ‰§è¡Œç›¸åæ“ä½œã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_to_matrix</span><span class="params">(input_tensor)</span>:</span></span><br><span class="line">  <span class="string">"""Reshapes a &gt;= rank 2 tensor to a rank 2 tensor (i.e., a matrix)."""</span></span><br><span class="line">  ndims = input_tensor.shape.ndims</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> ndims == <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">return</span> input_tensor</span><br><span class="line"></span><br><span class="line">  width = input_tensor.shape[<span class="number">-1</span>]</span><br><span class="line">  output_tensor = tf.reshape(input_tensor, [<span class="number">-1</span>, width])</span><br><span class="line">  <span class="keyword">return</span> output_tensor</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_from_matrix</span><span class="params">(output_tensor, orig_shape_list)</span>:</span></span><br><span class="line">  <span class="string">"""Reshapes a rank 2 tensor back to its original rank &gt;= 2 tensor."""</span></span><br><span class="line">  <span class="keyword">if</span> len(orig_shape_list) == <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">return</span> output_tensor</span><br><span class="line">  </span><br><span class="line">  output_shape = get_shape_list(output_tensor)</span><br><span class="line">  orig_dims = orig_shape_list[<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">  width = output_shape[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> tf.reshape(output_tensor, orig_dims + [width])</span><br></pre></td></tr></table></figure>
</li>
<li><p>assert_rank</p>
<p>rank æ ¡éªŒ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">assert_rank</span><span class="params">(tensor, expected_rank, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Raises an exception if the tensor rank is not of the expected rank."""</span></span><br><span class="line">  ...</span><br><span class="line">  expected_rank_dict = &#123;&#125;</span><br><span class="line">  <span class="comment"># åªæœŸæœ›ä¸€ä¸ª rank</span></span><br><span class="line">  <span class="keyword">if</span> isinstance(expected_rank, six.integer_types):</span><br><span class="line">    expected_rank_dict[expected_rank] = <span class="literal">True</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">		<span class="comment"># è¾“å…¥ expected_rank ä¸ºlist[]ï¼Œå­˜åœ¨å¤šä¸ªæœŸæœ›çš„ rank</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> expected_rank:</span><br><span class="line">      expected_rank_dict[x] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">  actual_rank = tensor.shape.ndims <span class="comment"># tensor å®é™…çš„ rank</span></span><br><span class="line">  <span class="keyword">if</span> actual_rank <span class="keyword">not</span> <span class="keyword">in</span> expected_rank_dict:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(...)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>embedding ç›¸å…³</strong></p>
<ul>
<li><p>embedding_lookup</p>
<p>å°†è¾“å…¥çš„  ids æ˜ å°„æˆ è¯å‘é‡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">embedding_lookup</span><span class="params">(input_ids, # int32 Tenso: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                     vocab_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                     embedding_size=<span class="number">128</span>, # BERT_base ä¸­ <span class="number">768</span></span></span></span><br><span class="line"><span class="function"><span class="params">                     initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                     word_embedding_name=<span class="string">"word_embeddings"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                     use_one_hot_embeddings=False)</span>:</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># é»˜è®¤è¾“å…¥3é˜¶ [batch_size, seq_length, num_inputs]</span></span><br><span class="line">  <span class="comment"># 2é˜¶è¾“å…¥[batch_size, seq_length] æ‰©å±•ä¸º [batch_size, seq_length, num_inputs=1]</span></span><br><span class="line">  <span class="keyword">if</span> input_ids.shape.ndims == <span class="number">2</span>:</span><br><span class="line">    input_ids = tf.expand_dims(input_ids, axis=[<span class="number">-1</span>]) <span class="comment"># [batch_size, seq_length, num_inputs=1]</span></span><br><span class="line"></span><br><span class="line">  embedding_table = tf.get_variable(</span><br><span class="line">      name=word_embedding_name,</span><br><span class="line">      shape=[vocab_size, embedding_size],</span><br><span class="line">      initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  flat_input_ids = tf.reshape(input_ids, [<span class="number">-1</span>]) <span class="comment"># [batch_size*seq_length*num_inputs,]</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># å° vocabulary æ—¶å€™ use_one_hot_embeddings æ›´å¿«</span></span><br><span class="line">  <span class="comment"># å¤§ vocabulary æ—¶å€™ tf.gather æ›´å¿«</span></span><br><span class="line">  <span class="keyword">if</span> use_one_hot_embeddings: </span><br><span class="line">    one_hot_input_ids = tf.one_hot(flat_input_ids, depth=vocab_size) <span class="comment"># [batch_size*seq_length*num_inputs, vocab_size]</span></span><br><span class="line">    output = tf.matmul(one_hot_input_ids, embedding_table) <span class="comment"># [batch_size*seq_length*num_inputs, embedding_size]</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    output = tf.gather(embedding_table, flat_input_ids) <span class="comment"># [batch_size*seq_length*num_inputs, embedding_size]</span></span><br><span class="line"></span><br><span class="line">  input_shape = get_shape_list(input_ids)</span><br><span class="line">  <span class="comment"># # [batch_size, seq_length, num_inputs*embedding_size]</span></span><br><span class="line">  output = tf.reshape(output, input_shape[<span class="number">0</span>:<span class="number">-1</span>] + [input_shape[<span class="number">-1</span>] * embedding_size])</span><br><span class="line">  <span class="keyword">return</span> (output, embedding_table)</span><br></pre></td></tr></table></figure>
</li>
<li><p>embedding_postprocessor</p>
<p>å¯¹ embedding è¿›è¡Œåå¤„ç†ï¼š+ position_emb + type/segment_emb + Layer_Norm + dropout</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">embedding_postprocessor</span><span class="params">(input_tensor, # [batch_size, seq_length, embedding_size]</span></span></span><br><span class="line"><span class="function"><span class="params">                            use_token_type=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                            token_type_ids=None, # [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                            token_type_vocab_size=<span class="number">16</span>, # æœ€å¤š<span class="number">16</span>ç§type</span></span></span><br><span class="line"><span class="function"><span class="params">                            token_type_embedding_name=<span class="string">"token_type_embeddings"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                            use_position_embeddings=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                            position_embedding_name=<span class="string">"position_embeddings"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                            initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                            max_position_embeddings=<span class="number">512</span>, # åºåˆ—æœ€å¤§å¯ç”¨é•¿åº¦</span></span></span><br><span class="line"><span class="function"><span class="params">                            dropout_prob=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">  </span><br><span class="line">  input_shape = get_shape_list(input_tensor, expected_rank=<span class="number">3</span>) <span class="comment"># [batch_size, seq_length, embedding_size]</span></span><br><span class="line">  batch_size = input_shape[<span class="number">0</span>]</span><br><span class="line">  seq_length = input_shape[<span class="number">1</span>]</span><br><span class="line">  width = input_shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">  output = input_tensor</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> use_token_type:</span><br><span class="line">    ... <span class="comment"># è¾“å…¥åˆæ³•æ€§åˆ¤æ–­</span></span><br><span class="line">    token_type_table = tf.get_variable(</span><br><span class="line">        name=token_type_embedding_name,</span><br><span class="line">        shape=[token_type_vocab_size, width],</span><br><span class="line">        initializer=create_initializer(initializer_range))</span><br><span class="line">    <span class="comment"># å° vocabulary æ—¶å€™ use_one_hot_embeddings æ›´å¿«</span></span><br><span class="line">    flat_token_type_ids = tf.reshape(token_type_ids, [<span class="number">-1</span>])</span><br><span class="line">    one_hot_ids = tf.one_hot(flat_token_type_ids, depth=token_type_vocab_size) </span><br><span class="line">    token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)</span><br><span class="line">    token_type_embeddings = tf.reshape(token_type_embeddings,</span><br><span class="line">                                       [batch_size, seq_length, width])</span><br><span class="line">    output += token_type_embeddings <span class="comment"># ç›´æ¥æŒ‰ä½åŠ </span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> use_position_embeddings:</span><br><span class="line">    assert_op = tf.assert_less_equal(seq_length, max_position_embeddings) <span class="comment"># è¾“å…¥åˆæ³•æ€§åˆ¤æ–­</span></span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([assert_op]):</span><br><span class="line">      full_position_embeddings = tf.get_variable(</span><br><span class="line">          name=position_embedding_name,</span><br><span class="line">          shape=[max_position_embeddings, width],</span><br><span class="line">          initializer=create_initializer(initializer_range))</span><br><span class="line">      <span class="comment"># æˆªå– [0, 1, ... seq_length-1] åŒºé—´çš„ embedding_tableï¼Œæ›´å¿« </span></span><br><span class="line">      position_embeddings = tf.slice(full_position_embeddings, [<span class="number">0</span>, <span class="number">0</span>], [seq_length, <span class="number">-1</span>])</span><br><span class="line">      num_dims = len(output.shape.as_list())</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Only the last two dimensions are relevant (`seq_length` and `width`), so</span></span><br><span class="line">      <span class="comment"># we broadcast among the first dimensions â€”â€” the batch size.</span></span><br><span class="line">      position_broadcast_shape = []</span><br><span class="line">      <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_dims - <span class="number">2</span>):</span><br><span class="line">        position_broadcast_shape.append(<span class="number">1</span>)</span><br><span class="line">      position_broadcast_shape.extend([seq_length, width])</span><br><span class="line">      position_embeddings = tf.reshape(position_embeddings,</span><br><span class="line">                                       position_broadcast_shape)</span><br><span class="line">      output += position_embeddings <span class="comment"># ç›´æ¥æŒ‰ä½åŠ </span></span><br><span class="line"></span><br><span class="line">  output = layer_norm_and_dropout(output, dropout_prob)</span><br><span class="line">  <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Transformer æ¨¡å‹</strong></p>
<ul>
<li><p>transformer_model</p>
<table>
<td><img src="/bert-squad-tf/image-20190703013613264.png" width="70%"></td>
  <td><img src="/bert-squad-tf/image-20190702234605092.png" width="100%"></td>
</table>
</li>
<li><p>Scaled Dot-Product Attention</p>
<script type="math/tex; mode=display">\text { Attention }(Q, K, V)=\operatorname{softmax}\big(\displaystyle\frac{Q K^{T}}{\sqrt{d_{k}}}\big) V</script><ul>
<li><p>queries and keys of dimension <script type="math/tex">d_k</script>ï¼Œvalues of dimension <script type="math/tex">d_v</script></p>
</li>
<li><p>queries, keys and values are  packed together into matrices <script type="math/tex">Q</script>, <script type="math/tex">K</script> and <script type="math/tex">V</script>.</p>
</li>
<li><p>why scale the product by <script type="math/tex">\begin{equation}
  \frac{1}{\sqrt{d_{k}}}
\end{equation}</script>: for large values of <script type="math/tex">d_k</script>, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients.</p>
</li>
</ul>
</li>
<li><p>Multi-Head Attention</p>
<script type="math/tex; mode=display">\begin{aligned} \text { MultiHead }(Q, K, V) &=\text {Concat}\left(\text { head}_{1}, \ldots, \text { head}_{h}\right) W^{O} \\ \text { where head }_{i} &=\text {Attention}\left(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\right) \end{aligned}</script><ul>
<li><script type="math/tex; mode=display">W_{i}^{Q} \in \mathbb{R}^{d_{\text {model}} \times d_{k}}, W_{i}^{K} \in \mathbb{R}^{d_{\text {model}} \times d_{k}}, W_{i}^{V} \in \mathbb{R}^{d_{\text {model}} \times d_{v}}, W^{O} \in \mathbb{R}^{h d_{v} \times d_{\text {model}}}</script><ul>
<li><script type="math/tex; mode=display">d_{k}=d_{v}=d_{\mathrm{model}} / h</script></li>
</ul>
</li>
<li><p>Position-wise Feed-Forward Networks</p>
<script type="math/tex; mode=display">\operatorname{FFN}(x)=\text{activation}\left(x W_{1}+b_{1}\right) W_{2}+b_{2}</script><ul>
<li>Another way of describing this is as two convolutions with kernel size 1</li>
</ul>
<p>è¯¦ç»†çš„ Transformer ç›¸å…³çš„å¯ä»¥å‚ç…§åŸè®ºæ–‡å’Œä»£ç å®ç°ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transformer_model</span><span class="params">(input_tensor,	# [batch_size, seq_length, hidden_size]</span></span></span><br><span class="line"><span class="function"><span class="params">                        attention_mask=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                      hidden_size=<span class="number">768</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        num_hidden_layers=<span class="number">12</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      num_attention_heads=<span class="number">12</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        intermediate_size=<span class="number">3072</span>, # FFN ä½¿ç”¨</span></span></span><br><span class="line"><span class="function"><span class="params">                        intermediate_act_fn=gelu,</span></span></span><br><span class="line"><span class="function"><span class="params">                        hidden_dropout_prob=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      attention_probs_dropout_prob=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      do_return_all_layers=False)</span>:</span></span><br><span class="line">    <span class="string">"""Multi-headed, multi-layer Transformer from "Attention is All You Need".</span></span><br><span class="line"><span class="string">  https://arxiv.org/abs/1706.03762</span></span><br><span class="line"><span class="string">    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  <span class="keyword">if</span> hidden_size % num_attention_heads != <span class="number">0</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(...)</span><br><span class="line"></span><br><span class="line">    attention_head_size = int(hidden_size / num_attention_heads) <span class="comment"># d_k = d_v = d_model / h</span></span><br><span class="line">  input_shape = get_shape_list(input_tensor, expected_rank=<span class="number">3</span>)</span><br><span class="line">    batch_size = input_shape[<span class="number">0</span>]</span><br><span class="line">  seq_length = input_shape[<span class="number">1</span>]</span><br><span class="line">    input_width = input_shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># Re-shape æ“ä½œåœ¨ TPU ä¸Šäº§ç”Ÿé¢å¤–å¼€é”€ï¼Œå› æ­¤ä¿ç•™ä¸€ä»½ 2D çš„ input_tensor </span></span><br><span class="line">    prev_output = reshape_to_matrix(input_tensor)</span><br><span class="line">  </span><br><span class="line">    all_layer_outputs = []</span><br><span class="line">    <span class="keyword">for</span> layer_idx <span class="keyword">in</span> range(num_hidden_layers):</span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(<span class="string">"layer_%d"</span> % layer_idx):</span><br><span class="line">        layer_input = prev_output</span><br><span class="line">  </span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"attention"</span>):</span><br><span class="line">          attention_heads = [] <span class="comment"># å¤šä¸ª sequence</span></span><br><span class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">"self"</span>):</span><br><span class="line">            attention_head = attention_layer(...)</span><br><span class="line">            attention_heads.append(attention_head)</span><br><span class="line">  </span><br><span class="line">          attention_output = <span class="literal">None</span></span><br><span class="line">          <span class="keyword">if</span> len(attention_heads) == <span class="number">1</span>:</span><br><span class="line">            attention_output = attention_heads[<span class="number">0</span>]</span><br><span class="line">          <span class="keyword">else</span>: <span class="comment"># </span></span><br><span class="line">            <span class="comment"># In the case where we have other sequences, we just concatenate</span></span><br><span class="line">            <span class="comment"># them to the self-attention head before the projection.</span></span><br><span class="line">            attention_output = tf.concat(attention_heads, axis=<span class="number">-1</span>)</span><br><span class="line">  				</span><br><span class="line">          <span class="comment"># å¯¹é½åˆ° `hidden_size`</span></span><br><span class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">"output"</span>):</span><br><span class="line">            attention_output = tf.layers.dense(</span><br><span class="line">                attention_output,</span><br><span class="line">                hidden_size,</span><br><span class="line">                kernel_initializer=create_initializer(initializer_range))</span><br><span class="line">            attention_output = dropout(attention_output, hidden_dropout_prob)</span><br><span class="line">            <span class="comment"># Add &amp; Norm</span></span><br><span class="line">            attention_output = layer_norm(attention_output + layer_input) </span><br><span class="line">  			</span><br><span class="line">        <span class="comment"># FFN</span></span><br><span class="line">        <span class="comment"># The activation is only applied to the "intermediate" hidden layer.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"intermediate"</span>):</span><br><span class="line">          intermediate_output = tf.layers.dense(</span><br><span class="line">              attention_output,</span><br><span class="line">              intermediate_size,</span><br><span class="line">              activation=intermediate_act_fn,</span><br><span class="line">              kernel_initializer=create_initializer(initializer_range))</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># Down-project back to `hidden_size` then add the residual.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"output"</span>):</span><br><span class="line">          layer_output = tf.layers.dense(</span><br><span class="line">              intermediate_output,</span><br><span class="line">              hidden_size,</span><br><span class="line">              kernel_initializer=create_initializer(initializer_range))</span><br><span class="line">          layer_output = dropout(layer_output, hidden_dropout_prob)</span><br><span class="line">          <span class="comment"># Add &amp; Norm</span></span><br><span class="line">          layer_output = layer_norm(layer_output + attention_output)</span><br><span class="line">          prev_output = layer_output</span><br><span class="line">          all_layer_outputs.append(layer_output)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> do_return_all_layers:</span><br><span class="line">      final_outputs = []</span><br><span class="line">      <span class="keyword">for</span> layer_output <span class="keyword">in</span> all_layer_outputs:</span><br><span class="line">        final_output = reshape_from_matrix(layer_output, input_shape) <span class="comment"># è¿˜åŸæˆ input_shape æ ¼å¼</span></span><br><span class="line">        final_outputs.append(final_output)</span><br><span class="line">      <span class="keyword">return</span> final_outputs</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      final_output = reshape_from_matrix(prev_output, input_shape) <span class="comment"># è¿˜åŸæˆ input_shape æ ¼å¼</span></span><br><span class="line">      <span class="keyword">return</span> final_output</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>attention_layer</p>
<p>å¤šå¤´ attention çš„è®¡ç®—ï¼Œå®é™…ä¸Šå¤šå¤´æœºåˆ¶é€šè¿‡çŸ©é˜µçš„transposes å’Œ reshape æ–¹å¼æ¥å¹¶è¡Œå®ç°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_layer</span><span class="params">(from_tensor,</span></span></span><br><span class="line"><span class="function"><span class="params">                    to_tensor,</span></span></span><br><span class="line"><span class="function"><span class="params">                    attention_mask=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    num_attention_heads=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    size_per_head=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    query_act=None, # Activation function for the query transform.</span></span></span><br><span class="line"><span class="function"><span class="params">                    key_act=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    value_act=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    attention_probs_dropout_prob=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    do_return_2d_tensor=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                    batch_size=None, # <span class="number">2</span>D input æ‰éœ€è¦</span></span></span><br><span class="line"><span class="function"><span class="params">                    from_seq_length=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    to_seq_length=None)</span>:</span></span><br><span class="line">  <span class="string">"""Performs multi-headed attention from `from_tensor` to `to_tensor`.</span></span><br><span class="line"><span class="string">  In practice, the multi-headed attention are done with transposes and</span></span><br><span class="line"><span class="string">  reshapes rather than actual separate tensors."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">transpose_for_scores</span><span class="params">(input_tensor, batch_size, num_attention_heads,</span></span></span><br><span class="line"><span class="function"><span class="params">                           seq_length, width)</span>:</span></span><br><span class="line">    output_tensor = tf.reshape(</span><br><span class="line">        input_tensor, [batch_size, seq_length, num_attention_heads, width])</span><br><span class="line"></span><br><span class="line">    output_tensor = tf.transpose(output_tensor, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">    <span class="keyword">return</span> output_tensor</span><br><span class="line"></span><br><span class="line">  from_shape = get_shape_list(from_tensor, expected_rank=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">  to_shape = get_shape_list(to_tensor, expected_rank=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment"># Scalar dimensions referenced here:</span></span><br><span class="line">  <span class="comment">#   B = batch size (number of sequences)</span></span><br><span class="line">  <span class="comment">#   F = `from_tensor` sequence length</span></span><br><span class="line">  <span class="comment">#   T = `to_tensor` sequence length</span></span><br><span class="line">  <span class="comment">#   N = `num_attention_heads`</span></span><br><span class="line">  <span class="comment">#   H = `size_per_head`</span></span><br><span class="line"></span><br><span class="line">  from_tensor_2d = reshape_to_matrix(from_tensor) <span class="comment"># [B*F, width]</span></span><br><span class="line">  to_tensor_2d = reshape_to_matrix(to_tensor) <span class="comment"># [B*T, width]</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># `query_layer` = [B*F, N*H]</span></span><br><span class="line">  query_layer = tf.layers.dense(</span><br><span class="line">      from_tensor_2d, <span class="comment">#</span></span><br><span class="line">      num_attention_heads * size_per_head,</span><br><span class="line">      activation=query_act,</span><br><span class="line">      name=<span class="string">"query"</span>,</span><br><span class="line">      kernel_initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `key_layer` = [B*T, N*H]</span></span><br><span class="line">  key_layer = tf.layers.dense(</span><br><span class="line">      to_tensor_2d, <span class="comment">#</span></span><br><span class="line">      num_attention_heads * size_per_head,</span><br><span class="line">      activation=key_act,</span><br><span class="line">      name=<span class="string">"key"</span>,</span><br><span class="line">      kernel_initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `value_layer` = [B*T, N*H]</span></span><br><span class="line">  value_layer = tf.layers.dense(</span><br><span class="line">      to_tensor_2d,</span><br><span class="line">      num_attention_heads * size_per_head,</span><br><span class="line">      activation=value_act,</span><br><span class="line">      name=<span class="string">"value"</span>,</span><br><span class="line">      kernel_initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `query_layer` = [B, N, F, H]</span></span><br><span class="line">  query_layer = transpose_for_scores(query_layer, batch_size,</span><br><span class="line">                                     num_attention_heads, from_seq_length,</span><br><span class="line">                                     size_per_head)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `key_layer` = [B, N, T, H]</span></span><br><span class="line">  key_layer = transpose_for_scores(key_layer, batch_size, num_attention_heads,</span><br><span class="line">                                   to_seq_length, size_per_head)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Dot product between "query" and "key" to get the raw attention scores.</span></span><br><span class="line">  <span class="comment"># `attention_scores` = [B, N, F, T]</span></span><br><span class="line">  attention_scores = tf.matmul(query_layer, key_layer, transpose_b=<span class="literal">True</span>)</span><br><span class="line">  attention_scores = tf.multiply(attention_scores,</span><br><span class="line">                                 <span class="number">1.0</span> / math.sqrt(float(size_per_head)))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> attention_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># `attention_mask` = [B, 1, F, T]</span></span><br><span class="line">    attention_mask = tf.expand_dims(attention_mask, axis=[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># å°†è¢« mask æ‰çš„åœ°æ–¹çš„ attention å€¼è®¾ç½®ä¸ºå¾ˆå°çš„è´Ÿæ•°ï¼Œè¿™æ ·åœ¨åš softmax åï¼Œ</span></span><br><span class="line">    <span class="comment"># è¿™äº›ä½ç½®çš„æ¦‚ç‡ä¸º 0.</span></span><br><span class="line">    adder = (<span class="number">1.0</span> - tf.cast(attention_mask, tf.float32)) * <span class="number">-10000.0</span></span><br><span class="line">    attention_scores += adder</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Normalize the attention scores to probabilities.</span></span><br><span class="line">  <span class="comment"># `attention_probs` = [B, N, F, T]</span></span><br><span class="line">  attention_probs = tf.nn.softmax(attention_scores)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># This is actually dropping out entire tokens to attend to, which might</span></span><br><span class="line">  <span class="comment"># seem a bit unusual, but is taken from the original Transformer paper.</span></span><br><span class="line">  attention_probs = dropout(attention_probs, attention_probs_dropout_prob)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `value_layer` = [B, T, N, H]</span></span><br><span class="line">  value_layer = tf.reshape(</span><br><span class="line">      value_layer,</span><br><span class="line">      [batch_size, to_seq_length, num_attention_heads, size_per_head])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `value_layer` = [B, N, T, H]</span></span><br><span class="line">  value_layer = tf.transpose(value_layer, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `context_layer` = [B, N, F, H]</span></span><br><span class="line">  context_layer = tf.matmul(attention_probs, value_layer)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `context_layer` = [B, F, N, H]</span></span><br><span class="line">  context_layer = tf.transpose(context_layer, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> do_return_2d_tensor:</span><br><span class="line">    <span class="comment"># `context_layer` = [B*F, N*H]</span></span><br><span class="line">    context_layer = tf.reshape(</span><br><span class="line">        context_layer,</span><br><span class="line">        [batch_size * from_seq_length, num_attention_heads * size_per_head])</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># `context_layer` = [B, F, N*H]</span></span><br><span class="line">    context_layer = tf.reshape(</span><br><span class="line">        context_layer,</span><br><span class="line">        [batch_size, from_seq_length, num_attention_heads * size_per_head])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> context_layer</span><br></pre></td></tr></table></figure>
</li>
<li><p>layer_norm_and_dropout</p>
<p>è¿™ä¸ªå‡½æ•°ç»„æ²¡å•¥å¥½è¯´çš„ï¼Œå¦‚ä»£ç æ‰€ç¤ºã€‚å¦‚æœè¿™ä¸ªéƒ½çœ‹ä¸æ‡‚ï¼Œåˆ«ç»§ç»­çœ‹äº†ã€‚</p>
<p>å‚è€ƒè®ºæ–‡ <a href="https://arxiv.org/abs/1607.06450" target="_blank" rel="noopener">https://arxiv.org/abs/1607.06450</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span><span class="params">(input_tensor, dropout_prob)</span>:</span> <span class="comment"># NOT of *keeping* a dimension as in `tf.nn.dropout`</span></span><br><span class="line">  <span class="keyword">if</span> dropout_prob <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> dropout_prob == <span class="number">0.0</span>:</span><br><span class="line">    <span class="keyword">return</span> input_tensor</span><br><span class="line">  output = tf.nn.dropout(input_tensor, <span class="number">1.0</span> - dropout_prob)</span><br><span class="line">  <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_norm</span><span class="params">(input_tensor, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Run layer normalization on the last dimension of the tensor."""</span></span><br><span class="line">  <span class="keyword">return</span> tf.contrib.layers.layer_norm(</span><br><span class="line">      inputs=input_tensor, begin_norm_axis=<span class="number">-1</span>, begin_params_axis=<span class="number">-1</span>, scope=name)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_norm_and_dropout</span><span class="params">(input_tensor, dropout_prob, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Runs layer normalization followed by dropout."""</span></span><br><span class="line">  output_tensor = layer_norm(input_tensor, name)</span><br><span class="line">  output_tensor = dropout(output_tensor, dropout_prob)</span><br><span class="line">  <span class="keyword">return</span> output_tensor</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_activation</p>
<p>æ ¹æ®åç§°è¿”å›å¯¹åº”çš„æ¿€æ´»å‡½æ•°ï¼Œæ”¯æŒ â€œlinearâ€ / â€œreluâ€ / â€œgeluâ€ / â€œtanhâ€</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_activation</span><span class="params">(activation_string)</span>:</span></span><br><span class="line">  <span class="string">"""Maps a string to a Python function, e.g., "relu" =&gt; `tf.nn.relu`."""</span></span><br><span class="line">  ...</span><br><span class="line">  act = activation_string.lower()</span><br><span class="line">  <span class="keyword">if</span> act == <span class="string">"linear"</span>:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
</li>
<li><p>gelu</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gelu</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="string">"""Gaussian Error Linear Unit.</span></span><br><span class="line"><span class="string">  Original paper: https://arxiv.org/abs/1606.08415</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  cdf = <span class="number">0.5</span> * (<span class="number">1.0</span> + tf.tanh(</span><br><span class="line">      (np.sqrt(<span class="number">2</span> / np.pi) * (x + <span class="number">0.044715</span> * tf.pow(x, <span class="number">3</span>)))))</span><br><span class="line">  <span class="keyword">return</span> x * cdf</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>BertConfigç±»</strong><br>å…³é”®é…ç½®ï¼š</p>
<p>â€‹    <script type="math/tex">\text{BERT}_\text{BASE}</script>  (L=12, H=768, A=12, Total Parameters=110M)  </p>
<p>â€‹    <script type="math/tex">\text{BERT}_\text{LARGE}</script>  (L=24, H=1024, A=16, Total Parameters=340M).</p>
<p>â€‹    L: num_hidden_layers, H: hidden_size, A: num_attention_heads</p>
<p>ä»£ç è¿è¡Œé€»è¾‘ï¼š</p>
<p>â€‹    BertConfig.from_json_file(FLAGS.bert_config_file)  â€”&gt; cls.from_dict(json.loads(text)) ï¼Œåœ¨ from_dict å‡½æ•°ä¸­å®Œæˆ BertConfig å®ä¾‹åŒ–</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BertConfig</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Configuration for `BertModel`."""</span></span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, hidden_size=<span class="number">768</span>, num_hidden_layers=<span class="number">12</span>, num_attention_heads=<span class="number">12</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               intermediate_size=<span class="number">3072</span>, hidden_act=<span class="string">"gelu"</span>, hidden_dropout_prob=<span class="number">0.1</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               attention_probs_dropout_prob=<span class="number">0.1</span>, max_position_embeddings=<span class="number">512</span>, type_vocab_size=<span class="number">16</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               initializer_range=<span class="number">0.02</span>)</span>:</span></span><br><span class="line">    <span class="string">"""...</span></span><br><span class="line"><span class="string">      intermediate_size: The size of the "intermediate" (i.e., feed-forward)</span></span><br><span class="line"><span class="string">        layer in the Transformer encoder.</span></span><br><span class="line"><span class="string">      ...</span></span><br><span class="line"><span class="string">      max_position_embeddings: The maximum sequence length that this model might</span></span><br><span class="line"><span class="string">        ever be used with. Typically set this to something large just in case</span></span><br><span class="line"><span class="string">        (e.g., 512 or 1024 or 2048).</span></span><br><span class="line"><span class="string">      ...</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    self.vocab_size = vocab_size</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">from_dict</span><span class="params">(cls, json_object)</span>:</span></span><br><span class="line">    <span class="string">"""Constructs a `BertConfig` from a Python dictionary of parameters."""</span></span><br><span class="line">    config = BertConfig(vocab_size=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> (key, value) <span class="keyword">in</span> six.iteritems(json_object):</span><br><span class="line">      config.__dict__[key] = value</span><br><span class="line">    <span class="keyword">return</span> config</span><br><span class="line"></span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">from_json_file</span><span class="params">(cls, json_file)</span>:</span> <span class="comment"># ä¾‹: json_file='/root/bert/uncased_L-12_H-768_A-12/bert_config.json'</span></span><br><span class="line">    <span class="string">"""Constructs a `BertConfig` from a json file of parameters."""</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(json_file, <span class="string">"r"</span>) <span class="keyword">as</span> reader:</span><br><span class="line">      text = reader.read()</span><br><span class="line">    <span class="keyword">return</span> cls.from_dict(json.loads(text))</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">to_dict</span><span class="params">(self)</span>:</span> <span class="comment"># å°†å¯¹è±¡è½¬æˆå­—å…¸</span></span><br><span class="line">    <span class="string">"""Serializes this instance to a Python dictionary."""</span></span><br><span class="line">    output = copy.deepcopy(self.__dict__)</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">to_json_string</span><span class="params">(self)</span>:</span> <span class="comment"># å°†å¯¹è±¡è½¬æˆjson</span></span><br><span class="line">    <span class="string">"""Serializes this instance to a JSON string."""</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(self.to_dict(), indent=<span class="number">2</span>, sort_keys=<span class="literal">True</span>) + <span class="string">"\n"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>BertModelç±»</strong></p>
<p>æ„å»ºè¾“å…¥ï¼š</p>
<table><img src="/bert-squad-tf/image-20190702200034350.png" width="70%" align="left"></table>

<p>æ„é€ å‡½æ•°çš„ä»£ç é€»è¾‘ï¼š</p>
<p>è·å–æ¨¡å‹é…ç½® -&gt; æ ¹æ®æ˜¯å¦è®­ç»ƒè®¾ç½®dropout -&gt; æ£€æŸ¥maskå’Œtype -&gt; è®¡ç®—è¾“å…¥embedding -&gt; # ä½¿ç”¨å¤šå±‚ Transformer Block å¤„ç† -&gt; Transformerçš„è¾“å‡ºç”¨äºä¸‹æ¸¸ä»»åŠ¡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BertModel</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""BERT model ("Bidirectional Encoder Representations from Transformers").</span></span><br><span class="line"><span class="string">  Example usage:</span></span><br><span class="line"><span class="string">    ```python</span></span><br><span class="line"><span class="string">  # Already been converted into WordPiece token ids</span></span><br><span class="line"><span class="string">    input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])</span></span><br><span class="line"><span class="string">  input_mask = tf.constant([[1, 1, 1], [1, 1, 0]])</span></span><br><span class="line"><span class="string">    token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    config = modeling.BertConfig(vocab_size=32000, hidden_size=512,</span></span><br><span class="line"><span class="string">      num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    model = modeling.BertModel(config=config, is_training=True,</span></span><br><span class="line"><span class="string">      input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type_ids)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    label_embeddings = tf.get_variable(...)</span></span><br><span class="line"><span class="string">    pooled_output = model.get_pooled_output()</span></span><br><span class="line"><span class="string">    logits = tf.matmul(pooled_output, label_embeddings)</span></span><br><span class="line"><span class="string">    ...</span></span><br><span class="line"><span class="string">    ```</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                 config, # `BertConfig` å¯¹è±¡</span></span></span><br><span class="line"><span class="function"><span class="params">                 is_training, # bool. æ§åˆ¶æ˜¯å¦ä½¿ç”¨ dropout</span></span></span><br><span class="line"><span class="function"><span class="params">                 input_ids, # int32 Tensor: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                 input_mask=None, # <span class="params">(optional)</span>int32 Tensor: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                 token_type_ids=None, # <span class="params">(optional)</span>int32 Tensor: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                 use_one_hot_embeddings=False, # word embeddings ä½¿ç”¨ one-hot embeddings è¿˜æ˜¯ tf.embedding_lookup<span class="params">()</span></span></span></span><br><span class="line"><span class="function"><span class="params">                 scope=None)</span>:</span></span><br><span class="line">  </span><br><span class="line">      config = copy.deepcopy(config)</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> is_training: <span class="comment"># eval æ¨¡å¼ä¸ä½¿ç”¨ dropout</span></span><br><span class="line">        config.hidden_dropout_prob = <span class="number">0.0</span></span><br><span class="line">        config.attention_probs_dropout_prob = <span class="number">0.0</span></span><br><span class="line">  </span><br><span class="line">      input_shape = get_shape_list(input_ids, expected_rank=<span class="number">2</span>) <span class="comment"># [12, 384]</span></span><br><span class="line">      batch_size = input_shape[<span class="number">0</span>]</span><br><span class="line">      seq_length = input_shape[<span class="number">1</span>]</span><br><span class="line">  </span><br><span class="line">      <span class="comment"># æ£€æŸ¥ mask å’Œ type</span></span><br><span class="line">      <span class="keyword">if</span> input_mask <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># æ²¡æœ‰æŒ‡å®š mask å°±è®¤ä¸ºæ‰€æœ‰ä½ç½®éƒ½æ˜¯çœŸå®tokensï¼Œå…¨éƒ¨éœ€è¦ attend</span></span><br><span class="line">        input_mask = tf.ones(shape=[batch_size, seq_length], dtype=tf.int32)</span><br><span class="line">      <span class="keyword">if</span> token_type_ids <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># æ²¡æœ‰æŒ‡å®š type å°±æŠŠæ•´ä¸ªè¾“å…¥å½“ä½œä¸€ä¸ª type/segment</span></span><br><span class="line">        token_type_ids = tf.zeros(shape=[batch_size, seq_length], dtype=tf.int32)</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(scope, default_name=<span class="string">"bert"</span>):</span><br><span class="line">        <span class="comment"># è®¡ç®—è¾“å…¥embedding</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"embeddings"</span>):</span><br><span class="line">          <span class="comment"># Perform embedding lookup on the word ids.</span></span><br><span class="line">          (self.embedding_output, self.embedding_table) = embedding_lookup(...)</span><br><span class="line">          <span class="comment"># word embeddings + positional embeddings + token type embeddings</span></span><br><span class="line">          <span class="comment"># ç„¶å layer normalize &amp; perform dropout.</span></span><br><span class="line">          self.embedding_output = embedding_postprocessor(...)</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># ä½¿ç”¨å¤šå±‚ Transformer Block å¤„ç†</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"encoder"</span>):</span><br><span class="line">          <span class="comment"># è®¡ç®—åœ¨ attention çŸ©é˜µä¸­è¦ mask æ‰çš„ä½ç½®</span></span><br><span class="line">          attention_mask = create_attention_mask_from_input_mask(input_ids, input_mask)</span><br><span class="line">          <span class="comment"># Run the stacked transformer.</span></span><br><span class="line">          <span class="comment"># `sequence_output` shape = [batch_size, seq_length, hidden_size].</span></span><br><span class="line">          self.all_encoder_layers = transformer_model(...)</span><br><span class="line">  			</span><br><span class="line">        <span class="comment"># Transformerçš„è¾“å‡ºç”¨äºä¸‹æ¸¸ä»»åŠ¡</span></span><br><span class="line">        self.sequence_output = self.all_encoder_layers[<span class="number">-1</span>] <span class="comment"># æœ€åçš„ hidden_layer</span></span><br><span class="line">        <span class="comment"># ä½¿ç”¨æœ€åhidden_layer çš„ [cls] ä½ç½®çš„è¾“å‡ºæ¥å®Œæˆ classification çš„ä¸‹æ¸¸ä»»åŠ¡</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"pooler"</span>):</span><br><span class="line">          first_token_tensor = tf.squeeze(self.sequence_output[:, <span class="number">0</span>:<span class="number">1</span>, :], axis=<span class="number">1</span>)</span><br><span class="line">          self.pooled_output = tf.layers.dense(</span><br><span class="line">              first_token_tensor,</span><br><span class="line">              config.hidden_size,</span><br><span class="line">              activation=tf.tanh,</span><br><span class="line">              kernel_initializer=create_initializer(config.initializer_range))</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># è¿”å› [CLS] ä½ç½®çš„å‘é‡ç”¨äºä¸‹æ¸¸ä»»åŠ¡</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pooled_output</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.pooled_output</span><br><span class="line">  	<span class="comment"># è¿”å›æœ€åçš„ hidden_layer çš„æ¯ä¸ªä½ç½®çš„è¾“å‡º</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_sequence_output</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="string">"""Gets final hidden layer of encoder: [batch_size, seq_length, hidden_size]"""</span></span><br><span class="line">      <span class="keyword">return</span> self.sequence_output</span><br><span class="line">  	<span class="comment"># å‚æ•°è®¾ç½®è¿”å›æ‰€æœ‰å±‚çš„æ¯ä¸ªä½ç½®çš„è¾“å‡ºï¼Œæˆ–æœ€åçš„ hidden_layer çš„æ¯ä¸ªä½ç½®çš„è¾“å‡º</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_encoder_layers</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.all_encoder_layers</span><br><span class="line">  	<span class="comment"># è¿”å›è¾“å…¥embedding</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_embedding_output</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.embedding_output</span><br><span class="line">  	<span class="comment"># è¿”å›embedding_table</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_embedding_table</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.embedding_table</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h6 id="optimization-py"><a href="#optimization-py" class="headerlink" title="optimization.py"></a>optimization.py</h6><p><img src="/bert-squad-tf/image-20190703184633330.png" alt="image-20190703184633330"></p>
<ul>
<li><p>create_optimizer</p>
<p>BERT è®ºæ–‡é‡Œï¼šWe use Adam with learning rate of 1e-4, <script type="math/tex">Î²_1</script> = 0.9, <script type="math/tex">Î²_2</script> = 0.999, L2 weight decay of 0.01, learning rate warm-up over the first 10,000 steps, and linear decay of the learning rate. </p>
<p>è¯¥å‡½æ•°çš„æµç¨‹ä¸ºï¼šè®¡ç®—å­¦ä¹ ç‡ï¼ˆå…ˆ warm_up å çº¿æ€§è¡°å‡ï¼‰ -&gt; åˆ›å»ºä¼˜åŒ–å™¨ -&gt; è®¡ç®—æ¢¯åº¦ -&gt; è£å‰ªæ¢¯åº¦ -&gt; æ›´æ–°å‚æ•°å’Œglobal_step</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_optimizer</span><span class="params">(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu)</span>:</span></span><br><span class="line">  <span class="string">"""Creates an optimizer training op."""</span></span><br><span class="line">  global_step = tf.train.get_or_create_global_step()</span><br><span class="line"></span><br><span class="line">  learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># çº¿æ€§è¡°å‡å­¦ä¹ ç‡ `power` = 1.0</span></span><br><span class="line">  <span class="comment"># global_step = min(global_step, decay_steps)</span></span><br><span class="line">	<span class="comment"># decayed_learning_rate = (learning_rate - end_learning_rate) *</span></span><br><span class="line">  <span class="comment">#                      (1 - global_step / decay_steps) ^ (power) +</span></span><br><span class="line">  <span class="comment">#                      end_learning_rate</span></span><br><span class="line">  learning_rate = tf.train.polynomial_decay(...) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># Implements linear warmup. I.e., if global_step &lt; num_warmup_steps, the</span></span><br><span class="line">  <span class="comment"># learning rate will be `global_step/num_warmup_steps * init_lr`.</span></span><br><span class="line">  <span class="keyword">if</span> num_warmup_steps:</span><br><span class="line">    global_steps_int = tf.cast(global_step, tf.int32)</span><br><span class="line">    warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    global_steps_float = tf.cast(global_steps_int, tf.float32)</span><br><span class="line">    warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)</span><br><span class="line"></span><br><span class="line">    warmup_percent_done = global_steps_float / warmup_steps_float</span><br><span class="line">    warmup_learning_rate = init_lr * warmup_percent_done</span><br><span class="line">		<span class="comment"># æ ¹æ® global_steps é€‰æ‹©æ˜¯ warmup é˜¶æ®µ è¿˜æ˜¯ decay é˜¶æ®µ</span></span><br><span class="line">    is_warmup = tf.cast(global_steps_int &lt; warmup_steps_int, tf.float32)</span><br><span class="line">    learning_rate = (</span><br><span class="line">        (<span class="number">1.0</span> - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># æ¨èåœ¨ fine-tune é˜¶æ®µä½¿ç”¨è¿™ä¸ª optimizer (ä¿æŒä¸€è‡´æ€§)</span></span><br><span class="line">  <span class="comment"># Adam m/v variables **ä¸** ä» init_checkpoint åŠ è½½</span></span><br><span class="line">  optimizer = AdamWeightDecayOptimizer(...)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># CrossShardOptimizer ä¸æœ¬åœ°è®­ç»ƒä¸å…¼å®¹ï¼Œè¦åœ¨æœ¬åœ°å’Œ Cloud TPU ä¸Šè¿è¡Œç›¸åŒä»£ç ï¼Œè¯·æ·»åŠ ï¼š</span></span><br><span class="line">  <span class="keyword">if</span> use_tpu: </span><br><span class="line">    <span class="comment"># è¿™ä¸ªæ¥å£ä¼¼ä¹æœ‰ bugï¼Œç›®å‰å®˜æ–¹æ–‡æ¡£ä¸­å·²ç» 404</span></span><br><span class="line">    <span class="comment"># ä½¿ç”¨ allreduce èšåˆæ¢¯åº¦å¹¶å°†ç»“æœå¹¿æ’­åˆ°å„ä¸ªåˆ†ç‰‡ï¼ˆæ¯ä¸ª TPU æ ¸ï¼‰</span></span><br><span class="line">    optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)</span><br><span class="line">	</span><br><span class="line">  <span class="comment"># å¯¹å¯è®­ç»ƒå˜é‡è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">  tvars = tf.trainable_variables()</span><br><span class="line">  grads = tf.gradients(loss, tvars)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># æ¢¯åº¦æˆªæ–­ä½¿ç”¨ clip_by_global_norm(t_list, clip_norm, ...)</span></span><br><span class="line">  <span class="comment"># global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))</span></span><br><span class="line">  <span class="comment"># t_list[i] * clip_norm / max(global_norm, clip_norm)</span></span><br><span class="line">  <span class="comment"># å‚è€ƒ http://arxiv.org/pdf/1211.5063.pdf</span></span><br><span class="line">  (grads, _) = tf.clip_by_global_norm(grads, clip_norm=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">  train_op = optimizer.apply_gradients(</span><br><span class="line">      zip(grads, tvars), global_step=global_step) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># é€šå¸¸åœ¨ apply_gradients ä¸­æ›´æ–° global_stepï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæ›´æ–°</span></span><br><span class="line">  new_global_step = global_step + <span class="number">1</span></span><br><span class="line">  train_op = tf.group(train_op, [global_step.assign(new_global_step)])</span><br><span class="line">  <span class="keyword">return</span> train_op</span><br></pre></td></tr></table></figure>
</li>
<li><p>AdamWeightDecayOptimizer</p>
<p>Adam ä¼˜åŒ–å™¨ï¼š</p>
<ul>
<li><p>Initialization: </p>
<script type="math/tex; mode=display">\begin{array}{c}{m_{0} :=0(\text { Initialize initial } 1 \text { st moment vector })} \\ {v_{0} :=0(\text { Initialize initial } 2 \text { nd moment vector })} \\ {t :=0(\text { Initialize timestep })}\end{array}</script></li>
<li><p>update rule:</p>
<script type="math/tex; mode=display">\begin{array}{c}{t :=t+1} \\ {l r_{t} :=\text { learning_rate } * \sqrt{1-\text { beta}_{2}^{t}} /\left(1-\text { beta}_{1}^{t}\right)} \\ {m_{t} :=b e t a_{1} * m_{t-1}+\left(1-b e t a_{1}\right) * g} \\ {v_{t} :=b e t a_{2} * v_{t-1}+\left(1-\text { bet } a_{2}\right) * g * g} \\ {\text {variable} :=\text {variable}-l r_{t} * m_{t} /\left(\sqrt{v_{t}}+\epsilon\right)}\\\end{array}</script><ul>
<li><script type="math/tex">m_t</script> æ˜¯ä¸€é˜¶åŠ¨é‡ï¼Œ<script type="math/tex">v_t</script> æ˜¯äºŒé˜¶åŠ¨é‡ï¼Œ<script type="math/tex">g</script> æ˜¯æ¢¯åº¦</li>
</ul>
<p>å‚è€ƒè®ºæ–‡ &lt;<a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1412.6980.pdf</a></p>
</li>
</ul>
<p>Adam çš„ weight decayï¼šbertè®­ç»ƒé‡‡ç”¨çš„ä¼˜åŒ–æ–¹æ³•å°±æ˜¯adamwï¼Œå¯¹é™¤äº†layernormï¼Œbiasé¡¹ä¹‹å¤–çš„æ¨¡å‹å‚æ•°åšweight decayã€‚</p>
<ul>
<li>å°†æƒé‡çš„å¹³æ–¹å’ŒåŠ åˆ°æŸå¤±å‡½æ•°ä¸­<strong>ä¸æ˜¯</strong>æ­£ç¡®çš„ Adam çš„ weight decayã€‚</li>
<li>è¿™ç§æ–¹å¼ç­‰ä»·äº SGD çš„ L2 regularizationã€‚<br>å¯ä»¥å‚è§ICLR 2019è¿™ç¯‡æ–‡ç«  <a href="https://arxiv.org/pdf/1711.05101.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.05101.pdf</a> æˆ–è€… é€šä¿—ç‰ˆ <a href="https://zhuanlan.zhihu.com/p/63982470" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63982470</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdamWeightDecayOptimizer</span><span class="params">(tf.train.Optimizer)</span>:</span></span><br><span class="line">  <span class="string">"""A basic Adam optimizer that includes "correct" L2 weight decay."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">               learning_rate,</span></span></span><br><span class="line"><span class="function"><span class="params">               weight_decay_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               beta_1=<span class="number">0.9</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               beta_2=<span class="number">0.999</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               epsilon=<span class="number">1e-6</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               exclude_from_weight_decay=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               name=<span class="string">"AdamWeightDecayOptimizer"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Constructs a AdamWeightDecayOptimizer."""</span></span><br><span class="line">    super(AdamWeightDecayOptimizer, self).__init__(<span class="literal">False</span>, name)</span><br><span class="line">    self.learning_rate = learning_rate</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># æ›´æ–°å‚æ•°</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply_gradients</span><span class="params">(self, grads_and_vars, global_step=None, name=None)</span>:</span></span><br><span class="line">    <span class="string">"""See base class."""</span></span><br><span class="line">    assignments = []</span><br><span class="line">    <span class="keyword">for</span> (grad, param) <span class="keyword">in</span> grads_and_vars:</span><br><span class="line">      <span class="keyword">if</span> grad <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> param <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">      param_name = self._get_variable_name(param.name)</span><br><span class="line">			</span><br><span class="line">      <span class="comment"># ä¸€é˜¶åŠ¨é‡</span></span><br><span class="line">      m = tf.get_variable(</span><br><span class="line">          name=param_name + <span class="string">"/adam_m"</span>,</span><br><span class="line">          shape=param.shape.as_list(),</span><br><span class="line">          dtype=tf.float32,</span><br><span class="line">          trainable=<span class="literal">False</span>,</span><br><span class="line">          initializer=tf.zeros_initializer())</span><br><span class="line">      <span class="comment"># äºŒé˜¶åŠ¨é‡</span></span><br><span class="line">      v = tf.get_variable(</span><br><span class="line">          name=param_name + <span class="string">"/adam_v"</span>,</span><br><span class="line">          shape=param.shape.as_list(),</span><br><span class="line">          dtype=tf.float32,</span><br><span class="line">          trainable=<span class="literal">False</span>,</span><br><span class="line">          initializer=tf.zeros_initializer())</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Standard Adam update.</span></span><br><span class="line">      next_m = (</span><br><span class="line">          tf.multiply(self.beta_1, m) + tf.multiply(<span class="number">1.0</span> - self.beta_1, grad))</span><br><span class="line">      next_v = (</span><br><span class="line">          tf.multiply(self.beta_2, v) + tf.multiply(<span class="number">1.0</span> - self.beta_2,</span><br><span class="line">                                                    tf.square(grad)))</span><br><span class="line">      update = next_m / (tf.sqrt(next_v) + self.epsilon)</span><br><span class="line">			</span><br><span class="line">      <span class="comment"># Adam çš„æ­£ç¡® weight decay æ–¹å¼</span></span><br><span class="line">      <span class="keyword">if</span> self._do_use_weight_decay(param_name):</span><br><span class="line">        update += self.weight_decay_rate * param</span><br><span class="line"></span><br><span class="line">      update_with_lr = self.learning_rate * update</span><br><span class="line"></span><br><span class="line">      next_param = param - update_with_lr</span><br><span class="line"></span><br><span class="line">      assignments.extend(</span><br><span class="line">          [param.assign(next_param),</span><br><span class="line">           m.assign(next_m),</span><br><span class="line">           v.assign(next_v)])</span><br><span class="line">    <span class="keyword">return</span> tf.group(*assignments, name=name)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_do_use_weight_decay</span><span class="params">(self, param_name)</span>:</span></span><br><span class="line">    <span class="string">"""Whether to use L2 weight decay for `param_name`."""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.weight_decay_rate:</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> self.exclude_from_weight_decay: <span class="comment"># æœ¬ä¾‹ä¸­ ['LayerNorm', 'layer_norm', 'bias']</span></span><br><span class="line">      <span class="keyword">for</span> r <span class="keyword">in</span> self.exclude_from_weight_decay:</span><br><span class="line">        <span class="keyword">if</span> re.search(r, param_name) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_get_variable_name</span><span class="params">(self, param_name)</span>:</span></span><br><span class="line">    <span class="string">"""Get the variable name from the tensor name."""</span></span><br><span class="line">    m = re.match(<span class="string">"^(.*):\\d+$$"</span>, param_name)</span><br><span class="line">    <span class="keyword">if</span> m <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      param_name = m.group(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> param_name</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h6 id="run-squad-py"><a href="#run-squad-py" class="headerlink" title="run_squad.py"></a>run_squad.py</h6><p><img src="/bert-squad-tf/image-20190704121235449.png" alt="image-20190704121235449"></p>
<p>è¿™æ˜¯ Bert è¿è¡Œ Squad ä»»åŠ¡çš„ä¸»ç¨‹åºï¼Œä½¿ç”¨äº† Estimator é«˜çº§ API å®ç°ï¼Œå¯ä»¥å‚è€ƒ <a href="https://www.tensorflow.org/guide/custom_estimators" target="_blank" rel="noopener">https://www.tensorflow.org/guide/custom_estimators</a> è¯¦ç»†äº†è§£ç‰¹æ€§å’Œå®ç°ã€‚</p>
<p>è¦æ ¹æ®é¢„åˆ›å»ºçš„ Estimator ç¼–å†™ TensorFlow ç¨‹åºï¼Œæ‚¨å¿…é¡»æ‰§è¡Œä¸‹åˆ—ä»»åŠ¡ï¼š</p>
<ol>
<li><p>åˆ›å»ºä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥å‡½æ•°ã€‚</p>
</li>
<li><p>å®šä¹‰æ¨¡å‹çš„ç‰¹å¾åˆ—ã€‚</p>
</li>
<li><p>å®ä¾‹åŒ– Estimatorï¼ŒæŒ‡å®šç‰¹å¾åˆ—å’Œå„ç§è¶…å‚æ•°ã€‚</p>
</li>
<li><p>åœ¨ Estimator å¯¹è±¡ä¸Šè°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ªæ–¹æ³•ï¼Œä¼ é€’é€‚å½“çš„è¾“å…¥å‡½æ•°ä½œä¸ºæ•°æ®çš„æ¥æºã€‚</p>
</li>
</ol>
<ul>
<li><p>import &amp; FLAGS</p>
<p>FLAGS ä¸è¿è¡Œå‚æ•°å¯¹åº”ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">python run_squad.py \</span><br><span class="line">  --vocab_file=$$BERT_BASE_DIR/vocab.txt \</span><br><span class="line">  --bert_config_file=$$BERT_BASE_DIR/bert_config.json \</span><br><span class="line">  --init_checkpoint=$$BERT_BASE_DIR/bert_model.ckpt \</span><br><span class="line">  --do_train=True \</span><br><span class="line">  --train_file=$$SQUAD_DIR/train-v1.1.json \</span><br><span class="line">  --do_predict=True \</span><br><span class="line">  --predict_file=$$SQUAD_DIR/dev-v1.1.json \</span><br><span class="line">  --train_batch_size=12 \</span><br><span class="line">  --learning_rate=3e-5 \</span><br><span class="line">  --num_train_epochs=2.0 \</span><br><span class="line">  --max_seq_length=384 \</span><br><span class="line">  --doc_stride=128 \</span><br><span class="line">  --output_dir=/tmp/squad_base/</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line">...</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line">...</span><br><span class="line">flags = tf.flags</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"><span class="comment">## Required parameters</span></span><br><span class="line">flags.DEFINE_string(</span><br><span class="line">    <span class="string">"bert_config_file"</span>, <span class="literal">None</span>,</span><br><span class="line">    <span class="string">"The config json file corresponding to the pre-trained BERT model. "</span></span><br><span class="line">    <span class="string">"This specifies the model architecture."</span>)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>validate_flags_or_throw</p>
<p>å¯¹ä¼ å…¥çš„éƒ¨åˆ†å‚æ•°è¿›è¡Œæ£€æŸ¥ï¼š</p>
<p>â€‹    æ£€æŸ¥æŒ‡å®šå¤§å°å†™æ•æ„Ÿæ˜¯å¦å’Œå¾…åŠ è½½æ¨¡å‹ç›¸ä¸€è‡´</p>
<p>â€‹    æ£€æŸ¥è¿è¡Œæ¨¡å¼ï¼Œtrain / predict è‡³å°‘ä¸€ç§ï¼Œåœ¨æ¯ç§æ¨¡å¼ä¸‹æ£€æŸ¥è¾“è¾“å…¥æ–‡ä»¶</p>
<p>â€‹    æ£€æŸ¥è¾“å…¥æœ€å¤§é•¿åº¦ï¼Œä¸è¶…è¿‡æœ€å¤§ä½ç½®åµŒå…¥é•¿åº¦ï¼Œä¸å°äºqueryæœ€å¤§é•¿åº¦+3</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate_flags_or_throw</span><span class="params">(bert_config)</span>:</span></span><br><span class="line">  <span class="comment"># æ£€æŸ¥æŒ‡å®šå¤§å°å†™æ•æ„Ÿæ˜¯å¦å’Œå¾…åŠ è½½æ¨¡å‹ç›¸ä¸€è‡´</span></span><br><span class="line">  tokenization.validate_case_matches_checkpoint(FLAGS.do_lower_case, FLAGS.init_checkpoint)</span><br><span class="line">  <span class="comment"># æ£€æŸ¥è¿è¡Œæ¨¡å¼ï¼Œtrain / predict è‡³å°‘ä¸€ç§ï¼Œåœ¨æ¯ç§æ¨¡å¼ä¸‹æ£€æŸ¥è¾“è¾“å…¥æ–‡ä»¶</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> FLAGS.do_train <span class="keyword">and</span> <span class="keyword">not</span> FLAGS.do_predict:</span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_train <span class="keyword">and</span> <span class="keyword">not</span> FLAGS.train_file:</span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_predict <span class="keyword">and</span> <span class="keyword">not</span> FLAGS.predict_file:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(...)</span><br><span class="line">	<span class="comment"># æ£€æŸ¥è¾“å…¥æœ€å¤§é•¿åº¦ï¼Œä¸è¶…è¿‡æœ€å¤§ä½ç½®åµŒå…¥é•¿åº¦ï¼Œä¸å°äºqueryæœ€å¤§é•¿åº¦+3</span></span><br><span class="line">  <span class="keyword">if</span> FLAGS.max_seq_length &gt; bert_config.max_position_embeddings:</span><br><span class="line">  <span class="keyword">if</span> FLAGS.max_seq_length &lt;= FLAGS.max_query_length + <span class="number">3</span>: <span class="comment"># [cls]...[sep]...[sep] å ç”¨ä¸‰ä¸ªä½ç½®</span></span><br><span class="line">    <span class="keyword">raise</span> ValueError(...)</span><br></pre></td></tr></table></figure>
</li>
<li><p>_compute_softmax</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_softmax</span><span class="params">(scores)</span>:</span></span><br><span class="line">  <span class="string">"""Compute softmax probability over raw logits."""</span></span><br><span class="line">  ...</span><br><span class="line">  max_score = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">for</span> score <span class="keyword">in</span> scores:</span><br><span class="line">    <span class="keyword">if</span> max_score <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> score &gt; max_score:</span><br><span class="line">      max_score = score</span><br><span class="line"></span><br><span class="line">  exp_scores = []</span><br><span class="line">  total_sum = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> score <span class="keyword">in</span> scores:</span><br><span class="line">    x = math.exp(score - max_score) <span class="comment"># é˜²æ­¢æº¢å‡º</span></span><br><span class="line">    exp_scores.append(x)</span><br><span class="line">    total_sum += x</span><br><span class="line"></span><br><span class="line">  probs = []</span><br><span class="line">  <span class="keyword">for</span> score <span class="keyword">in</span> exp_scores:</span><br><span class="line">    probs.append(score / total_sum)</span><br><span class="line">  <span class="keyword">return</span> probs</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Squadè¾“å…¥</strong></p>
<ul>
<li><p><strong>SquadExample ç±»</strong></p>
<p>ç”¨äº Squad ä»»åŠ¡çš„å•ä¸ª exampleï¼Œä¸»è¦åŒ…å«å››éƒ¨åˆ†</p>
<p>â€‹    context: doc_tokens</p>
<p>â€‹    id: qas_id</p>
<p>â€‹    question: question_text</p>
<p>â€‹    answer: orig_answer_text / start_position / end_position / is_impossible</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SquadExample</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="comment"># å¯¹äº answer ä¸å­˜åœ¨çš„ exampleï¼Œstart_position = end_position = -1</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">               qas_id,</span></span></span><br><span class="line"><span class="function"><span class="params">               question_text,</span></span></span><br><span class="line"><span class="function"><span class="params">               doc_tokens,</span></span></span><br><span class="line"><span class="function"><span class="params">               orig_answer_text=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               start_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               end_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               is_impossible=False)</span>:</span></span><br><span class="line">    self.qas_id = qas_id</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># ç”¨äºæ˜¾ç¤ºçš„æ–¹æ³•</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.__repr__()</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">    s = <span class="string">""</span></span><br><span class="line">    s += <span class="string">"qas_id: %s"</span> % (tokenization.printable_text(self.qas_id))</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>InputFeatures ç±»</strong></p>
<p>å®šä¹‰è¾“å…¥ç‰¹å¾é›†åˆæ•°æ®ç»“æ„</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InputFeatures</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""A single set of features of data."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">               unique_id,</span></span></span><br><span class="line"><span class="function"><span class="params">               example_index,</span></span></span><br><span class="line"><span class="function"><span class="params">               doc_span_index,</span></span></span><br><span class="line"><span class="function"><span class="params">               tokens,</span></span></span><br><span class="line"><span class="function"><span class="params">               token_to_orig_map,</span></span></span><br><span class="line"><span class="function"><span class="params">               token_is_max_context,</span></span></span><br><span class="line"><span class="function"><span class="params">               input_ids,</span></span></span><br><span class="line"><span class="function"><span class="params">               input_mask,</span></span></span><br><span class="line"><span class="function"><span class="params">               segment_ids,</span></span></span><br><span class="line"><span class="function"><span class="params">               start_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               end_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               is_impossible=None)</span>:</span></span><br><span class="line">    self.unique_id = unique_id</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
</li>
<li><p>read_squad_examples</p>
<p>ä» .json æ ¼å¼æ–‡ä»¶è¯»å–è¾“å…¥ï¼Œè§£ææˆ SquadExample ç»“æ„</p>
<p>å¤„ç†æµç¨‹ï¼šload_json æ–‡ä»¶ -&gt; ä½¿ç”¨ whitespace æ¥å¯¹ context åˆ†è¯å¾—åˆ° doc_tokensï¼Œå¹¶æ„å»ºcharåˆ°wordçš„æ˜ å°„å…³ç³» -&gt; è§£æé“ qas_id å’Œ question_text -&gt; å¤„ç† answerï¼Œå¾—åˆ° orig_answer_text / start_position / end_position / is_impossible -&gt;  SquadExample ç»“æ„</p>
<ul>
<li>è¿™æ—¶å€™ start_position å’Œ end_position å·²ç»æ˜¯ è¯çº§åˆ«çš„äº†</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_squad_examples</span><span class="params">(input_file, is_training)</span>:</span></span><br><span class="line">  <span class="string">"""Read a SQuAD json file into a list of SquadExample."""</span></span><br><span class="line">  <span class="keyword">with</span> tf.gfile.Open(input_file, <span class="string">"r"</span>) <span class="keyword">as</span> reader:</span><br><span class="line">    input_data = json.load(reader)[<span class="string">"data"</span>] <span class="comment"># dict&#123;"data":..., "version":...&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">is_whitespace</span><span class="params">(c)</span>:</span> <span class="comment"># ç–‘é—®ï¼šord(c) == 0x202F å’Œ tokenization.whitespace_tokenize å­˜åœ¨ä¸ä¸€è‡´ï¼Œä¸ä¼šæœ‰é—®é¢˜ï¼Ÿ</span></span><br><span class="line">    <span class="keyword">if</span> c == <span class="string">" "</span> <span class="keyword">or</span> c == <span class="string">"\t"</span> <span class="keyword">or</span> c == <span class="string">"\r"</span> <span class="keyword">or</span> c == <span class="string">"\n"</span> <span class="keyword">or</span> ord(c) == <span class="number">0x202F</span>: <span class="comment"># ord(c) è¿”å›å­—ç¬¦cçš„unicodeæ•°å€¼ï¼Œ0x202F è¡¨ç¤º NARROW NO-BREAK SPACE</span></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">  </span><br><span class="line">	<span class="string">""" input_data æ•°æ®ç»“æ„</span></span><br><span class="line"><span class="string">	- input_data: [&#123;&#125;,...,&#123;&#125;]</span></span><br><span class="line"><span class="string">		- 'title': str</span></span><br><span class="line"><span class="string">		- 'paragraphs': [&#123;&#125;,...,&#123;&#125;]</span></span><br><span class="line"><span class="string">			- 'context': str</span></span><br><span class="line"><span class="string">			- 'qas': [&#123;&#125;,...,&#123;&#125;]</span></span><br><span class="line"><span class="string">				- 'id': str</span></span><br><span class="line"><span class="string">				- 'question': str</span></span><br><span class="line"><span class="string">				- 'answers': [&#123;&#125;] # __len__ = 1</span></span><br><span class="line"><span class="string">					- 'answer_start': int</span></span><br><span class="line"><span class="string">					- 'text': 'str</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">  examples = []</span><br><span class="line">  <span class="keyword">for</span> entry <span class="keyword">in</span> input_data: </span><br><span class="line">    <span class="keyword">for</span> paragraph <span class="keyword">in</span> entry[<span class="string">"paragraphs"</span>]:</span><br><span class="line">      <span class="comment"># å¤„ç† context</span></span><br><span class="line">      paragraph_text = paragraph[<span class="string">"context"</span>]</span><br><span class="line">      doc_tokens = [] <span class="comment"># ä¸€ä¸ª paragraph["context"] ä¸­çš„æ‰€æœ‰ tokens</span></span><br><span class="line">      char_to_word_offset = [] <span class="comment"># æ¯ä¸ªå­—ç¬¦å±äºç¬¬å‡ ä¸ª token</span></span><br><span class="line">      prev_is_whitespace = <span class="literal">True</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># ä»¥ whitespace ä¸º context åˆ†è¯</span></span><br><span class="line">      <span class="keyword">for</span> c <span class="keyword">in</span> paragraph_text:</span><br><span class="line">        <span class="keyword">if</span> is_whitespace(c): <span class="comment"># whitespace ä¸ä¿å­˜ï¼Œç”¨æ¥åš tokenize</span></span><br><span class="line">          prev_is_whitespace = <span class="literal">True</span> </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">if</span> prev_is_whitespace: <span class="comment"># whitespace åé¢æ˜¯ä¸€ä¸ªæ–°çš„ token</span></span><br><span class="line">            doc_tokens.append(c)</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            doc_tokens[<span class="number">-1</span>] += c <span class="comment"># åŠ å…¥åˆ°å½“å‰ token</span></span><br><span class="line">          prev_is_whitespace = <span class="literal">False</span></span><br><span class="line">        char_to_word_offset.append(len(doc_tokens) - <span class="number">1</span>) <span class="comment"># å½“å‰å­—ç¬¦å±äºç¬¬å‡ ä¸ª token</span></span><br><span class="line">			</span><br><span class="line">      <span class="comment"># å¤„ç† question å’Œ answer</span></span><br><span class="line">      <span class="keyword">for</span> qa <span class="keyword">in</span> paragraph[<span class="string">"qas"</span>]:</span><br><span class="line">        qas_id = qa[<span class="string">"id"</span>]</span><br><span class="line">        question_text = qa[<span class="string">"question"</span>]</span><br><span class="line">        start_position = <span class="literal">None</span> <span class="comment"># answer çš„å¼€å§‹ä½ç½®</span></span><br><span class="line">        end_position = <span class="literal">None</span> <span class="comment"># answer çš„ç»“æŸä½ç½®</span></span><br><span class="line">        orig_answer_text = <span class="literal">None</span> <span class="comment"># åŸå§‹ç­”æ¡ˆtext</span></span><br><span class="line">        is_impossible = <span class="literal">False</span> <span class="comment"># å¯¹äºsquad 2.0ï¼Œå­˜åœ¨æ²¡æœ‰ answer çš„é—®é¢˜</span></span><br><span class="line">        <span class="keyword">if</span> is_training: <span class="comment"># åœ¨ predict é˜¶æ®µï¼Œjson æ–‡ä»¶ä¸­æ²¡æœ‰ answer</span></span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">            is_impossible = qa[<span class="string">"is_impossible"</span>]</span><br><span class="line">          <span class="keyword">if</span> (len(qa[<span class="string">"answers"</span>]) != <span class="number">1</span>) <span class="keyword">and</span> (<span class="keyword">not</span> is_impossible): <span class="comment"># æœ‰ answer çš„é—®é¢˜å”¯ä¸€è§£</span></span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">"For training, each question should have exactly 1 answer."</span>)</span><br><span class="line">          <span class="keyword">if</span> <span class="keyword">not</span> is_impossible: <span class="comment"># æœ‰ answer</span></span><br><span class="line">            answer = qa[<span class="string">"answers"</span>][<span class="number">0</span>] <span class="comment"># å”¯ä¸€è§£</span></span><br><span class="line">            orig_answer_text = answer[<span class="string">"text"</span>]</span><br><span class="line">            answer_offset = answer[<span class="string">"answer_start"</span>] <span class="comment"># åœ¨ context ä¸­ answer çš„ char çº§åˆ«çš„ offset</span></span><br><span class="line">            answer_length = len(orig_answer_text) <span class="comment"># answer è¦†ç›–çš„ char æ•°ç›® </span></span><br><span class="line">            start_position = char_to_word_offset[answer_offset] <span class="comment"># char çº§åˆ«çš„ offset è½¬æ¢æˆ tokens ä¸­çš„ä½ç½®</span></span><br><span class="line">            end_position = char_to_word_offset[answer_offset + answer_length - <span class="number">1</span>] </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># å»é™¤å¯èƒ½ç”±ç¼–ç é—®é¢˜å¯¼è‡´ answer ä¸èƒ½åœ¨åŸæ–‡æ‰¾åˆ°</span></span><br><span class="line">            actual_text = <span class="string">" "</span>.join(</span><br><span class="line">                doc_tokens[start_position:(end_position + <span class="number">1</span>)])</span><br><span class="line">            cleaned_answer_text = <span class="string">" "</span>.join(</span><br><span class="line">                tokenization.whitespace_tokenize(orig_answer_text))</span><br><span class="line">            <span class="keyword">if</span> actual_text.find(cleaned_answer_text) == <span class="number">-1</span>:</span><br><span class="line">              tf.logging.warning(...)</span><br><span class="line">              <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">else</span>: <span class="comment"># æ²¡æœ‰ answer çš„é—®é¢˜ï¼Œç‰¹æ®Šå¤„ç†</span></span><br><span class="line">            start_position = <span class="number">-1</span></span><br><span class="line">            end_position = <span class="number">-1</span></span><br><span class="line">            orig_answer_text = <span class="string">""</span></span><br><span class="line"></span><br><span class="line">        example = SquadExample(...)</span><br><span class="line">        examples.append(example)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>
</li>
<li><p>convert_examples_to_features</p>
<p>å°† SquadExample è§£ææˆ ä¸€ä¸ªæˆ–å¤šä¸ª InputFeatures</p>
<p>æµç¨‹ï¼šunique_id,example_index -&gt; å¯¹ question_text åˆ†è¯å¾—åˆ° query_tokens -&gt; å¯¹ doc_tokens è¿›ä¸€æ­¥åˆ†è¯å¾—åˆ° all_doc_tokensï¼Œå¹¶å»ºç«‹ä¸¤ç§ tokens ä¹‹é—´çš„æ˜ å°„å…³ç³» -&gt; æ›´æ–° answer åœ¨ all_doc_tokens ä¸­çš„ tok_start_position å’Œ  tok_start_position -&gt; ä½¿ç”¨æ»‘åŠ¨çª—å£æœºåˆ¶å¤„ç† all_doc_tokensï¼Œæ¯ä¸ª doc_span = [[â€˜CLSâ€™] query_tokens [â€˜SEPâ€™] doc_span_text [â€˜SEPâ€™]] -&gt; å¯¹å…¶ answer åœ¨å½“å‰ doc_span ä¸­çš„èµ·å§‹ä½ç½® start_position å’Œ  start_position  -&gt;  InputFeatures ç»“æ„ -&gt; é€šè¿‡ FeatureWriter å†™å…¥åˆ° TFRecord æ–‡ä»¶ä¸­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_examples_to_features</span><span class="params">(examples, tokenizer, max_seq_length,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 doc_stride, max_query_length, is_training,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 output_fn)</span>:</span></span><br><span class="line">  unique_id = <span class="number">1000000000</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (example_index, example) <span class="keyword">in</span> enumerate(examples):</span><br><span class="line">    <span class="comment"># question_text åˆ†è¯ï¼Œä½¿ç”¨ FullTokenizer.tokenize</span></span><br><span class="line">    query_tokens = tokenizer.tokenize(example.question_text) </span><br><span class="line">    <span class="keyword">if</span> len(query_tokens) &gt; max_query_length:</span><br><span class="line">      query_tokens = query_tokens[<span class="number">0</span>:max_query_length]</span><br><span class="line">      </span><br><span class="line">		<span class="comment"># FullTokenizeråˆ†è¯åçš„tokenåœ¨å¯¹åº”çš„ example.doc_tokens é‡Œé¢çš„ç´¢å¼•</span></span><br><span class="line">    <span class="comment"># æ ·ä¾‹ï¼š&lt;class 'list'&gt;: [0, 0, 0, 1, 2, 3, 4, 4, ...]</span></span><br><span class="line">    tok_to_orig_index = [] </span><br><span class="line">    <span class="comment"># tok_to_orig_index çš„é€†ï¼Œæ ·ä¾‹ï¼š&lt;class 'list'&gt;: [0, 3, 4, 5, ...]</span></span><br><span class="line">    orig_to_tok_index = []</span><br><span class="line">    </span><br><span class="line">    all_doc_tokens = []</span><br><span class="line">    <span class="keyword">for</span> (i, token) <span class="keyword">in</span> enumerate(example.doc_tokens):</span><br><span class="line">      orig_to_tok_index.append(len(all_doc_tokens))</span><br><span class="line">      sub_tokens = tokenizer.tokenize(token)</span><br><span class="line">      <span class="keyword">for</span> sub_token <span class="keyword">in</span> sub_tokens:</span><br><span class="line">        tok_to_orig_index.append(i)</span><br><span class="line">        all_doc_tokens.append(sub_token)</span><br><span class="line"></span><br><span class="line">    tok_start_position = <span class="literal">None</span></span><br><span class="line">    tok_end_position = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> is_training <span class="keyword">and</span> example.is_impossible: <span class="comment"># squad v2.0</span></span><br><span class="line">      tok_start_position = <span class="number">-1</span></span><br><span class="line">      tok_end_position = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">if</span> is_training <span class="keyword">and</span> <span class="keyword">not</span> example.is_impossible:</span><br><span class="line">      tok_start_position = orig_to_tok_index[example.start_position]</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># ä¾‹å¦‚ï¼šori[end_position] = "unaffable", tok = [..., "un", "##aff", "##able", ...]</span></span><br><span class="line">      <span class="comment"># orig_to_tok_index[end_position] ä½ç½®åœ¨ tok ä¸­å¯¹åº”çš„æ˜¯ "un"</span></span><br><span class="line">      <span class="comment"># orig_to_tok_index[end_position + 1] - 1 ä½ç½®åœ¨ tok ä¸­å¯¹åº”çš„æ˜¯ "##able"</span></span><br><span class="line">      <span class="keyword">if</span> example.end_position &lt; len(example.doc_tokens) - <span class="number">1</span>:</span><br><span class="line">        tok_end_position = orig_to_tok_index[example.end_position + <span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">      <span class="comment"># å¦‚æœæ˜¯ ori ä¸­æœ€åä¸€ä¸ª token</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        tok_end_position = len(all_doc_tokens) - <span class="number">1</span></span><br><span class="line">      <span class="comment"># å¾—åˆ°æ›´ç²¾å‡†çš„ answer çš„å§‹æœ«ä½ç½®</span></span><br><span class="line">      (tok_start_position, tok_end_position) = _improve_answer_span(</span><br><span class="line">          all_doc_tokens, tok_start_position, tok_end_position, tokenizer,</span><br><span class="line">          example.orig_answer_text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The -3 accounts for [CLS], [SEP] and [SEP]</span></span><br><span class="line">    max_tokens_for_doc = max_seq_length - len(query_tokens) - <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ä¸ºäº†å¤„ç†è¶…é•¿çš„æ–‡æœ¬ï¼Œä½¿ç”¨ æ»‘åŠ¨çª—å£ æœºåˆ¶</span></span><br><span class="line">    <span class="comment"># æ¯æ¬¡æ»‘åŠ¨ doc_stride çš„é•¿åº¦ï¼Œçª—å£åŒºé—´ä¸º min(length, max_tokens_for_doc)</span></span><br><span class="line">    <span class="comment"># ç›¸é‚»çš„ doc_span ä¹‹é—´ä¼šæœ‰é‡å </span></span><br><span class="line">    _DocSpan = collections.namedtuple(<span class="string">"DocSpan"</span>, [<span class="string">"start"</span>, <span class="string">"length"</span>])</span><br><span class="line">    doc_spans = []</span><br><span class="line">    start_offset = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> start_offset &lt; len(all_doc_tokens):</span><br><span class="line">      length = len(all_doc_tokens) - start_offset <span class="comment"># å‰©ä½™æœªåˆ’åˆ†æˆ doc_span çš„ tokens é•¿åº¦</span></span><br><span class="line">      <span class="keyword">if</span> length &gt; max_tokens_for_doc:</span><br><span class="line">        length = max_tokens_for_doc</span><br><span class="line">      doc_spans.append(_DocSpan(start=start_offset, length=length))</span><br><span class="line">      <span class="keyword">if</span> start_offset + length == len(all_doc_tokens):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      start_offset += min(length, doc_stride) </span><br><span class="line">		</span><br><span class="line">    <span class="comment"># å¯¹äºæ¯ä¸ªçª—å£ doc_spanï¼Œæ„å»ºæ‹¼æ¥çš„è¾“å…¥ [['CLS'] query_tokens ['SEP'] doc_span_text ['SEP']] </span></span><br><span class="line">    <span class="keyword">for</span> (doc_span_index, doc_span) <span class="keyword">in</span> enumerate(doc_spans):</span><br><span class="line">      tokens = []</span><br><span class="line">      token_to_orig_map = &#123;&#125;</span><br><span class="line">      token_is_max_context = &#123;&#125;</span><br><span class="line">      segment_ids = []</span><br><span class="line">      <span class="comment"># '[CLS]' query '[SEP]'</span></span><br><span class="line">      tokens.append(<span class="string">"[CLS]"</span>)</span><br><span class="line">      segment_ids.append(<span class="number">0</span>)</span><br><span class="line">      <span class="keyword">for</span> token <span class="keyword">in</span> query_tokens:</span><br><span class="line">        tokens.append(token)</span><br><span class="line">        segment_ids.append(<span class="number">0</span>)</span><br><span class="line">      tokens.append(<span class="string">"[SEP]"</span>)</span><br><span class="line">      segment_ids.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> range(doc_span.length):</span><br><span class="line">        split_token_index = doc_span.start + i <span class="comment"># å½“å‰ token åœ¨ all_doc_tokens[] ä¸­çš„ä½ç½®</span></span><br><span class="line">        token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]</span><br><span class="line"></span><br><span class="line">        is_max_context = _check_is_max_context(doc_spans, doc_span_index,</span><br><span class="line">                                               split_token_index)</span><br><span class="line">        token_is_max_context[len(tokens)] = is_max_context <span class="comment"># å½“å‰ span æ˜¯å¦æ˜¯å½“å‰ token çš„æœ€ä½³ context</span></span><br><span class="line">        tokens.append(all_doc_tokens[split_token_index])</span><br><span class="line">        segment_ids.append(<span class="number">1</span>)</span><br><span class="line">      tokens.append(<span class="string">"[SEP]"</span>)</span><br><span class="line">      segment_ids.append(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      input_ids = tokenizer.convert_tokens_to_ids(tokens) </span><br><span class="line"></span><br><span class="line">      <span class="comment"># mask=1 è¡¨ç¤ºçœŸå® tokenï¼Œéœ€è¦è¢« attend åˆ°</span></span><br><span class="line">      input_mask = [<span class="number">1</span>] * len(input_ids)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Zero-pad up to the sequence length.</span></span><br><span class="line">      <span class="keyword">while</span> len(input_ids) &lt; max_seq_length:</span><br><span class="line">        input_ids.append(<span class="number">0</span>)</span><br><span class="line">        input_mask.append(<span class="number">0</span>)</span><br><span class="line">        segment_ids.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">assert</span> len(input_ids) == max_seq_length</span><br><span class="line">      <span class="keyword">assert</span> len(input_mask) == max_seq_length</span><br><span class="line">      <span class="keyword">assert</span> len(segment_ids) == max_seq_length</span><br><span class="line"></span><br><span class="line">      start_position = <span class="literal">None</span></span><br><span class="line">      end_position = <span class="literal">None</span></span><br><span class="line">      <span class="keyword">if</span> is_training <span class="keyword">and</span> <span class="keyword">not</span> example.is_impossible:</span><br><span class="line">        <span class="comment"># For training, if our document chunk does not contain an annotation</span></span><br><span class="line">        <span class="comment"># we throw it out, since there is nothing to predict.</span></span><br><span class="line">        doc_start = doc_span.start</span><br><span class="line">        doc_end = doc_span.start + doc_span.length - <span class="number">1</span></span><br><span class="line">        out_of_span = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># answer æ²¡æœ‰è¢«å®Œæ•´åŒ…å«åœ¨å½“å‰ span ä¸­</span></span><br><span class="line">        <span class="comment"># ä¼šä¸ä¼š answer åœ¨ç›¸é‚» doc_span ä¸­éƒ½æ°å¥½æ²¡æœ‰å®Œå…¨åŒ…å«ï¼Ÿï¼Ÿ</span></span><br><span class="line">        <span class="comment"># åº”è¯¥éœ€è¦ doc_stride &lt;&lt; max_tokens_for_doc</span></span><br><span class="line">        <span class="comment"># ä¾‹å¦‚ï¼šanswer = [token1 token2 token3]</span></span><br><span class="line">        <span class="comment"># å½“å‰çš„span: [... token1 token2] token3 token4...</span></span><br><span class="line">        <span class="comment"># ä¸‹ä¸€ä¸ªspan: ... token1 [token2 token3 token4...] ...</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> (tok_start_position &gt;= doc_start <span class="keyword">and</span></span><br><span class="line">                tok_end_position &lt;= doc_end):</span><br><span class="line">          out_of_span = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> out_of_span:</span><br><span class="line">          start_position = <span class="number">0</span></span><br><span class="line">          end_position = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          doc_offset = len(query_tokens) + <span class="number">2</span> <span class="comment"># '[CLS]' query '[SEP]'</span></span><br><span class="line">          start_position = tok_start_position - doc_start + doc_offset <span class="comment"># åœ¨å½“å‰æ‹¼æ¥çš„è¾“å…¥ä¸­çš„ä½ç½®</span></span><br><span class="line">          end_position = tok_end_position - doc_start + doc_offset</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> is_training <span class="keyword">and</span> example.is_impossible: <span class="comment"># squad v2.0</span></span><br><span class="line">        start_position = <span class="number">0</span></span><br><span class="line">        end_position = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> example_index &lt; <span class="number">20</span>:</span><br><span class="line">        tf.logging.info(...)</span><br><span class="line"></span><br><span class="line">      feature = InputFeatures(...)</span><br><span class="line">      <span class="comment"># å›è°ƒå‡½æ•°ï¼Œé€šè¿‡ FeatureWriter å†™å…¥åˆ° TFRecord æ–‡ä»¶ä¸­</span></span><br><span class="line">      output_fn(feature)</span><br><span class="line"></span><br><span class="line">      unique_id += <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>_improve_answer_span</p>
<p>ç»è¿‡ WordPiece åˆ†è¯åï¼Œå¯ä»¥å¾—åˆ°æ›´ç²¾å‡†çš„ç­”æ¡ˆèµ·å§‹ä½ç½®</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_improve_answer_span</span><span class="params">(doc_tokens, input_start, input_end, tokenizer,</span></span></span><br><span class="line"><span class="function"><span class="params">                         orig_answer_text)</span>:</span></span><br><span class="line">  <span class="string">"""Returns tokenized answer spans that better match the annotated answer."""</span></span><br><span class="line">  <span class="comment">#   Question: What year was John Smith born?</span></span><br><span class="line">  <span class="comment">#   Context: The leader was John Smith (1895-1943).</span></span><br><span class="line">  <span class="comment">#   Answer: 1895</span></span><br><span class="line">  <span class="comment"># orig_answer_text å¯èƒ½åªæ˜¯Contextä¸­ token çš„ä¸€éƒ¨åˆ†ï¼Œç»è¿‡ WordPiece åˆ†è¯åï¼Œå¯ä»¥æœ‰æ›´ç²¾å‡†çš„ä½ç½®</span></span><br><span class="line">  </span><br><span class="line">  tok_answer_text = <span class="string">" "</span>.join(tokenizer.tokenize(orig_answer_text))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> new_start <span class="keyword">in</span> range(input_start, input_end + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> new_end <span class="keyword">in</span> range(input_end, new_start - <span class="number">1</span>, <span class="number">-1</span>):</span><br><span class="line">      text_span = <span class="string">" "</span>.join(doc_tokens[new_start:(new_end + <span class="number">1</span>)])</span><br><span class="line">      <span class="keyword">if</span> text_span == tok_answer_text:</span><br><span class="line">        <span class="keyword">return</span> (new_start, new_end)</span><br><span class="line">  </span><br><span class="line">	<span class="keyword">return</span> (input_start, input_end)</span><br></pre></td></tr></table></figure>
</li>
<li><p>FeatureWriter</p>
<p>å°† InputFeature å†™å…¥åˆ° TFRecords æ–‡ä»¶ï¼Œéœ€è¦å°†æ¯ä¸€ä¸ªæ ·æœ¬æ•°æ®å°è£…ä¸ºtf.train.Exampleæ ¼å¼ï¼Œå†å°†Exampleé€ä¸ªå†™å…¥æ–‡ä»¶ã€‚</p>
<p>tf.train.Feature()çš„å‚æ•°æ˜¯BytesList, FloatList, Int64Listä¸‰ç§ã€‚</p>
<p>tf.train.Features: å®ƒçš„å‚æ•°æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œk-vå¯¹ä¸­ v çš„ç±»å‹æ˜¯Featureï¼Œå¯¹åº”æ¯ä¸€ä¸ªå­—æ®µã€‚</p>
<p>æµç¨‹ï¼šå°†æ¯ä¸€ä¸ªå­—æ®µæ˜ å°„ Feature -&gt; å¤šä¸ªFeatureç»„æˆFeatures -&gt; å°†å…¶å°è£…ä¸º tf.train.Example å°±å¯ä»¥å†™å…¥ tfrecordsäºŒè¿›åˆ¶æ–‡ä»¶äº†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureWriter</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Writes InputFeature to TF example file."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename, is_training)</span>:</span></span><br><span class="line">    self.filename = filename</span><br><span class="line">    self.is_training = is_training</span><br><span class="line">    self.num_features = <span class="number">0</span></span><br><span class="line">    self._writer = tf.python_io.TFRecordWriter(filename) <span class="comment"># å°† records å†™å…¥åˆ° TFRecords æ–‡ä»¶</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># å°† InputFeature è§£ææˆ tf.train.Example å†™å…¥åˆ° tfrecords æ–‡ä»¶</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">process_feature</span><span class="params">(self, feature)</span>:</span></span><br><span class="line">    <span class="string">"""Write a InputFeature to the TFRecordWriter as a tf.train.Example."""</span></span><br><span class="line">    self.num_features += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_int_feature</span><span class="params">(values)</span>:</span></span><br><span class="line">      <span class="comment"># ä¸‰ç§åŸºç¡€æ•°æ®ç±»å‹ï¼šbytesï¼Œfloatï¼Œint64</span></span><br><span class="line">			<span class="comment"># å¯¹åº”tf.trainä¸­ä¸‰ç§ç±»å‹ï¼šBytesList(å­—ç¬¦ä¸²åˆ—è¡¨), FloatList(æµ®ç‚¹æ•°åˆ—è¡¨), Int64List(64ä½æ•´æ•°åˆ—è¡¨)</span></span><br><span class="line">      feature = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))</span><br><span class="line">      <span class="keyword">return</span> feature</span><br><span class="line"></span><br><span class="line">    features = collections.OrderedDict()</span><br><span class="line">    features[<span class="string">"unique_ids"</span>] = create_int_feature([feature.unique_id])</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=features))</span><br><span class="line">    self._writer.write(tf_example.SerializeToString())</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">    self._writer.close()</span><br></pre></td></tr></table></figure>
</li>
<li><p>_check_is_max_context</p>
<p>æ£€æŸ¥å½“å‰ doc_span æ˜¯ä¸æ˜¯æŸä¸ª position çš„å·¦&amp;å³context æœ€ä¸°å¯Œçš„ span</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_check_is_max_context</span><span class="params">(doc_spans, cur_span_index, position)</span>:</span></span><br><span class="line">  <span class="string">"""Check if this is the 'max context' doc span for the token."""</span></span><br><span class="line">	<span class="comment"># ç”¨æ¥ç»™å½“å‰ position é€‰æ‹©å‡º å·¦&amp;å³context æœ€ä¸°å¯Œçš„ span</span></span><br><span class="line">  <span class="comment"># Because of the sliding window approach taken to scoring documents, a single</span></span><br><span class="line">  <span class="comment"># token can appear in multiple documents. E.g.</span></span><br><span class="line">  <span class="comment">#  Doc: the man went to the store and bought a gallon of milk</span></span><br><span class="line">  <span class="comment">#  Span A: the man went to the</span></span><br><span class="line">  <span class="comment">#  Span B: to the store and bought</span></span><br><span class="line">  <span class="comment">#  Span C: and bought a gallon of</span></span><br><span class="line">  <span class="comment">#  ...</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># Now the word 'bought' will have two scores from spans B and C. We only</span></span><br><span class="line">  <span class="comment"># want to consider the score with "maximum context", which we define as</span></span><br><span class="line">  <span class="comment"># the *minimum* of its left and right context (the *sum* of left and</span></span><br><span class="line">  <span class="comment"># right context will always be the same, of course).</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># In the example the maximum context for 'bought' would be span C since</span></span><br><span class="line">  <span class="comment"># it has 1 left context and 3 right context, while span B has 4 left context</span></span><br><span class="line">  <span class="comment"># and 0 right context.</span></span><br><span class="line"> </span><br><span class="line">  best_score = <span class="literal">None</span></span><br><span class="line">  best_span_index = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">for</span> (span_index, doc_span) <span class="keyword">in</span> enumerate(doc_spans):</span><br><span class="line">    end = doc_span.start + doc_span.length - <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> position &lt; doc_span.start:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> position &gt; end:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    num_left_context = position - doc_span.start</span><br><span class="line">    num_right_context = end - position</span><br><span class="line">    <span class="comment"># åŠ å¹³æ»‘é¡¹ï¼Œå€¾å‘äºé€‰æ‹©é•¿ spanï¼Œcontext æ›´ä¸°å¯Œ</span></span><br><span class="line">    score = min(num_left_context, num_right_context) + <span class="number">0.01</span> * doc_span.length </span><br><span class="line">    <span class="keyword">if</span> best_score <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> score &gt; best_score:</span><br><span class="line">      best_score = score</span><br><span class="line">      best_span_index = span_index</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> cur_span_index == best_span_index</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Estimator</strong></p>
<ul>
<li><p>create_model</p>
<p> åˆ›å»ºåºåˆ—åˆ†ç±»æ¨¡å‹</p>
<p>å¼•å…¥ start vector <script type="math/tex">S \in \mathbb{R}^{H}</script>ï¼Œparagraph ä¸­ç¬¬ <script type="math/tex">i</script> ä¸ªä½ç½®æ˜¯ start_position çš„æ¦‚ç‡ä¸º <script type="math/tex">P_{i}=\frac{e^{S \cdot T_{i}}}{\sum_{j} e^{S \cdot T_{j}}}</script>ï¼Œend_position åŒç†ã€‚</p>
<p>æœ¬å‡½æ•°ä½¿ç”¨ BERT æœ€å hidden å±‚è¾“å‡ºï¼Œæ˜ å°„ä¸º start vector å’Œ end vector ä¸¤ä¸ªå‘é‡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(bert_config, is_training, input_ids, input_mask, segment_ids,</span></span></span><br><span class="line"><span class="function"><span class="params">                 use_one_hot_embeddings)</span>:</span></span><br><span class="line">  </span><br><span class="line">  model = modeling.BertModel(...)</span><br><span class="line"></span><br><span class="line">  final_hidden = model.get_sequence_output() <span class="comment"># BERT æœ€å hidden å±‚è¾“å‡º</span></span><br><span class="line"></span><br><span class="line">  final_hidden_shape = modeling.get_shape_list(final_hidden, expected_rank=<span class="number">3</span>)</span><br><span class="line">  (batch_size, seq_length, hidden_size) = final_hidden_shape</span><br><span class="line"></span><br><span class="line">  output_weights = tf.get_variable(</span><br><span class="line">      <span class="string">"cls/squad/output_weights"</span>, [<span class="number">2</span>, hidden_size], <span class="comment"># start vector å’Œ end vector ä¸¤ä¸ªå‘é‡</span></span><br><span class="line">      initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.02</span>))</span><br><span class="line">  output_bias = tf.get_variable(</span><br><span class="line">      <span class="string">"cls/squad/output_bias"</span>, [<span class="number">2</span>], initializer=tf.zeros_initializer())</span><br><span class="line"></span><br><span class="line">  final_hidden_matrix = tf.reshape(final_hidden,</span><br><span class="line">                                   [batch_size * seq_length, hidden_size])</span><br><span class="line">  logits = tf.matmul(final_hidden_matrix, output_weights, transpose_b=<span class="literal">True</span>)</span><br><span class="line">  logits = tf.nn.bias_add(logits, output_bias) <span class="comment"># [batch_size * seq_length, 2]</span></span><br><span class="line"></span><br><span class="line">  logits = tf.reshape(logits, [batch_size, seq_length, <span class="number">2</span>]) <span class="comment"># [batch_size, seq_length, 2]</span></span><br><span class="line">  logits = tf.transpose(logits, [<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]) <span class="comment"># # [2, batch_size * seq_length]</span></span><br><span class="line">	</span><br><span class="line">  <span class="comment"># start vector: [batch_size * seq_length]</span></span><br><span class="line">  <span class="comment"># end vector: [batch_size * seq_length]</span></span><br><span class="line">  unstacked_logits = tf.unstack(logits, axis=<span class="number">0</span>)</span><br><span class="line">  (start_logits, end_logits) = (unstacked_logits[<span class="number">0</span>], unstacked_logits[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (start_logits, end_logits)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>model_fn_builder</p>
<p>åˆ›å»ºæ¨¡å‹å‡½æ•°</p>
<table><img src="/bert-squad-tf/image-20190703085937162.png" width="70%" align="left"></table>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn_builder</span><span class="params">(bert_config, </span></span></span><br><span class="line"><span class="function"><span class="params">                     init_checkpoint, </span></span></span><br><span class="line"><span class="function"><span class="params">                     learning_rate,</span></span></span><br><span class="line"><span class="function"><span class="params">                     num_train_steps, </span></span></span><br><span class="line"><span class="function"><span class="params">                     num_warmup_steps, </span></span></span><br><span class="line"><span class="function"><span class="params">                     use_tpu,</span></span></span><br><span class="line"><span class="function"><span class="params">                     use_one_hot_embeddings)</span>:</span></span><br><span class="line">  <span class="string">"""Returns `model_fn` closure for TPUEstimator."""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># å‰ä¸¤ä¸ªå‚æ•°æ˜¯ä»è¾“å…¥å‡½æ•°ä¸­è¿”å›çš„ç‰¹å¾å’Œæ ‡ç­¾batch</span></span><br><span class="line">  <span class="comment"># mode å‚æ•°è¡¨ç¤ºè°ƒç”¨ç¨‹åºæ˜¯è¯·æ±‚è®­ç»ƒã€é¢„æµ‹è¿˜æ˜¯è¯„ä¼°</span></span><br><span class="line">  <span class="comment"># params: é¢å¤–å‚æ•°ã€‚è°ƒç”¨ç¨‹åºå¯ä»¥å°† params ä¼ é€’ç»™ Estimator çš„æ„é€ å‡½æ•°ã€‚</span></span><br><span class="line">  <span class="comment"># ä¼ é€’ç»™æ„é€ å‡½æ•°çš„æ‰€æœ‰ params è½¬è€Œåˆä¼ é€’ç»™ model_fnã€‚</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  def my_model_fn(</span></span><br><span class="line"><span class="string">          features, # This is batch_features from input_fn</span></span><br><span class="line"><span class="string">          labels,   # This is batch_labels from input_fn</span></span><br><span class="line"><span class="string">          mode,     # An instance of tf.estimator.ModeKeys, see below</span></span><br><span class="line"><span class="string">          params):  # Additional configuration</span></span><br><span class="line"><span class="string">  å½“æœ‰äººè°ƒç”¨ train()ã€evaluate() æˆ– predict() æ—¶ï¼ŒEstimator æ¡†æ¶ä¼š è°ƒç”¨æ¨¡å‹å‡½æ•° å¹¶å°† mode å‚æ•°è®¾ç½®ä¸ºå¦‚ä¸‹æ‰€ç¤ºçš„å€¼ï¼š</span></span><br><span class="line"><span class="string">    Estimatoræ–¹æ³•	Estimator æ¨¡å¼  	è¿”å›</span></span><br><span class="line"><span class="string">    train()			 ModeKeys.TRAIN		 EstimatorSpec(mode, loss, train_op)</span></span><br><span class="line"><span class="string">    evaluate()	 ModeKeys.EVAL		 EstimatorSpec(mode, loss, eval_metric_ops)</span></span><br><span class="line"><span class="string">    predict()		 ModeKeys.PREDICT	 EstimatorSpec(mode, predictions)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  å¯¹äºæ¯ä¸ª mode å€¼ï¼Œéƒ½å¿…é¡»è¿”å› tf.estimator.EstimatorSpec çš„ä¸€ä¸ªå®ä¾‹ï¼Œå…¶ä¸­åŒ…å«è°ƒç”¨ç¨‹åºæ‰€éœ€çš„ä¿¡æ¯ã€‚</span></span><br><span class="line"><span class="string">  EstimatorSpecï¼šOps and objects returned from a model_fn and passed to an Estimator</span></span><br><span class="line"><span class="string">  EstimatorSpec **fully** defines the model to be run by an Estimator.</span></span><br><span class="line"><span class="string">  tf.summary.scalar ä¼šåœ¨ TRAIN å’Œ EVAL æ¨¡å¼ä¸‹å‘ TensorBoard æä¾›å‡†ç¡®ç‡</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># æ ¹æ®è¿è¡Œæ¨¡å¼ï¼Œåˆ›å»ºå¹¶è¿”å›ä¸åŒçš„ EstimatorSpec </span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode, params)</span>:</span>   <span class="comment"># params example: &#123;'batch_size': 12, 'use_tpu': False&#125;</span></span><br><span class="line">    <span class="string">"""The `model_fn` for TPUEstimator."""</span></span><br><span class="line">    ...</span><br><span class="line">    unique_ids = features[<span class="string">"unique_ids"</span>] <span class="comment"># Tensor("IteratorGetNext:5", shape=(12,), dtype=int32)</span></span><br><span class="line">    input_ids = features[<span class="string">"input_ids"</span>] <span class="comment"># Tensor("IteratorGetNext:1", shape=(12, 384), dtype=int32)</span></span><br><span class="line">    input_mask = features[<span class="string">"input_mask"</span>] <span class="comment"># Tensor("IteratorGetNext:2", shape=(12, 384), dtype=int32)</span></span><br><span class="line">    segment_ids = features[<span class="string">"segment_ids"</span>] <span class="comment"># Tensor("IteratorGetNext:3", shape=(12, 384), dtype=int32)</span></span><br><span class="line"></span><br><span class="line">    is_training = (mode == tf.estimator.ModeKeys.TRAIN) <span class="comment"># è¿è¡Œæ¨¡å¼</span></span><br><span class="line"></span><br><span class="line">    (start_logits, end_logits) = create_model(...)</span><br><span class="line"></span><br><span class="line">    tvars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">    initialized_variable_names = &#123;&#125;</span><br><span class="line">    <span class="comment"># é€šè¿‡ tf.Scaffold è‡ªå®šä¹‰ variable initialization</span></span><br><span class="line">    <span class="comment"># ä½œä¸º Scaffold å‚æ•°ä¼ ç»™ EstimatorSpec çš„æ„é€ å‡½æ•°</span></span><br><span class="line">    scaffold_fn = <span class="literal">None</span> </span><br><span class="line">    <span class="keyword">if</span> init_checkpoint:</span><br><span class="line">      (assignment_map, initialized_variable_names</span><br><span class="line">      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)</span><br><span class="line">      <span class="keyword">if</span> use_tpu:</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">tpu_scaffold</span><span class="params">()</span>:</span></span><br><span class="line">          <span class="comment"># Replaces tf.Variable initializers so they load from a checkpoint file.</span></span><br><span class="line">          tf.train.init_from_checkpoint(init_checkpoint, assignment_map) <span class="comment"># </span></span><br><span class="line">          <span class="keyword">return</span> tf.train.Scaffold()</span><br><span class="line"></span><br><span class="line">        scaffold_fn = tpu_scaffold</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)</span><br><span class="line"></span><br><span class="line">    tf.logging.info(<span class="string">"**** Trainable Variables ****"</span>)</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    output_spec = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> mode == tf.estimator.ModeKeys.TRAIN:</span><br><span class="line">      seq_length = modeling.get_shape_list(input_ids)[<span class="number">1</span>]</span><br><span class="line">			</span><br><span class="line">      <span class="comment"># ä½¿ç”¨ cross-entropy / negative-log-likelihood è®¡ç®— loss</span></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span><span class="params">(logits, positions)</span>:</span></span><br><span class="line">        one_hot_positions = tf.one_hot(</span><br><span class="line">            positions, depth=seq_length, dtype=tf.float32)</span><br><span class="line">        log_probs = tf.nn.log_softmax(logits, axis=<span class="number">-1</span>)</span><br><span class="line">        loss = -tf.reduce_mean(</span><br><span class="line">            tf.reduce_sum(one_hot_positions * log_probs, axis=<span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">      start_positions = features[<span class="string">"start_positions"</span>]</span><br><span class="line">      end_positions = features[<span class="string">"end_positions"</span>]</span><br><span class="line">			<span class="comment"># è®¡ç®— loss</span></span><br><span class="line">      start_loss = compute_loss(start_logits, start_positions)</span><br><span class="line">      end_loss = compute_loss(end_logits, end_positions)</span><br><span class="line">      total_loss = (start_loss + end_loss) / <span class="number">2.0</span></span><br><span class="line">			<span class="comment"># Creates an optimizer training op</span></span><br><span class="line">      train_op = optimization.create_optimizer( </span><br><span class="line">          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)</span><br><span class="line"></span><br><span class="line">      output_spec = tf.contrib.tpu.TPUEstimatorSpec(</span><br><span class="line">          mode=mode,</span><br><span class="line">          loss=total_loss,</span><br><span class="line">          train_op=train_op,</span><br><span class="line">          scaffold_fn=scaffold_fn)</span><br><span class="line">    <span class="keyword">elif</span> mode == tf.estimator.ModeKeys.PREDICT: <span class="comment"># é¢„æµ‹</span></span><br><span class="line">      predictions = &#123;</span><br><span class="line">          <span class="string">"unique_ids"</span>: unique_ids,</span><br><span class="line">          <span class="string">"start_logits"</span>: start_logits,</span><br><span class="line">          <span class="string">"end_logits"</span>: end_logits,</span><br><span class="line">      &#125;</span><br><span class="line">      output_spec = tf.contrib.tpu.TPUEstimatorSpec(</span><br><span class="line">          mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(</span><br><span class="line">          <span class="string">"Only TRAIN and PREDICT modes are supported: %s"</span> % (mode))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output_spec</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model_fn</span><br></pre></td></tr></table></figure>
</li>
<li><p>input_fn_builder</p>
<p>åˆ›å»ºè¾“å…¥å‡½æ•°</p>
<p>Tensorflow çš„ Dataset API åŒ…å«ä¸‹åˆ—ç±»ï¼š</p>
<table>
<img src="/bert-squad-tf/image-20190702102852057.png" width="50%" align="left">
</table>

<ul>
<li><code>Dataset</code> - åŒ…å«åˆ›å»ºå’Œè½¬æ¢æ•°æ®é›†çš„æ–¹æ³•çš„åŸºç±»ã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡è¯¥ç±»ä»å†…å­˜ä¸­çš„æ•°æ®æˆ– Python ç”Ÿæˆå™¨åˆå§‹åŒ–æ•°æ®é›†ã€‚</li>
</ul>
</li>
<li><code>TextLineDataset</code> - ä»æ–‡æœ¬æ–‡ä»¶ä¸­è¯»å–è¡Œã€‚<ul>
<li><code>TFRecordDataset</code> - ä» TFRecord æ–‡ä»¶ä¸­è¯»å–è®°å½•ã€‚ï¼ˆæˆ‘ä»¬è¿™é‡Œä½¿ç”¨ï¼‰</li>
</ul>
</li>
<li><p><code>FixedLengthRecordDataset</code> - ä»äºŒè¿›åˆ¶æ–‡ä»¶ä¸­è¯»å–å…·æœ‰å›ºå®šå¤§å°çš„è®°å½•ã€‚</p>
<ul>
<li><code>Iterator</code> - æä¾›ä¸€æ¬¡è®¿é—®ä¸€ä¸ªæ•°æ®é›†å…ƒç´ çš„æ–¹æ³•</li>
</ul>
<p>åˆ›å»ºè¾“å…¥å‡½æ•°æµç¨‹ï¼š</p>
<p>â€‹    å®šä¹‰å¾…mapçš„ features -&gt; å®ä¾‹åŒ–TFRecordDatasetå¯¹è±¡ï¼Œä»TFRecord æ–‡ä»¶ä¸­è¯»å–è®°å½• -&gt; repeat &amp; shuffle -&gt; å°† record mapåˆ° featuresï¼Œæ„å»ºbatch</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn_builder</span><span class="params">(input_file, seq_length, is_training, drop_remainder)</span>:</span></span><br><span class="line">  <span class="string">"""Creates an `input_fn` closure to be passed to TPUEstimator."""</span></span><br><span class="line"></span><br><span class="line">  name_to_features = &#123;</span><br><span class="line">  	<span class="comment"># tf.FixedLenFeature: Configuration for parsing a fixed-length input feature.</span></span><br><span class="line">    	<span class="comment"># è¿”å›ä¸€ä¸ªå®šé•¿çš„tensor</span></span><br><span class="line">    <span class="string">"unique_ids"</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">      <span class="string">"input_ids"</span>: tf.FixedLenFeature([seq_length], tf.int64),</span><br><span class="line">    <span class="string">"input_mask"</span>: tf.FixedLenFeature([seq_length], tf.int64),</span><br><span class="line">      <span class="string">"segment_ids"</span>: tf.FixedLenFeature([seq_length], tf.int64),</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> is_training:</span><br><span class="line">    name_to_features[<span class="string">"start_positions"</span>] = tf.FixedLenFeature([], tf.int64)</span><br><span class="line">    name_to_features[<span class="string">"end_positions"</span>] = tf.FixedLenFeature([], tf.int64)</span><br><span class="line">	</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_decode_record</span><span class="params">(record, name_to_features)</span>:</span></span><br><span class="line">    <span class="string">"""Decodes a record to a TensorFlow example."""</span></span><br><span class="line">    <span class="comment"># è¿”å›ä¸€ä¸ª feature keys åˆ° `Tensor`çš„ dict</span></span><br><span class="line">    example = tf.parse_single_example(record, name_to_features)</span><br><span class="line">    ... <span class="comment"># tf.int64 -&gt; tf.int32ï¼Œå®ç°TPU å…¼å®¹</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(params)</span>:</span></span><br><span class="line">    <span class="string">"""The actual input function."""</span></span><br><span class="line">    batch_size = params[<span class="string">"batch_size"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For training, we want a lot of parallel reading and shuffling.</span></span><br><span class="line">    <span class="comment"># For eval, we want no shuffling and parallel reading doesn't matter.</span></span><br><span class="line">    d = tf.data.TFRecordDataset(input_file) <span class="comment"># ä» TFRecord æ–‡ä»¶ä¸­è¯»å–è®°å½•</span></span><br><span class="line">    <span class="keyword">if</span> is_training:</span><br><span class="line">      d = d.repeat()</span><br><span class="line">      d = d.shuffle(buffer_size=<span class="number">100</span>)</span><br><span class="line">		</span><br><span class="line">    <span class="comment"># tf.data.Dataset.apply(transformation_func)</span></span><br><span class="line">    <span class="comment"># å°†ç”¨æˆ·è‡ªå®šä¹‰çš„è½¬æ¢å‡½æ•°åº”ç”¨äºå½“å‰æ•°æ®é›†</span></span><br><span class="line">    <span class="comment"># tf.contrib.data.map_and_batch å¯¹æ•°æ®é›†çš„ batch_size ä¸ªè¿ç»­å…ƒç´ ï¼Œå…ˆ map å batch</span></span><br><span class="line">    d = d.apply(</span><br><span class="line">        tf.contrib.data.map_and_batch(</span><br><span class="line">            <span class="keyword">lambda</span> record: _decode_record(record, name_to_features),</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            drop_remainder=drop_remainder)) <span class="comment"># é»˜è®¤ Falseï¼Œæœ€åä¸€ä¸ª batch é•¿åº¦å°äº batch_size ä¸ä¸¢å¼ƒ</span></span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> input_fn</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>write_predictions </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_predictions</span><span class="params">(all_examples, all_features, all_results, n_best_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                      max_answer_length, do_lower_case, output_prediction_file,</span></span></span><br><span class="line"><span class="function"><span class="params">                      output_nbest_file, output_null_log_odds_file)</span>:</span></span><br><span class="line">  <span class="string">"""Write final predictions to the json file and log-odds of null if needed."""</span></span><br><span class="line"></span><br><span class="line">  example_index_to_features = collections.defaultdict(list)</span><br><span class="line">  <span class="keyword">for</span> feature <span class="keyword">in</span> all_features: <span class="comment"># InputFeatures</span></span><br><span class="line">    example_index_to_features[feature.example_index].append(feature)</span><br><span class="line"></span><br><span class="line">  unique_id_to_result = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> result <span class="keyword">in</span> all_results: <span class="comment"># RawResult(unique_id,start_logits,end_logits)</span></span><br><span class="line">    unique_id_to_result[result.unique_id] = result</span><br><span class="line"></span><br><span class="line">  _PrelimPrediction = collections.namedtuple(</span><br><span class="line">      <span class="string">"PrelimPrediction"</span>,</span><br><span class="line">      [<span class="string">"feature_index"</span>, <span class="string">"start_index"</span>, <span class="string">"end_index"</span>, <span class="string">"start_logit"</span>, <span class="string">"end_logit"</span>])</span><br><span class="line"></span><br><span class="line">  all_predictions = collections.OrderedDict()</span><br><span class="line">  all_nbest_json = collections.OrderedDict()</span><br><span class="line">  scores_diff_json = collections.OrderedDict()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (example_index, example) <span class="keyword">in</span> enumerate(all_examples): <span class="comment"># SquadExample</span></span><br><span class="line">    features = example_index_to_features[example_index] <span class="comment"># å½“å‰ SquadExample å¯¹åº”çš„ features</span></span><br><span class="line"></span><br><span class="line">    prelim_predictions = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># è·Ÿè¸ª answer ä¸å­˜åœ¨çš„æ—¶å€™çš„æœ€å° socre</span></span><br><span class="line">    score_null = <span class="number">1000000</span>  <span class="comment"># large and positive</span></span><br><span class="line">    min_null_feature_index = <span class="number">0</span>  <span class="comment"># the paragraph slice with min mull score</span></span><br><span class="line">    null_start_logit = <span class="number">0</span>  <span class="comment"># the start logit at the slice with min null score</span></span><br><span class="line">    null_end_logit = <span class="number">0</span>  <span class="comment"># the end logit at the slice with min null score</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (feature_index, feature) <span class="keyword">in</span> enumerate(features): <span class="comment"># ä¸€ä¸ª SquadExample å¯ä»¥è§£æå‡ºä¸€ä¸ªæˆ–å¤šä¸ª features</span></span><br><span class="line">      result = unique_id_to_result[feature.unique_id]</span><br><span class="line">      start_indexes = _get_best_indexes(result.start_logits, n_best_size)</span><br><span class="line">      end_indexes = _get_best_indexes(result.end_logits, n_best_size)</span><br><span class="line">      <span class="comment"># if we could have irrelevant answers, get the min score of irrelevant</span></span><br><span class="line">      <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">        <span class="comment"># å¯¹äº v2ï¼Œanswer ä¸å­˜åœ¨æ—¶ï¼Œstart_position = end_position = 0</span></span><br><span class="line">        feature_null_score = result.start_logits[<span class="number">0</span>] + result.end_logits[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> feature_null_score &lt; score_null:</span><br><span class="line">          score_null = feature_null_score</span><br><span class="line">          min_null_feature_index = feature_index</span><br><span class="line">          null_start_logit = result.start_logits[<span class="number">0</span>]</span><br><span class="line">          null_end_logit = result.end_logits[<span class="number">0</span>]</span><br><span class="line">      <span class="keyword">for</span> start_index <span class="keyword">in</span> start_indexes:</span><br><span class="line">        <span class="keyword">for</span> end_index <span class="keyword">in</span> end_indexes:</span><br><span class="line">          <span class="comment"># ä¸¢å¼ƒæ— æ•ˆçš„ index çš„æƒ…å†µï¼š</span></span><br><span class="line">          <span class="comment"># é¢„æµ‹åˆ°äº† pad ä½ç½®ã€é¢„æµ‹åˆ°äº† écontext çš„ä½ç½®</span></span><br><span class="line">          <span class="keyword">if</span> start_index &gt;= len(feature.tokens):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> end_index &gt;= len(feature.tokens):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> start_index <span class="keyword">not</span> <span class="keyword">in</span> feature.token_to_orig_map:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> end_index <span class="keyword">not</span> <span class="keyword">in</span> feature.token_to_orig_map:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="comment"># å½“å‰spanä¸æ˜¯ start_index çš„æœ€å¤§ä¸Šä¸‹æ–‡ ï¼ˆï¼Ÿä¸ºä»€ä¹ˆä¸å¤„ç†end_indexï¼‰</span></span><br><span class="line">          <span class="keyword">if</span> <span class="keyword">not</span> feature.token_is_max_context.get(start_index, <span class="literal">False</span>): </span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> end_index &lt; start_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          length = end_index - start_index + <span class="number">1</span></span><br><span class="line">          <span class="keyword">if</span> length &gt; max_answer_length:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          prelim_predictions.append( <span class="comment"># æš‚å­˜å¯èƒ½çš„ [start, end] ç»„åˆ</span></span><br><span class="line">              _PrelimPrediction(...))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">      prelim_predictions.append(</span><br><span class="line">          _PrelimPrediction(</span><br><span class="line">              feature_index=min_null_feature_index,</span><br><span class="line">              start_index=<span class="number">0</span>,</span><br><span class="line">              end_index=<span class="number">0</span>,</span><br><span class="line">              start_logit=null_start_logit,</span><br><span class="line">              end_logit=null_end_logit))</span><br><span class="line">    <span class="comment"># å¯¹æ‰€æœ‰å¯èƒ½çš„ [start, end] ç»„åˆæ’åº</span></span><br><span class="line">    <span class="comment"># logit çš„å¤§å°ä¼šç”¨äº softmax è®¡ç®—æ¦‚ç‡</span></span><br><span class="line">    <span class="comment"># e^start_logit * e^end_logit = e^(start_logit+end_logit) </span></span><br><span class="line">    prelim_predictions = sorted( </span><br><span class="line">        prelim_predictions,</span><br><span class="line">        key=<span class="keyword">lambda</span> x: (x.start_logit + x.end_logit),</span><br><span class="line">        reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    _NbestPrediction = collections.namedtuple(  <span class="comment"># pylint: disable=invalid-name</span></span><br><span class="line">        <span class="string">"NbestPrediction"</span>, [<span class="string">"text"</span>, <span class="string">"start_logit"</span>, <span class="string">"end_logit"</span>])</span><br><span class="line"></span><br><span class="line">    seen_predictions = &#123;&#125;</span><br><span class="line">    nbest = []</span><br><span class="line">    <span class="comment"># é€‰å‡ºå‰ n_best_size å¾—åˆ†çš„ [start, end] ç»„åˆ</span></span><br><span class="line">    <span class="keyword">for</span> pred <span class="keyword">in</span> prelim_predictions:</span><br><span class="line">      <span class="keyword">if</span> len(nbest) &gt;= n_best_size:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      feature = features[pred.feature_index]</span><br><span class="line">      <span class="comment"># å¯¹äº non-null çš„ answerï¼Œä» tokens æ¢å¤å‡º text</span></span><br><span class="line">      <span class="keyword">if</span> pred.start_index &gt; <span class="number">0</span>:  <span class="comment"># this is a non-null prediction</span></span><br><span class="line">        tok_tokens = feature.tokens[pred.start_index:(pred.end_index + <span class="number">1</span>)]</span><br><span class="line">        orig_doc_start = feature.token_to_orig_map[pred.start_index]</span><br><span class="line">        orig_doc_end = feature.token_to_orig_map[pred.end_index]</span><br><span class="line">        orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + <span class="number">1</span>)]</span><br><span class="line">        tok_text = <span class="string">" "</span>.join(tok_tokens)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># De-tokenize WordPieces å¾—åˆ°çš„æ˜¯ BasicTokenizer åˆ†è¯åçš„æ ¼å¼</span></span><br><span class="line">        tok_text = tok_text.replace(<span class="string">" ##"</span>, <span class="string">""</span>)</span><br><span class="line">        tok_text = tok_text.replace(<span class="string">"##"</span>, <span class="string">""</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Clean whitespace</span></span><br><span class="line">        tok_text = tok_text.strip()</span><br><span class="line">        tok_text = <span class="string">" "</span>.join(tok_text.split()) <span class="comment"># wordpiece tokens æ¢å¤å‡ºçš„ answer</span></span><br><span class="line">        orig_text = <span class="string">" "</span>.join(orig_tokens) <span class="comment"># åŸæ–‡çš„ answerï¼Œå¦‚ï¼š'(NFL) for the 2015 season. The American'</span></span><br><span class="line"></span><br><span class="line">        final_text = get_final_text(tok_text, orig_text, do_lower_case)</span><br><span class="line">        <span class="keyword">if</span> final_text <span class="keyword">in</span> seen_predictions:</span><br><span class="line">          <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        seen_predictions[final_text] = <span class="literal">True</span></span><br><span class="line">      <span class="comment"># å¯¹äº nullï¼Œ answer =""</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        final_text = <span class="string">""</span></span><br><span class="line">        seen_predictions[final_text] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">      nbest.append(</span><br><span class="line">          _NbestPrediction(</span><br><span class="line">              text=final_text,</span><br><span class="line">              start_logit=pred.start_logit,</span><br><span class="line">              end_logit=pred.end_logit))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># if we didn't inlude the empty option in the n-best, inlcude it</span></span><br><span class="line">    <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">      <span class="keyword">if</span> <span class="string">""</span> <span class="keyword">not</span> <span class="keyword">in</span> seen_predictions:</span><br><span class="line">        nbest.append(</span><br><span class="line">            _NbestPrediction(</span><br><span class="line">                text=<span class="string">""</span>, start_logit=null_start_logit,</span><br><span class="line">                end_logit=null_end_logit))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># In very rare edge cases we could have no valid predictions. So we</span></span><br><span class="line">    <span class="comment"># just create a nonce prediction in this case to avoid failure.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> nbest:</span><br><span class="line">      nbest.append(</span><br><span class="line">          _NbestPrediction(text=<span class="string">"empty"</span>, start_logit=<span class="number">0.0</span>, end_logit=<span class="number">0.0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> len(nbest) &gt;= <span class="number">1</span></span><br><span class="line">		</span><br><span class="line">    <span class="comment"># è®¡ç®—æ¯ä¸ª [start, end] ç»„åˆçš„æ¦‚ç‡</span></span><br><span class="line">    total_scores = []</span><br><span class="line">    best_non_null_entry = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> entry <span class="keyword">in</span> nbest:</span><br><span class="line">      total_scores.append(entry.start_logit + entry.end_logit)</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> best_non_null_entry:</span><br><span class="line">        <span class="keyword">if</span> entry.text:</span><br><span class="line">          best_non_null_entry = entry</span><br><span class="line"></span><br><span class="line">    probs = _compute_softmax(total_scores)</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">		</span><br><span class="line">    <span class="comment"># å¯¹äº v1ï¼Œå§‹ç»ˆå­˜åœ¨ answerï¼Œç›´æ¥å°†å¾—åˆ†æœ€é«˜çš„ä½œä¸ºè¾“å‡º</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> FLAGS.version_2_with_negative:</span><br><span class="line">      all_predictions[example.qas_id] = nbest_json[<span class="number">0</span>][<span class="string">"text"</span>]</span><br><span class="line">    <span class="comment"># å¯¹äº v2ï¼Œå¯èƒ½å­˜åœ¨æ‰¾ä¸åˆ° answerï¼Œæ ¹æ®ä»¥ä¸‹å…¬å¼æ˜¯å¦æˆç«‹æ¥ç¡®å®šè¾“å‡º</span></span><br><span class="line">    <span class="comment"># null score - the score of best non-null &gt; threshold</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      score_diff = score_null - best_non_null_entry.start_logit - (</span><br><span class="line">          best_non_null_entry.end_logit)</span><br><span class="line">      scores_diff_json[example.qas_id] = score_diff</span><br><span class="line">      <span class="keyword">if</span> score_diff &gt; FLAGS.null_score_diff_threshold:</span><br><span class="line">        all_predictions[example.qas_id] = <span class="string">""</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        all_predictions[example.qas_id] = best_non_null_entry.text</span><br><span class="line"></span><br><span class="line">    all_nbest_json[example.qas_id] = nbest_json</span><br><span class="line"></span><br><span class="line">  ... å†™å…¥æ–‡ä»¶</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_final_text</p>
<p>æˆ‘ä»¬å¯ä»¥åŒæ—¶å¾—åˆ°ä¸¤ç§ answer è¡¨ç¤ºï¼Œä¸€ç§æ˜¯åŸæ–‡ä¸­çš„ tokens ç›´æ¥æ¢å¤å‡ºæ¥çš„ orig_textï¼Œå¦ä¸€ç§æ˜¯ wordPiece çš„ subtokens å¯ä»¥æ¢å¤å‡ºçš„æ›´ç²¾ç¡®çš„ pred_textã€‚ å¦‚æœ pred_text èƒ½åœ¨ orig_text ä¸­å®šä½/å¯¹é½åˆ°ï¼Œé‚£ä¹ˆè¾“å‡ºæ›´ç²¾ç¡®çš„ pred_textã€‚å¦‚æœå› ä¸ºåˆ†è¯è¿‡ç¨‹å¸¦æ¥çš„å·®å¼‚ï¼Œå¯¼è‡´pred_text åœ¨åŸæ–‡ä¸­æ¢å¤ä¸å‡ºæ¥ï¼Œé‚£ä¹ˆç›´æ¥è¾“å‡º pred_textã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_final_text</span><span class="params">(pred_text, orig_text, do_lower_case)</span>:</span></span><br><span class="line">  <span class="string">"""Project the tokenized prediction back to the original text."""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># When we created the data, we kept track of the alignment between original</span></span><br><span class="line">  <span class="comment"># (whitespace tokenized) tokens and our WordPiece tokenized tokens. So</span></span><br><span class="line">  <span class="comment"># now `orig_text` contains the span of our original text corresponding to the</span></span><br><span class="line">  <span class="comment"># span that we predicted.</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># However, `orig_text` may contain extra characters that we don't want in</span></span><br><span class="line">  <span class="comment"># our prediction.</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># For example, let's say:</span></span><br><span class="line">  <span class="comment">#   pred_text = steve smith</span></span><br><span class="line">  <span class="comment">#   orig_text = Steve Smith's</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># We don't want to return `orig_text` because it contains the extra "'s".</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># We don't want to return `pred_text` because it's already been normalized</span></span><br><span class="line">  <span class="comment"># (the SQuAD eval script also does punctuation stripping/lower casing but</span></span><br><span class="line">  <span class="comment"># our tokenizer does additional normalization like stripping accent</span></span><br><span class="line">  <span class="comment"># characters).</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># What we really want to return is "Steve Smith".</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># Therefore, we have to apply a semi-complicated alignment heruistic between</span></span><br><span class="line">  <span class="comment"># `pred_text` and `orig_text` to get a character-to-charcter alignment. This</span></span><br><span class="line">  <span class="comment"># can fail in certain cases in which case we just return `orig_text`.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># å°†å­—ç¬¦ä¸² s ä¸­çš„ç©ºæ ¼å»æ‰å¾—åˆ° nsï¼Œå¹¶ä¸”å»ºç«‹ ns ç´¢å¼•åˆ° s ç´¢å¼•çš„æ˜ å°„</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_strip_spaces</span><span class="params">(text)</span>:</span></span><br><span class="line">    ns_chars = []</span><br><span class="line">    ns_to_s_map = collections.OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> (i, c) <span class="keyword">in</span> enumerate(text):</span><br><span class="line">      <span class="keyword">if</span> c == <span class="string">" "</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      ns_to_s_map[len(ns_chars)] = i</span><br><span class="line">      ns_chars.append(c)</span><br><span class="line">    ns_text = <span class="string">""</span>.join(ns_chars)</span><br><span class="line">    <span class="keyword">return</span> (ns_text, ns_to_s_map)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># We first tokenize `orig_text`, strip whitespace from the result</span></span><br><span class="line">  <span class="comment"># and `pred_text`, and check if they are the same length. If they are</span></span><br><span class="line">  <span class="comment"># NOT the same length, the heuristic has failed. If they are the same</span></span><br><span class="line">  <span class="comment"># length, we assume the characters are one-to-one aligned.</span></span><br><span class="line">  tokenizer = tokenization.BasicTokenizer(do_lower_case=do_lower_case)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ä¸¾ä¾‹ï¼šorig_text = '(NFL) for the 2015 season. The American'</span></span><br><span class="line">  <span class="comment">#       tok_text = '( nfl ) for the 2015 season . the american'</span></span><br><span class="line">  <span class="comment">#      pred_text = ') for the 2015 season . the american'</span></span><br><span class="line">  tok_text = <span class="string">" "</span>.join(tokenizer.tokenize(orig_text))</span><br><span class="line"></span><br><span class="line">  start_position = tok_text.find(pred_text)</span><br><span class="line">  <span class="comment"># pred_text ä¸åœ¨ BasicTokenizer å¤„ç†åçš„ orig_text ä¸­</span></span><br><span class="line">  <span class="comment"># pred_text ä¸­æœ‰ '[UNK]'è¿™æ ·çš„æƒ…å†µéœ€è¦è¿”å› orig_text</span></span><br><span class="line">  <span class="comment"># ä¸¾ä¾‹ï¼šorig_text = '(/táµ»ËˆnÉ’fÉ™rÉ™/; singular ctenophore,'</span></span><br><span class="line">  <span class="comment">#       tok_text = '( / táµ»ËˆnÉ’fÉ™rÉ™ / ; singular ctenophore ,'</span></span><br><span class="line">  <span class="comment">#      pred_text = '[UNK] / ; singular cteno'</span></span><br><span class="line">  <span class="keyword">if</span> start_position == <span class="number">-1</span>:</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(</span><br><span class="line">          <span class="string">"Unable to find text: '%s' in '%s'"</span> % (pred_text, orig_text))</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line">  </span><br><span class="line">  end_position = start_position + len(pred_text) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text) <span class="comment"># ä¾‹ '(NFL)forthe2015season.TheAmerican'</span></span><br><span class="line">  (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text) <span class="comment"># ä¾‹ '(nfl)forthe2015season.theamerican'</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># BasicTokenizer ä¼šå»æ‰ä¸€äº›éŸ³èŠ‚ä¹‹ç±»çš„ç¬¦å·ï¼Œå¯¼è‡´ orig_ns_text å’Œ tok_ns_text ä¸å¯¹é½</span></span><br><span class="line">  <span class="comment"># ä¸¾ä¾‹ï¼š </span></span><br><span class="line">  <span class="comment"># orig_ns_text = 'dust".)ItofferedaclassiccurriculumontheEnglishuniversitymodelâ€”â€‹â€‹manyleadersinthecolonyhadattendedtheUniversityofCambridgeâ€”â€‹â€‹butconformedPuritanism.'</span></span><br><span class="line">  <span class="comment"># tok_ns_text = 'dust".)itofferedaclassiccurriculumontheenglishuniversitymodelâ€”manyleadersinthecolonyhadattendedtheuniversityofcambridgeâ€”butconformedpuritanism.'</span></span><br><span class="line">  <span class="keyword">if</span> len(orig_ns_text) != len(tok_ns_text):</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(<span class="string">"Length not equal after stripping spaces: '%s' vs '%s'"</span>,</span><br><span class="line">                      orig_ns_text, tok_ns_text)</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line"></span><br><span class="line">  <span class="comment"># å°† pred_text å®šä½/å¯¹é½åˆ° orig_text ä¸­</span></span><br><span class="line">  <span class="comment"># We then project the characters in `pred_text` back to `orig_text` using</span></span><br><span class="line">  <span class="comment"># the character-to-character alignment.</span></span><br><span class="line">  tok_s_to_ns_map = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> (i, tok_index) <span class="keyword">in</span> six.iteritems(tok_ns_to_s_map):</span><br><span class="line">    tok_s_to_ns_map[tok_index] = i</span><br><span class="line"></span><br><span class="line">  orig_start_position = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">if</span> start_position <span class="keyword">in</span> tok_s_to_ns_map:</span><br><span class="line">    ns_start_position = tok_s_to_ns_map[start_position]</span><br><span class="line">    <span class="keyword">if</span> ns_start_position <span class="keyword">in</span> orig_ns_to_s_map:</span><br><span class="line">      orig_start_position = orig_ns_to_s_map[ns_start_position]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> orig_start_position <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(<span class="string">"Couldn't map start position"</span>)</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line"></span><br><span class="line">  orig_end_position = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">if</span> end_position <span class="keyword">in</span> tok_s_to_ns_map:</span><br><span class="line">    ns_end_position = tok_s_to_ns_map[end_position]</span><br><span class="line">    <span class="keyword">if</span> ns_end_position <span class="keyword">in</span> orig_ns_to_s_map:</span><br><span class="line">      orig_end_position = orig_ns_to_s_map[ns_end_position]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> orig_end_position <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(<span class="string">"Couldn't map end position"</span>)</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line"></span><br><span class="line">  output_text = orig_text[orig_start_position:(orig_end_position + <span class="number">1</span>)]</span><br><span class="line">  <span class="keyword">return</span> output_text</span><br></pre></td></tr></table></figure>
</li>
<li><p>_get_best_indexes</p>
<p>å°†ä¸€ä¸ª logits æŒ‰ç…§é€†åºæ’åºï¼Œå–å‡ºå‰ n ä¸ªå€¼çš„ç´¢å¼•</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_best_indexes</span><span class="params">(logits, n_best_size)</span>:</span></span><br><span class="line">  <span class="string">"""Get the n-best logits from a list."""</span></span><br><span class="line">  index_and_score = sorted(enumerate(logits), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  best_indexes = []</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(len(index_and_score)):</span><br><span class="line">    <span class="keyword">if</span> i &gt;= n_best_size:</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">    best_indexes.append(index_and_score[i][<span class="number">0</span>])</span><br><span class="line">  <span class="keyword">return</span> best_indexes</span><br></pre></td></tr></table></figure>
</li>
<li><p>main</p>
<p>ä¸»ç¨‹åºğŸ˜„ ç»ˆäºåˆ°ç»ˆç‚¹å•¦ï¼Œä¸è¿‡è¿™ä¹Ÿæ˜¯è¿è¡Œçš„èµ·ç‚¹ï½</p>
<p>æµç¨‹ï¼šåŠ è½½å¹¶æ£€æŸ¥æ¨¡å‹é…ç½® -&gt; åˆ›å»ºTokenizer -&gt; é…ç½®TPU</p>
<ul>
<li><strong>train</strong>:        -&gt; è¯»å–è®­ç»ƒè¾“å…¥æ–‡ä»¶å¹¶shuffle -&gt; åˆ›å»ºæ¨¡å‹å‡½æ•° -&gt; åˆ›å»º estimator -&gt; å¤„ç†è¾“å…¥å¹¶åˆ›å»ºè¾“å…¥å‡½æ•° -&gt;  estimator.train</li>
<li><strong>predict</strong>:    -&gt; è¯»å–é¢„æµ‹è¾“å…¥æ–‡ä»¶ -&gt; åˆ›å»ºæ¨¡å‹å‡½æ•° -&gt; åˆ›å»º estimator -&gt; å¤„ç†è¾“å…¥å¹¶åˆ›å»ºè¾“å…¥å‡½æ•° -&gt;  estimator.predict -&gt; output<ul>
<li>ï¼ˆä¸ºäº†æ–¹ä¾¿å¯¹æ¯”ï¼Œç¨å¾®è°ƒæ•´äº†ä¸‹ predict çš„è¿‡ç¨‹ï¼‰</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(_)</span>:</span></span><br><span class="line">  tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line"></span><br><span class="line">  bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)</span><br><span class="line">  validate_flags_or_throw(bert_config)</span><br><span class="line"></span><br><span class="line">  tf.gfile.MakeDirs(FLAGS.output_dir)</span><br><span class="line"></span><br><span class="line">  tokenizer = tokenization.FullTokenizer(</span><br><span class="line">      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)</span><br><span class="line"></span><br><span class="line">  ... tpu ç›¸å…³ ...</span><br><span class="line">  run_config = tf.contrib.tpu.RunConfig(...) <span class="comment"># å¿…é¡»å°† tf.contrib.tpu.RunConfig ä¼ é€’ç»™æ„é€ å‡½æ•°</span></span><br><span class="line"></span><br><span class="line">  train_examples = <span class="literal">None</span></span><br><span class="line">  num_train_steps = <span class="literal">None</span></span><br><span class="line">  num_warmup_steps = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_train:</span><br><span class="line">    train_examples = read_squad_examples(</span><br><span class="line">        input_file=FLAGS.train_file, is_training=<span class="literal">True</span>)</span><br><span class="line">    num_train_steps = int(len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)</span><br><span class="line">    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion) <span class="comment"># å’Œå­¦ä¹ ç‡æœ‰å…³</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pre-shuffle the input to avoid having to make a very large shuffle</span></span><br><span class="line">    <span class="comment"># buffer in in the `input_fn`.</span></span><br><span class="line">    rng = random.Random(<span class="number">12345</span>)</span><br><span class="line">    rng.shuffle(train_examples)</span><br><span class="line"></span><br><span class="line">  model_fn = model_fn_builder(</span><br><span class="line">      bert_config=bert_config,</span><br><span class="line">      init_checkpoint=FLAGS.init_checkpoint,</span><br><span class="line">      learning_rate=FLAGS.learning_rate,</span><br><span class="line">      num_train_steps=num_train_steps,</span><br><span class="line">      num_warmup_steps=num_warmup_steps,</span><br><span class="line">      use_tpu=FLAGS.use_tpu,</span><br><span class="line">      use_one_hot_embeddings=FLAGS.use_tpu)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># If TPU is not available, this will fall back to normal Estimator on CPU or GPU.</span></span><br><span class="line">  <span class="comment"># TPUEstimator ç±»ä¸ Estimator ç±»æœ‰æ‰€ä¸åŒã€‚</span></span><br><span class="line">	<span class="comment"># è¦ç»´æŠ¤å¯åœ¨ CPU/GPU æˆ– Cloud TPU ä¸Šè¿è¡Œçš„æ¨¡å‹ï¼Œæœ€ç®€å•çš„æ–¹å¼æ˜¯å°†æ¨¡å‹çš„æ¨ç†é˜¶æ®µï¼ˆä»è¾“å…¥åˆ°é¢„æµ‹ï¼‰å®šä¹‰åœ¨ model_fn ä¹‹å¤–ã€‚</span></span><br><span class="line">	<span class="comment"># ç„¶åï¼Œç¡®ä¿ Estimator è®¾ç½®å’Œ model_fn çš„å•ç‹¬å®ç°ï¼ŒäºŒè€…å‡åŒ…å«æ­¤æ¨ç†æ­¥éª¤ã€‚</span></span><br><span class="line">  <span class="comment"># åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šä½¿ç”¨ tf.contrib.tpu.TPUEstimator æ‰€éœ€çš„æ›´æ”¹ç›¸å¯¹è¾ƒå°‘ã€‚å°†æ„é€ å‡½æ•°ä¸­çš„ use_tpu å‚æ•°è®¾ä¸º Falseï¼Œå¹¶å°† 			</span></span><br><span class="line">  <span class="comment"># tf.contrib.tpu.RunConfig ä»¥ config å‚æ•°çš„å½¢å¼ä¼ é€’ã€‚</span></span><br><span class="line">  estimator = tf.contrib.tpu.TPUEstimator(</span><br><span class="line">      use_tpu=FLAGS.use_tpu,</span><br><span class="line">      model_fn=model_fn,</span><br><span class="line">      config=run_config,</span><br><span class="line">      train_batch_size=FLAGS.train_batch_size,</span><br><span class="line">      predict_batch_size=FLAGS.predict_batch_size)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_train:</span><br><span class="line">    <span class="comment"># We write to a temporary file to avoid storing very large constant tensors</span></span><br><span class="line">    <span class="comment"># in memory.</span></span><br><span class="line">    train_writer = FeatureWriter(</span><br><span class="line">        filename=os.path.join(FLAGS.output_dir, <span class="string">"train.tf_record"</span>),</span><br><span class="line">        is_training=<span class="literal">True</span>)</span><br><span class="line">    convert_examples_to_features(</span><br><span class="line">        examples=train_examples,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        max_seq_length=FLAGS.max_seq_length,</span><br><span class="line">        doc_stride=FLAGS.doc_stride,</span><br><span class="line">        max_query_length=FLAGS.max_query_length,</span><br><span class="line">        is_training=<span class="literal">True</span>,</span><br><span class="line">        output_fn=train_writer.process_feature)</span><br><span class="line">    train_writer.close()</span><br><span class="line">    </span><br><span class="line">		tf.logging.info(<span class="string">"***** Running training *****"</span>)</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">del</span> train_examples</span><br><span class="line"></span><br><span class="line">    train_input_fn = input_fn_builder(</span><br><span class="line">        input_file=train_writer.filename,</span><br><span class="line">        seq_length=FLAGS.max_seq_length,</span><br><span class="line">        is_training=<span class="literal">True</span>,</span><br><span class="line">        drop_remainder=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># æ¯å½“æœ‰äººè°ƒç”¨ Estimator çš„ trainã€evaluate æˆ– predict æ–¹æ³•æ—¶ï¼Œå°±ä¼šè°ƒç”¨æ¨¡å‹å‡½æ•°ã€‚</span></span><br><span class="line">    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_predict:</span><br><span class="line">    eval_examples = read_squad_examples(</span><br><span class="line">        input_file=FLAGS.predict_file, is_training=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    eval_writer = FeatureWriter(</span><br><span class="line">        filename=os.path.join(FLAGS.output_dir, <span class="string">"eval.tf_record"</span>),</span><br><span class="line">        is_training=<span class="literal">False</span>)</span><br><span class="line">    eval_features = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">append_feature</span><span class="params">(feature)</span>:</span></span><br><span class="line">      eval_features.append(feature) <span class="comment">#</span></span><br><span class="line">      eval_writer.process_feature(feature)</span><br><span class="line"></span><br><span class="line">    convert_examples_to_features(..., output_fn=append_feature)</span><br><span class="line">    eval_writer.close()</span><br><span class="line">    </span><br><span class="line">		tf.logging.info(<span class="string">"***** Running predictions *****"</span>)</span><br><span class="line">    ...</span><br><span class="line">    all_results = []</span><br><span class="line"></span><br><span class="line">    predict_input_fn = input_fn_builder(...)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If running eval on the TPU, you will need to specify the number of</span></span><br><span class="line">    <span class="comment"># steps.</span></span><br><span class="line">    all_results = []</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> estimator.predict(</span><br><span class="line">        predict_input_fn, yield_single_examples=<span class="literal">True</span>):</span><br><span class="line">      <span class="keyword">if</span> len(all_results) % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        tf.logging.info(<span class="string">"Processing example: %d"</span> % (len(all_results)))</span><br><span class="line">      unique_id = int(result[<span class="string">"unique_ids"</span>])</span><br><span class="line">      start_logits = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> result[<span class="string">"start_logits"</span>].flat]</span><br><span class="line">      end_logits = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> result[<span class="string">"end_logits"</span>].flat]</span><br><span class="line">      all_results.append(</span><br><span class="line">          RawResult(</span><br><span class="line">              unique_id=unique_id,</span><br><span class="line">              start_logits=start_logits,</span><br><span class="line">              end_logits=end_logits))</span><br><span class="line"></span><br><span class="line">    output_prediction_file = os.path.join(FLAGS.output_dir, <span class="string">"predictions.json"</span>)</span><br><span class="line">    output_nbest_file = os.path.join(FLAGS.output_dir, <span class="string">"nbest_predictions.json"</span>)</span><br><span class="line">    output_null_log_odds_file = os.path.join(FLAGS.output_dir, <span class="string">"null_odds.json"</span>)</span><br><span class="line"></span><br><span class="line">    write_predictions(eval_examples, eval_features, all_results,</span><br><span class="line">                      FLAGS.n_best_size, FLAGS.max_answer_length,</span><br><span class="line">                      FLAGS.do_lower_case, output_prediction_file,</span><br><span class="line">                      output_nbest_file, output_null_log_odds_file)</span><br></pre></td></tr></table></figure>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hexo/" rel="tag"># Hexo</a>
          
            <a href="/tags/Typora/" rel="tag"># Typora</a>
          
        </div>
      

      
      
      

      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-6"><a class="nav-link" href="#tokenization-py"><span class="nav-number">1.</span> <span class="nav-text">tokenization.py</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#modeling-py"><span class="nav-number">2.</span> <span class="nav-text">modeling.py</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#optimization-py"><span class="nav-number">3.</span> <span class="nav-text">optimization.py</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#run-squad-py"><span class="nav-number">4.</span> <span class="nav-text">run_squad.py</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
