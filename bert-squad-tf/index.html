<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo,Typora,">










<meta name="description" content="使用BERT半年多了，一直用的是Huggingface的pytorch代码，最近毕业抽空跟着Google官方Tensorflow代码敲了一遍，为了能够做到深入理解并复现，在这里详细分析BERT的官方代码。争取做到，能够理解后复现出来。上车🚗🚗🚗  tokenization.py这是对BERT输入进行分词的代码部分，我们先绘制出 tokenization.py 文件的结构，然后逐个函数逐行分析">
<meta name="keywords" content="Hexo,Typora">
<meta property="og:type" content="article">
<meta property="og:title" content="bert-squad-tf">
<meta property="og:url" content="https://1024er.github.io/bert-squad-tf/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="使用BERT半年多了，一直用的是Huggingface的pytorch代码，最近毕业抽空跟着Google官方Tensorflow代码敲了一遍，为了能够做到深入理解并复现，在这里详细分析BERT的官方代码。争取做到，能够理解后复现出来。上车🚗🚗🚗  tokenization.py这是对BERT输入进行分词的代码部分，我们先绘制出 tokenization.py 文件的结构，然后逐个函数逐行分析">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703180643549.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703180540319.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703013613264.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190702234605092.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190702200034350.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703184633330.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190704121235449.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190703085937162.png">
<meta property="og:image" content="https://1024er.github.io/bert-squad-tf/image-20190702102852057.png">
<meta property="og:updated_time" content="2019-07-04T19:08:55.543Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="bert-squad-tf">
<meta name="twitter:description" content="使用BERT半年多了，一直用的是Huggingface的pytorch代码，最近毕业抽空跟着Google官方Tensorflow代码敲了一遍，为了能够做到深入理解并复现，在这里详细分析BERT的官方代码。争取做到，能够理解后复现出来。上车🚗🚗🚗  tokenization.py这是对BERT输入进行分词的代码部分，我们先绘制出 tokenization.py 文件的结构，然后逐个函数逐行分析">
<meta name="twitter:image" content="https://1024er.github.io/bert-squad-tf/image-20190703180643549.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://1024er.github.io/bert-squad-tf/">





  <title>bert-squad-tf | Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://1024er.github.io/bert-squad-tf/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">bert-squad-tf</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-04T00:00:00+08:00">
                2019-07-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog-System/" itemprop="url" rel="index">
                    <span itemprop="name">Blog System</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog-System/Hexo/" itemprop="url" rel="index">
                    <span itemprop="name">Hexo</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>使用BERT半年多了，一直用的是Huggingface的pytorch代码，最近毕业抽空跟着Google官方Tensorflow代码敲了一遍，为了能够做到深入理解并复现，在这里详细分析BERT的官方代码。争取做到，能够理解后复现出来。上车🚗🚗🚗</p>
<hr>
<h6 id="tokenization-py"><a href="#tokenization-py" class="headerlink" title="tokenization.py"></a>tokenization.py</h6><p>这是对BERT输入进行分词的代码部分，我们先绘制出 tokenization.py 文件的结构，然后逐个函数逐行分析。</p>
<p><img src="/bert-squad-tf/image-20190703180643549.png" alt="image-20190703180643549"></p>
<p>Bert 的分词使用 FullTokenizer，包括两部分：</p>
<ul>
<li>使用 BasicTokenizer 根据符号分词，字母大小写处理，得到 tokens<ul>
<li>统一 unicode 编码，并去除无效字符、控制字符，统一空白字符</li>
<li>中文分词支持</li>
<li>处理大小写，去除音节符</li>
<li>根据符号分词</li>
<li>空格分词</li>
</ul>
</li>
<li>使用 WordpieceTokenizer 分词，得到 sub_tokens<ul>
<li>使用 wordpiece 方式分词，使用最长匹配优先的方式，使用 “##”前缀</li>
</ul>
</li>
</ul>
<p>补充参考：*</p>
<p>​    <em>unicodedata.category() 的返回值可以参考 <a href="https://www.compart.com/en/unicode/category" target="_blank" rel="noopener">https://www.compart.com/en/unicode/category</a></em></p>
<p>​    <em>ASCII码表可以参考 <a href="https://zh.wikipedia.org/wiki/Unicode字符列表#基本拉丁字母" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Unicode字符列表#基本拉丁字母</a></em></p>
<p><strong>case检查</strong></p>
<ul>
<li><p>validate_case_matches_checkpoint</p>
<p>这个函数的目的是检查传入参数 do_lower_case（是否大小写敏感） 和 要加载的模型 是是否匹配。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate_case_matches_checkpoint</span><span class="params">(do_lower_case, init_checkpoint)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> init_checkpoint: <span class="comment"># 输入合法性判断</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  </span><br><span class="line">	<span class="comment"># 使用懒惰模式来匹配模型的名称</span></span><br><span class="line">  <span class="comment"># 比如：init_checkpoint = /root/bert/uncased_L-12_H-768_A-12/bert_model.ckpt</span></span><br><span class="line">  <span class="comment"># 匹配后 model_name = uncased_L-12_H-768_A-12</span></span><br><span class="line">  m = re.match(<span class="string">"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt"</span>, init_checkpoint) </span><br><span class="line">  <span class="keyword">if</span> m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  model_name = m.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Google 提供的预训练好的模型名称集合</span></span><br><span class="line">  lower_models = [</span><br><span class="line">      <span class="string">"uncased_L-24_H-1024_A-16"</span>, <span class="string">"uncased_L-12_H-768_A-12"</span>,</span><br><span class="line">      <span class="string">"multilingual_L-12_H-768_A-12"</span>, <span class="string">"chinese_L-12_H-768_A-12"</span></span><br><span class="line">  ]</span><br><span class="line">  cased_models = [</span><br><span class="line">      <span class="string">"cased_L-12_H-768_A-12"</span>, <span class="string">"cased_L-24_H-1024_A-16"</span>,</span><br><span class="line">      <span class="string">"multi_cased_L-12_H-768_A-12"</span></span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">  is_bad_config = <span class="literal">False</span></span><br><span class="line">  <span class="comment"># 要加载的模型大小写不敏感，而传入的参数是大小写敏感</span></span><br><span class="line">  <span class="keyword">if</span> model_name <span class="keyword">in</span> lower_models <span class="keyword">and</span> <span class="keyword">not</span> do_lower_case:</span><br><span class="line">    is_bad_config = <span class="literal">True</span></span><br><span class="line">    ...</span><br><span class="line">	<span class="comment"># 要加载的模型大小写敏感，而传入的参数是大小写不敏感</span></span><br><span class="line">  <span class="keyword">if</span> model_name <span class="keyword">in</span> cased_models <span class="keyword">and</span> do_lower_case:</span><br><span class="line">    is_bad_config = <span class="literal">True</span></span><br><span class="line">    ...</span><br><span class="line">  <span class="comment"># 不一致就抛异常</span></span><br><span class="line">  <span class="keyword">if</span> is_bad_config:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(...)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>编码转换</strong></p>
<ul>
<li><p>convert_to_unicode</p>
<p>将输入 text 转成统一的 unicode 编码。这里需要区分：</p>
<ul>
<li><p>python3 有两种表示字符序列的类型：bytes 和 str。前者的实例包含原始的8位值；后者的实例包含Unicode字符。</p>
</li>
<li><p>python2 中也有两种表示字符序列的类型，分别叫做 str 和 unicode。与 python3 不同的是，str 的实例包含原始的8位值，而 unicode 的实例才包含 Unicode 字符。</p>
</li>
<li><p>python 中，使用 unicode 类型作为编码的基础类型：</p>
<p>​     decode               encode</p>
<p>str ————-&gt; unicode ————-&gt;str</p>
<ul>
<li>Unicode 是「字符集」UTF-8 是「编码规则」</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_to_unicode</span><span class="params">(text)</span>:</span></span><br><span class="line">  <span class="string">"""Converts `text` to Unicode (if it's not already), assuming utf-8 input."""</span></span><br><span class="line">  <span class="keyword">if</span> six.PY3:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, bytes):</span><br><span class="line">      <span class="keyword">return</span> text.decode(<span class="string">"utf-8"</span>, <span class="string">"ignore"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">elif</span> six.PY2:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text.decode(<span class="string">"utf-8"</span>, <span class="string">"ignore"</span>)</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, unicode):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">"Not running on Python2 or Python 3?"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>printable_text</p>
<p>将 text 转换成更适合打印的 str 格式，供 print / tf.logging 这样的函数使用。这些函数的指定输入格式都是 str 格式，格式之间的差异见convert_to_unicode 。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printable_text</span><span class="params">(text)</span>:</span> </span><br><span class="line">  <span class="string">"""Returns text encoded in a way suitable for print or `tf.logging`."""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># These functions want `str` for both Python2 and Python3, but in one case</span></span><br><span class="line">  <span class="comment"># it's a Unicode string and in the other it's a byte string.</span></span><br><span class="line">  <span class="keyword">if</span> six.PY3:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, bytes):</span><br><span class="line">      <span class="keyword">return</span> text.decode(<span class="string">"utf-8"</span>, <span class="string">"ignore"</span>) <span class="comment"># **de**code</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">elif</span> six.PY2:</span><br><span class="line">    <span class="keyword">if</span> isinstance(text, str):</span><br><span class="line">      <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">elif</span> isinstance(text, unicode):</span><br><span class="line">      <span class="keyword">return</span> text.encode(<span class="string">"utf-8"</span>) <span class="comment"># **en**code</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported string type: %s"</span> % (type(text)))</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">"Not running on Python2 or Python 3?"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>词典构建和转换</strong></p>
<ul>
<li><p>load_vocab</p>
<p>加载词典文件，存入到 OrderedDict {token: index}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_vocab</span><span class="params">(vocab_file)</span>:</span></span><br><span class="line">  <span class="string">"""Loads a vocabulary file into a dictionary."""</span></span><br><span class="line">  vocab = collections.OrderedDict()</span><br><span class="line">  index = <span class="number">0</span></span><br><span class="line">  <span class="keyword">with</span> tf.gfile.GFile(vocab_file, <span class="string">"r"</span>) <span class="keyword">as</span> reader:</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">      token = convert_to_unicode(reader.readline())</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> token: <span class="comment"># 当 token == '' 时候</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      token = token.strip()</span><br><span class="line">      vocab[token] = index</span><br><span class="line">      index += <span class="number">1</span></span><br><span class="line">  <span class="keyword">return</span> vocab <span class="comment"># uncased_L-12_H-768_A-12模型的 len(vocab)=30522</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>convert_by_vocab / convert_tokens_to_ids / convert_ids_to_tokens</p>
<p>根据此词表，实现 token 和 id 之间的互转</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_by_vocab</span><span class="params">(vocab, items)</span>:</span></span><br><span class="line">  output = []</span><br><span class="line">  <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">    output.append(vocab[item])</span><br><span class="line">  <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_tokens_to_ids</span><span class="params">(vocab, tokens)</span>:</span> <span class="comment"># vocab</span></span><br><span class="line">  <span class="keyword">return</span> convert_by_vocab(vocab, tokens)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_ids_to_tokens</span><span class="params">(inv_vocab, ids)</span>:</span> <span class="comment"># inv_vocab!</span></span><br><span class="line">  <span class="keyword">return</span> convert_by_vocab(inv_vocab, ids)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>字符处理</strong></p>
<ul>
<li><p>_is_whitespace / _is_control / _is_punctuation<br>是否是 空白符、控制符、标点符</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_is_whitespace</span><span class="params">(char)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> char == <span class="string">" "</span> <span class="keyword">or</span> char == <span class="string">"\t"</span> <span class="keyword">or</span> char == <span class="string">"\n"</span> <span class="keyword">or</span> char == <span class="string">"\r"</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  cat = unicodedata.category(char)</span><br><span class="line">  <span class="keyword">if</span> cat == <span class="string">"Zs"</span>: <span class="comment"># "Zs" 表示 Space Separator</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_is_control</span><span class="params">(char)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> char == <span class="string">"\t"</span> <span class="keyword">or</span> char == <span class="string">"\n"</span> <span class="keyword">or</span> char == <span class="string">"\r"</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">  cat = unicodedata.category(char)</span><br><span class="line">  <span class="keyword">if</span> cat <span class="keyword">in</span> (<span class="string">"Cc"</span>, <span class="string">"Cf"</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_is_punctuation</span><span class="params">(char)</span>:</span></span><br><span class="line">  cp = ord(char)</span><br><span class="line">  <span class="comment"># 所有非 字母/数字 的ASCII字符，**注意：没有包括空格符号**</span></span><br><span class="line">  <span class="keyword">if</span> ((cp &gt;= <span class="number">33</span> <span class="keyword">and</span> cp &lt;= <span class="number">47</span>) <span class="keyword">or</span> (cp &gt;= <span class="number">58</span> <span class="keyword">and</span> cp &lt;= <span class="number">64</span>) <span class="keyword">or</span></span><br><span class="line">      (cp &gt;= <span class="number">91</span> <span class="keyword">and</span> cp &lt;= <span class="number">96</span>) <span class="keyword">or</span> (cp &gt;= <span class="number">123</span> <span class="keyword">and</span> cp &lt;= <span class="number">126</span>)):</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="comment"># 所有 unicode 中分类为 punctuation 的字符</span></span><br><span class="line">  cat = unicodedata.category(char)</span><br><span class="line">  <span class="keyword">if</span> cat.startswith(<span class="string">"P"</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>分词</strong></p>
<ul>
<li><p>whitespace_tokenize</p>
<p>清理text前后的空格类符号，然后根据空格分词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">whitespace_tokenize</span><span class="params">(text)</span>:</span></span><br><span class="line">  text = text.strip()</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> text:</span><br><span class="line">    <span class="keyword">return</span> []</span><br><span class="line">  tokens = text.split()</span><br><span class="line">  <span class="keyword">return</span> tokens</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>BasicTokenizer 类</strong> </p>
<p>实现简单的分词功能：根据符号分词，字母大小写处理。</p>
<p>流程：统一 unicode 编码，并去除无效字符、控制字符，统一空白字符 -&gt; 中文分词支持 -&gt; 去除多余空格 -&gt; 处理大小写，去除音节符 -&gt; 根据符号分词 -&gt;  空格分词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicTokenizer</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, do_lower_case=True)</span>:</span></span><br><span class="line">    self.do_lower_case = do_lower_case</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 统一编码，过滤字符，中文处理，case 处理，符号分词</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="comment"># 统一为 unicode 编码，并去除无效字符、控制字符，将空白字符统一为单个空格</span></span><br><span class="line">    text = convert_to_unicode(text)</span><br><span class="line">    text = self._clean_text(text)</span><br><span class="line"></span><br><span class="line">    text = self._tokenize_chinese_chars(text) <span class="comment"># 中文支持</span></span><br><span class="line"></span><br><span class="line">    orig_tokens = whitespace_tokenize(text) <span class="comment"># 去除多余空白符</span></span><br><span class="line">    split_tokens = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> orig_tokens:</span><br><span class="line">      <span class="keyword">if</span> self.do_lower_case: <span class="comment"># 大小写处理</span></span><br><span class="line">        token = token.lower()</span><br><span class="line">        token = self._run_strip_accents(token) <span class="comment"># 去除音节符</span></span><br><span class="line">      split_tokens.extend(self._run_split_on_punc(token)) <span class="comment"># 根据符号分词</span></span><br><span class="line"></span><br><span class="line">    output_tokens = whitespace_tokenize(<span class="string">" "</span>.join(split_tokens)) </span><br><span class="line">    <span class="keyword">return</span> output_tokens</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 将音节字符转成组合字符表示再去除</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_run_strip_accents</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Strips accents from a piece of text."""</span></span><br><span class="line">    <span class="comment"># 在Unicode中，某些字符能够用多个合法的编码表示</span></span><br><span class="line">    <span class="comment"># normalize() 第一个参数指定字符串标准化的方式</span></span><br><span class="line">    <span class="comment"># NFC表示字符应该是整体组成(比如可能的话就使用单一编码)，如 'ﬁ'</span></span><br><span class="line">    <span class="comment"># 而NFD表示字符应该分解为多个组合字符表示，如 'fi'</span></span><br><span class="line">    text = unicodedata.normalize(<span class="string">"NFD"</span>, text)</span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> text:</span><br><span class="line">      cat = unicodedata.category(char)</span><br><span class="line">      <span class="keyword">if</span> cat == <span class="string">"Mn"</span>: <span class="comment"># Nonspacing Mark</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      output.append(char)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span>.join(output)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 根据标点符来分词</span></span><br><span class="line">  <span class="comment"># 例如："anti-labor" =&gt; ['anti', '-', 'labor']</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_run_split_on_punc</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Splits punctuation on a piece of text."""</span></span><br><span class="line">    chars = list(text)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    start_new_word = <span class="literal">True</span></span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">while</span> i &lt; len(chars):</span><br><span class="line">      char = chars[i]</span><br><span class="line">      <span class="keyword">if</span> _is_punctuation(char): </span><br><span class="line">        output.append([char]) <span class="comment"># 标点也存</span></span><br><span class="line">        start_new_word = <span class="literal">True</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> start_new_word:</span><br><span class="line">          output.append([])</span><br><span class="line">        start_new_word = <span class="literal">False</span></span><br><span class="line">        output[<span class="number">-1</span>].append(char)</span><br><span class="line">      i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">""</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> output]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_tokenize_chinese_chars</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Adds whitespace around any CJK character."""</span></span><br><span class="line">    <span class="comment"># CJK: Chinese Japanese Korean</span></span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> text:</span><br><span class="line">      cp = ord(char)</span><br><span class="line">      <span class="keyword">if</span> self._is_chinese_char(cp):</span><br><span class="line">        output.append(<span class="string">" "</span>)</span><br><span class="line">        output.append(char)</span><br><span class="line">        output.append(<span class="string">" "</span>) <span class="comment"># 多余的空格通过后面的 whitespace_tokenize 流程去除</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        output.append(char)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span>.join(output)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_is_chinese_char</span><span class="params">(self, cp)</span>:</span></span><br><span class="line">    <span class="string">"""Checks whether CP is the codepoint of a CJK character."""</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    <span class="keyword">if</span> ((cp &gt;= <span class="number">0x4E00</span> <span class="keyword">and</span> cp &lt;= <span class="number">0x9FFF</span>) <span class="keyword">or</span> ...:  <span class="comment">#</span></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 去除无效字符、控制字符，将空白字符统一为单个空格</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_clean_text</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""Performs invalid character removal and whitespace cleanup on text."""</span></span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> text:</span><br><span class="line">      cp = ord(char)</span><br><span class="line">      <span class="comment"># 0 表示 NULL</span></span><br><span class="line">      <span class="comment"># invalid character 会转换成 Unicode 的REPLACEMENT CHARACTER(0xFFFD)</span></span><br><span class="line">      <span class="keyword">if</span> cp == <span class="number">0</span> <span class="keyword">or</span> cp == <span class="number">0xfffd</span> <span class="keyword">or</span> _is_control(char):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      <span class="keyword">if</span> _is_whitespace(char):</span><br><span class="line">        output.append(<span class="string">" "</span>)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        output.append(char)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span>.join(output)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>WordpieceTokenizer 类</strong></p>
<p>使用 wordpiece 方式分词，使用最长匹配优先的方式，使用 “##”前缀。</p>
<font color="red">这里有个问题：未登录词会不会影响将来 answer 的定位？？</font>

<p>我的回答：不会，没找的词替换为 ‘[UNK]’ 后还是一个position 的占位，还是对齐的。在预测阶段如果要输出，输出对应位置原来的 token。这一处理可以参见 run_squad.py 中的 get_final_text()。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordpieceTokenizer</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Runs WordPiece tokenziation."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab, unk_token=<span class="string">"[UNK]"</span>, max_input_chars_per_word=<span class="number">200</span>)</span>:</span></span><br><span class="line">    self.vocab = vocab</span><br><span class="line">    self.unk_token = unk_token</span><br><span class="line">    self.max_input_chars_per_word = max_input_chars_per_word</span><br><span class="line">	</span><br><span class="line">  <span class="comment"># 统一编码，最长匹配优先，未登录token使用'[UNK]'替代</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    <span class="string">"""greedy **longest**-match-first</span></span><br><span class="line"><span class="string">    	For example:</span></span><br><span class="line"><span class="string">        input = "unaffable"</span></span><br><span class="line"><span class="string">        output = ["un", "##aff", "##able"]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    text = convert_to_unicode(text)</span><br><span class="line"></span><br><span class="line">    output_tokens = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> whitespace_tokenize(text):</span><br><span class="line">      chars = list(token)</span><br><span class="line">      <span class="keyword">if</span> len(chars) &gt; self.max_input_chars_per_word:</span><br><span class="line">        output_tokens.append(self.unk_token)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">      is_bad = <span class="literal">False</span> <span class="comment"># 是否是未登录token</span></span><br><span class="line">      start = <span class="number">0</span></span><br><span class="line">      sub_tokens = []</span><br><span class="line">      <span class="keyword">while</span> start &lt; len(chars):</span><br><span class="line">        end = len(chars)</span><br><span class="line">        cur_substr = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> start &lt; end:</span><br><span class="line">          substr = <span class="string">""</span>.join(chars[start:end])</span><br><span class="line">          <span class="keyword">if</span> start &gt; <span class="number">0</span>:</span><br><span class="line">            substr = <span class="string">"##"</span> + substr</span><br><span class="line">          <span class="keyword">if</span> substr <span class="keyword">in</span> self.vocab:</span><br><span class="line">            cur_substr = substr</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">          end -= <span class="number">1</span> <span class="comment"># **longest**-match-first</span></span><br><span class="line">        <span class="keyword">if</span> cur_substr <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># 出现未登录token，终止流程</span></span><br><span class="line">          is_bad = <span class="literal">True</span></span><br><span class="line">          <span class="keyword">break</span></span><br><span class="line">        sub_tokens.append(cur_substr)</span><br><span class="line">        start = end <span class="comment"># 寻找下一个 token</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> is_bad: <span class="comment"># 未登录token使用'[UNK]'替代</span></span><br><span class="line">        output_tokens.append(self.unk_token)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        output_tokens.extend(sub_tokens)</span><br><span class="line">    <span class="keyword">return</span> output_tokens</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>FullTokenizerr 类</strong></p>
<p>流程：text -&gt; 使用 BasicTokenizer 根据符号分词，字母大小写处理，得到 tokens -&gt; 使用 WordpieceTokenizer 分词，得到 sub_tokens</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FullTokenizer</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Runs end-to-end tokenziation."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_file, do_lower_case=True)</span>:</span></span><br><span class="line">    self.vocab = load_vocab(vocab_file) <span class="comment"># &#123;token: index&#125;</span></span><br><span class="line">    self.inv_vocab = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.vocab.items()&#125; <span class="comment"># &#123;index: token&#125;</span></span><br><span class="line">    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)</span><br><span class="line">    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(self, text)</span>:</span></span><br><span class="line">    split_tokens = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> self.basic_tokenizer.tokenize(text):</span><br><span class="line">      <span class="keyword">for</span> sub_token <span class="keyword">in</span> self.wordpiece_tokenizer.tokenize(token):</span><br><span class="line">        split_tokens.append(sub_token)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> split_tokens</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">convert_tokens_to_ids</span><span class="params">(self, tokens)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> convert_by_vocab(self.vocab, tokens)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">convert_ids_to_tokens</span><span class="params">(self, ids)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> convert_by_vocab(self.inv_vocab, ids)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h6 id="modeling-py"><a href="#modeling-py" class="headerlink" title="modeling.py"></a>modeling.py</h6><p>这是对BERT模型的代码部分，我们先绘制出 modeling.py 文件的结构，然后逐个函数逐行分析。</p>
<p><img src="/bert-squad-tf/image-20190703180540319.png" alt="image-20190703180540319"></p>
<ul>
<li><p>create_initializer</p>
<p>从截断的正态分布中输出随机值。生成的值服从具有指定平均值和标准偏差的正态分布，如果生成的值大于平均值2个标准偏差的值则丢弃重选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_initializer</span><span class="params">(initializer_range=<span class="number">0.02</span>)</span>:</span></span><br><span class="line">  <span class="string">"""Creates a `truncated_normal_initializer` with the given range."""</span></span><br><span class="line">  <span class="keyword">return</span> tf.truncated_normal_initializer(stddev=initializer_range)</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_assignment_map_from_checkpoint </p>
<p>对齐当前模型和 checkpoint，确定哪些变量可以通过 checkpoint 初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_assignment_map_from_checkpoint</span><span class="params">(tvars, init_checkpoint)</span>:</span></span><br><span class="line">  <span class="string">"""Compute the union of the current variables and checkpoint variables."""</span></span><br><span class="line">  assignment_map = &#123;&#125;</span><br><span class="line">  initialized_variable_names = &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Returns dict of all trainable variables in the model.</span></span><br><span class="line">  name_to_variable = collections.OrderedDict()</span><br><span class="line">  <span class="keyword">for</span> var <span class="keyword">in</span> tvars:</span><br><span class="line">    name = var.name <span class="comment"># 例 'bert/embeddings/word_embeddings:0'</span></span><br><span class="line">    m = re.match(<span class="string">"^(.*):\\d+$$"</span>, name)</span><br><span class="line">    <span class="keyword">if</span> m <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      name = m.group(<span class="number">1</span>) <span class="comment"># 例 'bert/embeddings/word_embeddings'</span></span><br><span class="line">    name_to_variable[name] = var</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Returns list of all variables in the checkpoint.</span></span><br><span class="line">  init_vars = tf.train.list_variables(init_checkpoint) </span><br><span class="line">	</span><br><span class="line">  <span class="comment"># 查找那些模型中的参数可以使用 checkpoint 初始化</span></span><br><span class="line">  assignment_map = collections.OrderedDict()</span><br><span class="line">  <span class="keyword">for</span> x <span class="keyword">in</span> init_vars:</span><br><span class="line">    (name, var) = (x[<span class="number">0</span>], x[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">not</span> <span class="keyword">in</span> name_to_variable:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    assignment_map[name] = name</span><br><span class="line">    initialized_variable_names[name] = <span class="number">1</span></span><br><span class="line">    initialized_variable_names[name + <span class="string">":0"</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (assignment_map, initialized_variable_names)</span><br></pre></td></tr></table></figure>
</li>
<li><p>create_attention_mask_from_input_mask</p>
<p>这个函数有点绕。我们不用管 batch_size 可能更容易理解一些。</p>
<p>对于一个 from_seq_length 的输入，我们从它的每个位置去 attend 目标序列中的没有被 mask 掉的位置。</p>
<p>[1, to_seq_length] * [from_seq_length, 1] =&gt; [from_seq_length, to_seq_length]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_attention_mask_from_input_mask</span><span class="params">(from_tensor, to_mask)</span>:</span></span><br><span class="line">  <span class="string">"""Create 3D attention mask from a 2D tensor mask.</span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].</span></span><br><span class="line"><span class="string">    to_mask: int32 Tensor of shape [batch_size, to_seq_length].</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    float Tensor of shape [batch_size, from_seq_length, to_seq_length].</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  from_shape = get_shape_list(from_tensor, expected_rank=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">  batch_size = from_shape[<span class="number">0</span>]</span><br><span class="line">  from_seq_length = from_shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  to_shape = get_shape_list(to_mask, expected_rank=<span class="number">2</span>)</span><br><span class="line">  to_seq_length = to_shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  to_mask = tf.cast(</span><br><span class="line">      tf.reshape(to_mask, [batch_size, <span class="number">1</span>, to_seq_length]), tf.float32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># We don't actually care if we attend *from* padding tokens (only *to* padding)</span></span><br><span class="line">  <span class="comment"># tokens so we create a tensor of all ones.</span></span><br><span class="line">  broadcast_ones = tf.ones(</span><br><span class="line">      shape=[batch_size, from_seq_length, <span class="number">1</span>], dtype=tf.float32) <span class="comment"># 从 from_seq 的每个位置去 attend to_seq</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Here we broadcast along two dimensions to create the mask.</span></span><br><span class="line">  mask = broadcast_ones * to_mask</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> mask</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>shape 相关</strong></p>
<ul>
<li><p>get_shape_list</p>
<p>返回 tensor 的维度信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_shape_list</span><span class="params">(tensor, expected_rank=None, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Returns a list of the shape of tensor, preferring static dimensions."""</span></span><br><span class="line">  ...</span><br><span class="line">  shape = tensor.shape.as_list() </span><br><span class="line"></span><br><span class="line">  non_static_indexes = []</span><br><span class="line">  <span class="keyword">for</span> (index, dim) <span class="keyword">in</span> enumerate(shape):</span><br><span class="line">    <span class="keyword">if</span> dim <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># 动态维度</span></span><br><span class="line">      non_static_indexes.append(index)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> non_static_indexes: <span class="comment"># 不存在动态维度</span></span><br><span class="line">    <span class="keyword">return</span> shape</span><br><span class="line">	<span class="comment"># 动态维度根据实际 tensor 的对应维度来填充</span></span><br><span class="line">  dyn_shape = tf.shape(tensor)</span><br><span class="line">  <span class="keyword">for</span> index <span class="keyword">in</span> non_static_indexes:</span><br><span class="line">    shape[index] = dyn_shape[index]</span><br><span class="line">  <span class="keyword">return</span> shape</span><br></pre></td></tr></table></figure>
</li>
<li><p>reshape_to_matrix / reshape_from_matrix</p>
<p>reshape_to_matrix 将超过2阶的 tensor 转成2阶，reshape_from_matrix 执行相反操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_to_matrix</span><span class="params">(input_tensor)</span>:</span></span><br><span class="line">  <span class="string">"""Reshapes a &gt;= rank 2 tensor to a rank 2 tensor (i.e., a matrix)."""</span></span><br><span class="line">  ndims = input_tensor.shape.ndims</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> ndims == <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">return</span> input_tensor</span><br><span class="line"></span><br><span class="line">  width = input_tensor.shape[<span class="number">-1</span>]</span><br><span class="line">  output_tensor = tf.reshape(input_tensor, [<span class="number">-1</span>, width])</span><br><span class="line">  <span class="keyword">return</span> output_tensor</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_from_matrix</span><span class="params">(output_tensor, orig_shape_list)</span>:</span></span><br><span class="line">  <span class="string">"""Reshapes a rank 2 tensor back to its original rank &gt;= 2 tensor."""</span></span><br><span class="line">  <span class="keyword">if</span> len(orig_shape_list) == <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">return</span> output_tensor</span><br><span class="line">  </span><br><span class="line">  output_shape = get_shape_list(output_tensor)</span><br><span class="line">  orig_dims = orig_shape_list[<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">  width = output_shape[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> tf.reshape(output_tensor, orig_dims + [width])</span><br></pre></td></tr></table></figure>
</li>
<li><p>assert_rank</p>
<p>rank 校验</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">assert_rank</span><span class="params">(tensor, expected_rank, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Raises an exception if the tensor rank is not of the expected rank."""</span></span><br><span class="line">  ...</span><br><span class="line">  expected_rank_dict = &#123;&#125;</span><br><span class="line">  <span class="comment"># 只期望一个 rank</span></span><br><span class="line">  <span class="keyword">if</span> isinstance(expected_rank, six.integer_types):</span><br><span class="line">    expected_rank_dict[expected_rank] = <span class="literal">True</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">		<span class="comment"># 输入 expected_rank 为list[]，存在多个期望的 rank</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> expected_rank:</span><br><span class="line">      expected_rank_dict[x] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">  actual_rank = tensor.shape.ndims <span class="comment"># tensor 实际的 rank</span></span><br><span class="line">  <span class="keyword">if</span> actual_rank <span class="keyword">not</span> <span class="keyword">in</span> expected_rank_dict:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(...)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>embedding 相关</strong></p>
<ul>
<li><p>embedding_lookup</p>
<p>将输入的  ids 映射成 词向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">embedding_lookup</span><span class="params">(input_ids, # int32 Tenso: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                     vocab_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                     embedding_size=<span class="number">128</span>, # BERT_base 中 <span class="number">768</span></span></span></span><br><span class="line"><span class="function"><span class="params">                     initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                     word_embedding_name=<span class="string">"word_embeddings"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                     use_one_hot_embeddings=False)</span>:</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 默认输入3阶 [batch_size, seq_length, num_inputs]</span></span><br><span class="line">  <span class="comment"># 2阶输入[batch_size, seq_length] 扩展为 [batch_size, seq_length, num_inputs=1]</span></span><br><span class="line">  <span class="keyword">if</span> input_ids.shape.ndims == <span class="number">2</span>:</span><br><span class="line">    input_ids = tf.expand_dims(input_ids, axis=[<span class="number">-1</span>]) <span class="comment"># [batch_size, seq_length, num_inputs=1]</span></span><br><span class="line"></span><br><span class="line">  embedding_table = tf.get_variable(</span><br><span class="line">      name=word_embedding_name,</span><br><span class="line">      shape=[vocab_size, embedding_size],</span><br><span class="line">      initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  flat_input_ids = tf.reshape(input_ids, [<span class="number">-1</span>]) <span class="comment"># [batch_size*seq_length*num_inputs,]</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 小 vocabulary 时候 use_one_hot_embeddings 更快</span></span><br><span class="line">  <span class="comment"># 大 vocabulary 时候 tf.gather 更快</span></span><br><span class="line">  <span class="keyword">if</span> use_one_hot_embeddings: </span><br><span class="line">    one_hot_input_ids = tf.one_hot(flat_input_ids, depth=vocab_size) <span class="comment"># [batch_size*seq_length*num_inputs, vocab_size]</span></span><br><span class="line">    output = tf.matmul(one_hot_input_ids, embedding_table) <span class="comment"># [batch_size*seq_length*num_inputs, embedding_size]</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    output = tf.gather(embedding_table, flat_input_ids) <span class="comment"># [batch_size*seq_length*num_inputs, embedding_size]</span></span><br><span class="line"></span><br><span class="line">  input_shape = get_shape_list(input_ids)</span><br><span class="line">  <span class="comment"># # [batch_size, seq_length, num_inputs*embedding_size]</span></span><br><span class="line">  output = tf.reshape(output, input_shape[<span class="number">0</span>:<span class="number">-1</span>] + [input_shape[<span class="number">-1</span>] * embedding_size])</span><br><span class="line">  <span class="keyword">return</span> (output, embedding_table)</span><br></pre></td></tr></table></figure>
</li>
<li><p>embedding_postprocessor</p>
<p>对 embedding 进行后处理：+ position_emb + type/segment_emb + Layer_Norm + dropout</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">embedding_postprocessor</span><span class="params">(input_tensor, # [batch_size, seq_length, embedding_size]</span></span></span><br><span class="line"><span class="function"><span class="params">                            use_token_type=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                            token_type_ids=None, # [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                            token_type_vocab_size=<span class="number">16</span>, # 最多<span class="number">16</span>种type</span></span></span><br><span class="line"><span class="function"><span class="params">                            token_type_embedding_name=<span class="string">"token_type_embeddings"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                            use_position_embeddings=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                            position_embedding_name=<span class="string">"position_embeddings"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                            initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                            max_position_embeddings=<span class="number">512</span>, # 序列最大可用长度</span></span></span><br><span class="line"><span class="function"><span class="params">                            dropout_prob=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">  </span><br><span class="line">  input_shape = get_shape_list(input_tensor, expected_rank=<span class="number">3</span>) <span class="comment"># [batch_size, seq_length, embedding_size]</span></span><br><span class="line">  batch_size = input_shape[<span class="number">0</span>]</span><br><span class="line">  seq_length = input_shape[<span class="number">1</span>]</span><br><span class="line">  width = input_shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">  output = input_tensor</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> use_token_type:</span><br><span class="line">    ... <span class="comment"># 输入合法性判断</span></span><br><span class="line">    token_type_table = tf.get_variable(</span><br><span class="line">        name=token_type_embedding_name,</span><br><span class="line">        shape=[token_type_vocab_size, width],</span><br><span class="line">        initializer=create_initializer(initializer_range))</span><br><span class="line">    <span class="comment"># 小 vocabulary 时候 use_one_hot_embeddings 更快</span></span><br><span class="line">    flat_token_type_ids = tf.reshape(token_type_ids, [<span class="number">-1</span>])</span><br><span class="line">    one_hot_ids = tf.one_hot(flat_token_type_ids, depth=token_type_vocab_size) </span><br><span class="line">    token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)</span><br><span class="line">    token_type_embeddings = tf.reshape(token_type_embeddings,</span><br><span class="line">                                       [batch_size, seq_length, width])</span><br><span class="line">    output += token_type_embeddings <span class="comment"># 直接按位加</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> use_position_embeddings:</span><br><span class="line">    assert_op = tf.assert_less_equal(seq_length, max_position_embeddings) <span class="comment"># 输入合法性判断</span></span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([assert_op]):</span><br><span class="line">      full_position_embeddings = tf.get_variable(</span><br><span class="line">          name=position_embedding_name,</span><br><span class="line">          shape=[max_position_embeddings, width],</span><br><span class="line">          initializer=create_initializer(initializer_range))</span><br><span class="line">      <span class="comment"># 截取 [0, 1, ... seq_length-1] 区间的 embedding_table，更快 </span></span><br><span class="line">      position_embeddings = tf.slice(full_position_embeddings, [<span class="number">0</span>, <span class="number">0</span>], [seq_length, <span class="number">-1</span>])</span><br><span class="line">      num_dims = len(output.shape.as_list())</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Only the last two dimensions are relevant (`seq_length` and `width`), so</span></span><br><span class="line">      <span class="comment"># we broadcast among the first dimensions —— the batch size.</span></span><br><span class="line">      position_broadcast_shape = []</span><br><span class="line">      <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_dims - <span class="number">2</span>):</span><br><span class="line">        position_broadcast_shape.append(<span class="number">1</span>)</span><br><span class="line">      position_broadcast_shape.extend([seq_length, width])</span><br><span class="line">      position_embeddings = tf.reshape(position_embeddings,</span><br><span class="line">                                       position_broadcast_shape)</span><br><span class="line">      output += position_embeddings <span class="comment"># 直接按位加</span></span><br><span class="line"></span><br><span class="line">  output = layer_norm_and_dropout(output, dropout_prob)</span><br><span class="line">  <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Transformer 模型</strong></p>
<ul>
<li><p>transformer_model</p>
<table>
<td><img src="/bert-squad-tf/image-20190703013613264.png" width="70%"></td>
  <td><img src="/bert-squad-tf/image-20190702234605092.png" width="100%"></td>
</table>
</li>
<li><p>Scaled Dot-Product Attention</p>
<script type="math/tex; mode=display">\text { Attention }(Q, K, V)=\operatorname{softmax}\big(\displaystyle\frac{Q K^{T}}{\sqrt{d_{k}}}\big) V</script><ul>
<li><p>queries and keys of dimension <script type="math/tex">d_k</script>，values of dimension <script type="math/tex">d_v</script></p>
</li>
<li><p>queries, keys and values are  packed together into matrices <script type="math/tex">Q</script>, <script type="math/tex">K</script> and <script type="math/tex">V</script>.</p>
</li>
<li><p>why scale the product by <script type="math/tex">\begin{equation}
  \frac{1}{\sqrt{d_{k}}}
\end{equation}</script>: for large values of <script type="math/tex">d_k</script>, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients.</p>
</li>
</ul>
</li>
<li><p>Multi-Head Attention</p>
<script type="math/tex; mode=display">\begin{aligned} \text { MultiHead }(Q, K, V) &=\text {Concat}\left(\text { head}_{1}, \ldots, \text { head}_{h}\right) W^{O} \\ \text { where head }_{i} &=\text {Attention}\left(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\right) \end{aligned}</script><ul>
<li><script type="math/tex; mode=display">W_{i}^{Q} \in \mathbb{R}^{d_{\text {model}} \times d_{k}}, W_{i}^{K} \in \mathbb{R}^{d_{\text {model}} \times d_{k}}, W_{i}^{V} \in \mathbb{R}^{d_{\text {model}} \times d_{v}}, W^{O} \in \mathbb{R}^{h d_{v} \times d_{\text {model}}}</script><ul>
<li><script type="math/tex; mode=display">d_{k}=d_{v}=d_{\mathrm{model}} / h</script></li>
</ul>
</li>
<li><p>Position-wise Feed-Forward Networks</p>
<script type="math/tex; mode=display">\operatorname{FFN}(x)=\text{activation}\left(x W_{1}+b_{1}\right) W_{2}+b_{2}</script><ul>
<li>Another way of describing this is as two convolutions with kernel size 1</li>
</ul>
<p>详细的 Transformer 相关的可以参照原论文和代码实现。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transformer_model</span><span class="params">(input_tensor,	# [batch_size, seq_length, hidden_size]</span></span></span><br><span class="line"><span class="function"><span class="params">                        attention_mask=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                      hidden_size=<span class="number">768</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        num_hidden_layers=<span class="number">12</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      num_attention_heads=<span class="number">12</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        intermediate_size=<span class="number">3072</span>, # FFN 使用</span></span></span><br><span class="line"><span class="function"><span class="params">                        intermediate_act_fn=gelu,</span></span></span><br><span class="line"><span class="function"><span class="params">                        hidden_dropout_prob=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      attention_probs_dropout_prob=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      do_return_all_layers=False)</span>:</span></span><br><span class="line">    <span class="string">"""Multi-headed, multi-layer Transformer from "Attention is All You Need".</span></span><br><span class="line"><span class="string">  https://arxiv.org/abs/1706.03762</span></span><br><span class="line"><span class="string">    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  <span class="keyword">if</span> hidden_size % num_attention_heads != <span class="number">0</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(...)</span><br><span class="line"></span><br><span class="line">    attention_head_size = int(hidden_size / num_attention_heads) <span class="comment"># d_k = d_v = d_model / h</span></span><br><span class="line">  input_shape = get_shape_list(input_tensor, expected_rank=<span class="number">3</span>)</span><br><span class="line">    batch_size = input_shape[<span class="number">0</span>]</span><br><span class="line">  seq_length = input_shape[<span class="number">1</span>]</span><br><span class="line">    input_width = input_shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># Re-shape 操作在 TPU 上产生额外开销，因此保留一份 2D 的 input_tensor </span></span><br><span class="line">    prev_output = reshape_to_matrix(input_tensor)</span><br><span class="line">  </span><br><span class="line">    all_layer_outputs = []</span><br><span class="line">    <span class="keyword">for</span> layer_idx <span class="keyword">in</span> range(num_hidden_layers):</span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(<span class="string">"layer_%d"</span> % layer_idx):</span><br><span class="line">        layer_input = prev_output</span><br><span class="line">  </span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"attention"</span>):</span><br><span class="line">          attention_heads = [] <span class="comment"># 多个 sequence</span></span><br><span class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">"self"</span>):</span><br><span class="line">            attention_head = attention_layer(...)</span><br><span class="line">            attention_heads.append(attention_head)</span><br><span class="line">  </span><br><span class="line">          attention_output = <span class="literal">None</span></span><br><span class="line">          <span class="keyword">if</span> len(attention_heads) == <span class="number">1</span>:</span><br><span class="line">            attention_output = attention_heads[<span class="number">0</span>]</span><br><span class="line">          <span class="keyword">else</span>: <span class="comment"># </span></span><br><span class="line">            <span class="comment"># In the case where we have other sequences, we just concatenate</span></span><br><span class="line">            <span class="comment"># them to the self-attention head before the projection.</span></span><br><span class="line">            attention_output = tf.concat(attention_heads, axis=<span class="number">-1</span>)</span><br><span class="line">  				</span><br><span class="line">          <span class="comment"># 对齐到 `hidden_size`</span></span><br><span class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">"output"</span>):</span><br><span class="line">            attention_output = tf.layers.dense(</span><br><span class="line">                attention_output,</span><br><span class="line">                hidden_size,</span><br><span class="line">                kernel_initializer=create_initializer(initializer_range))</span><br><span class="line">            attention_output = dropout(attention_output, hidden_dropout_prob)</span><br><span class="line">            <span class="comment"># Add &amp; Norm</span></span><br><span class="line">            attention_output = layer_norm(attention_output + layer_input) </span><br><span class="line">  			</span><br><span class="line">        <span class="comment"># FFN</span></span><br><span class="line">        <span class="comment"># The activation is only applied to the "intermediate" hidden layer.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"intermediate"</span>):</span><br><span class="line">          intermediate_output = tf.layers.dense(</span><br><span class="line">              attention_output,</span><br><span class="line">              intermediate_size,</span><br><span class="line">              activation=intermediate_act_fn,</span><br><span class="line">              kernel_initializer=create_initializer(initializer_range))</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># Down-project back to `hidden_size` then add the residual.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"output"</span>):</span><br><span class="line">          layer_output = tf.layers.dense(</span><br><span class="line">              intermediate_output,</span><br><span class="line">              hidden_size,</span><br><span class="line">              kernel_initializer=create_initializer(initializer_range))</span><br><span class="line">          layer_output = dropout(layer_output, hidden_dropout_prob)</span><br><span class="line">          <span class="comment"># Add &amp; Norm</span></span><br><span class="line">          layer_output = layer_norm(layer_output + attention_output)</span><br><span class="line">          prev_output = layer_output</span><br><span class="line">          all_layer_outputs.append(layer_output)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> do_return_all_layers:</span><br><span class="line">      final_outputs = []</span><br><span class="line">      <span class="keyword">for</span> layer_output <span class="keyword">in</span> all_layer_outputs:</span><br><span class="line">        final_output = reshape_from_matrix(layer_output, input_shape) <span class="comment"># 还原成 input_shape 格式</span></span><br><span class="line">        final_outputs.append(final_output)</span><br><span class="line">      <span class="keyword">return</span> final_outputs</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      final_output = reshape_from_matrix(prev_output, input_shape) <span class="comment"># 还原成 input_shape 格式</span></span><br><span class="line">      <span class="keyword">return</span> final_output</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>attention_layer</p>
<p>多头 attention 的计算，实际上多头机制通过矩阵的transposes 和 reshape 方式来并行实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_layer</span><span class="params">(from_tensor,</span></span></span><br><span class="line"><span class="function"><span class="params">                    to_tensor,</span></span></span><br><span class="line"><span class="function"><span class="params">                    attention_mask=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    num_attention_heads=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    size_per_head=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    query_act=None, # Activation function for the query transform.</span></span></span><br><span class="line"><span class="function"><span class="params">                    key_act=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    value_act=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    attention_probs_dropout_prob=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    initializer_range=<span class="number">0.02</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    do_return_2d_tensor=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                    batch_size=None, # <span class="number">2</span>D input 才需要</span></span></span><br><span class="line"><span class="function"><span class="params">                    from_seq_length=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    to_seq_length=None)</span>:</span></span><br><span class="line">  <span class="string">"""Performs multi-headed attention from `from_tensor` to `to_tensor`.</span></span><br><span class="line"><span class="string">  In practice, the multi-headed attention are done with transposes and</span></span><br><span class="line"><span class="string">  reshapes rather than actual separate tensors."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">transpose_for_scores</span><span class="params">(input_tensor, batch_size, num_attention_heads,</span></span></span><br><span class="line"><span class="function"><span class="params">                           seq_length, width)</span>:</span></span><br><span class="line">    output_tensor = tf.reshape(</span><br><span class="line">        input_tensor, [batch_size, seq_length, num_attention_heads, width])</span><br><span class="line"></span><br><span class="line">    output_tensor = tf.transpose(output_tensor, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">    <span class="keyword">return</span> output_tensor</span><br><span class="line"></span><br><span class="line">  from_shape = get_shape_list(from_tensor, expected_rank=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">  to_shape = get_shape_list(to_tensor, expected_rank=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment"># Scalar dimensions referenced here:</span></span><br><span class="line">  <span class="comment">#   B = batch size (number of sequences)</span></span><br><span class="line">  <span class="comment">#   F = `from_tensor` sequence length</span></span><br><span class="line">  <span class="comment">#   T = `to_tensor` sequence length</span></span><br><span class="line">  <span class="comment">#   N = `num_attention_heads`</span></span><br><span class="line">  <span class="comment">#   H = `size_per_head`</span></span><br><span class="line"></span><br><span class="line">  from_tensor_2d = reshape_to_matrix(from_tensor) <span class="comment"># [B*F, width]</span></span><br><span class="line">  to_tensor_2d = reshape_to_matrix(to_tensor) <span class="comment"># [B*T, width]</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># `query_layer` = [B*F, N*H]</span></span><br><span class="line">  query_layer = tf.layers.dense(</span><br><span class="line">      from_tensor_2d, <span class="comment">#</span></span><br><span class="line">      num_attention_heads * size_per_head,</span><br><span class="line">      activation=query_act,</span><br><span class="line">      name=<span class="string">"query"</span>,</span><br><span class="line">      kernel_initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `key_layer` = [B*T, N*H]</span></span><br><span class="line">  key_layer = tf.layers.dense(</span><br><span class="line">      to_tensor_2d, <span class="comment">#</span></span><br><span class="line">      num_attention_heads * size_per_head,</span><br><span class="line">      activation=key_act,</span><br><span class="line">      name=<span class="string">"key"</span>,</span><br><span class="line">      kernel_initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `value_layer` = [B*T, N*H]</span></span><br><span class="line">  value_layer = tf.layers.dense(</span><br><span class="line">      to_tensor_2d,</span><br><span class="line">      num_attention_heads * size_per_head,</span><br><span class="line">      activation=value_act,</span><br><span class="line">      name=<span class="string">"value"</span>,</span><br><span class="line">      kernel_initializer=create_initializer(initializer_range))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `query_layer` = [B, N, F, H]</span></span><br><span class="line">  query_layer = transpose_for_scores(query_layer, batch_size,</span><br><span class="line">                                     num_attention_heads, from_seq_length,</span><br><span class="line">                                     size_per_head)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `key_layer` = [B, N, T, H]</span></span><br><span class="line">  key_layer = transpose_for_scores(key_layer, batch_size, num_attention_heads,</span><br><span class="line">                                   to_seq_length, size_per_head)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Dot product between "query" and "key" to get the raw attention scores.</span></span><br><span class="line">  <span class="comment"># `attention_scores` = [B, N, F, T]</span></span><br><span class="line">  attention_scores = tf.matmul(query_layer, key_layer, transpose_b=<span class="literal">True</span>)</span><br><span class="line">  attention_scores = tf.multiply(attention_scores,</span><br><span class="line">                                 <span class="number">1.0</span> / math.sqrt(float(size_per_head)))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> attention_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># `attention_mask` = [B, 1, F, T]</span></span><br><span class="line">    attention_mask = tf.expand_dims(attention_mask, axis=[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将被 mask 掉的地方的 attention 值设置为很小的负数，这样在做 softmax 后，</span></span><br><span class="line">    <span class="comment"># 这些位置的概率为 0.</span></span><br><span class="line">    adder = (<span class="number">1.0</span> - tf.cast(attention_mask, tf.float32)) * <span class="number">-10000.0</span></span><br><span class="line">    attention_scores += adder</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Normalize the attention scores to probabilities.</span></span><br><span class="line">  <span class="comment"># `attention_probs` = [B, N, F, T]</span></span><br><span class="line">  attention_probs = tf.nn.softmax(attention_scores)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># This is actually dropping out entire tokens to attend to, which might</span></span><br><span class="line">  <span class="comment"># seem a bit unusual, but is taken from the original Transformer paper.</span></span><br><span class="line">  attention_probs = dropout(attention_probs, attention_probs_dropout_prob)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `value_layer` = [B, T, N, H]</span></span><br><span class="line">  value_layer = tf.reshape(</span><br><span class="line">      value_layer,</span><br><span class="line">      [batch_size, to_seq_length, num_attention_heads, size_per_head])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `value_layer` = [B, N, T, H]</span></span><br><span class="line">  value_layer = tf.transpose(value_layer, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `context_layer` = [B, N, F, H]</span></span><br><span class="line">  context_layer = tf.matmul(attention_probs, value_layer)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># `context_layer` = [B, F, N, H]</span></span><br><span class="line">  context_layer = tf.transpose(context_layer, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> do_return_2d_tensor:</span><br><span class="line">    <span class="comment"># `context_layer` = [B*F, N*H]</span></span><br><span class="line">    context_layer = tf.reshape(</span><br><span class="line">        context_layer,</span><br><span class="line">        [batch_size * from_seq_length, num_attention_heads * size_per_head])</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># `context_layer` = [B, F, N*H]</span></span><br><span class="line">    context_layer = tf.reshape(</span><br><span class="line">        context_layer,</span><br><span class="line">        [batch_size, from_seq_length, num_attention_heads * size_per_head])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> context_layer</span><br></pre></td></tr></table></figure>
</li>
<li><p>layer_norm_and_dropout</p>
<p>这个函数组没啥好说的，如代码所示。如果这个都看不懂，别继续看了。</p>
<p>参考论文 <a href="https://arxiv.org/abs/1607.06450" target="_blank" rel="noopener">https://arxiv.org/abs/1607.06450</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span><span class="params">(input_tensor, dropout_prob)</span>:</span> <span class="comment"># NOT of *keeping* a dimension as in `tf.nn.dropout`</span></span><br><span class="line">  <span class="keyword">if</span> dropout_prob <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> dropout_prob == <span class="number">0.0</span>:</span><br><span class="line">    <span class="keyword">return</span> input_tensor</span><br><span class="line">  output = tf.nn.dropout(input_tensor, <span class="number">1.0</span> - dropout_prob)</span><br><span class="line">  <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_norm</span><span class="params">(input_tensor, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Run layer normalization on the last dimension of the tensor."""</span></span><br><span class="line">  <span class="keyword">return</span> tf.contrib.layers.layer_norm(</span><br><span class="line">      inputs=input_tensor, begin_norm_axis=<span class="number">-1</span>, begin_params_axis=<span class="number">-1</span>, scope=name)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_norm_and_dropout</span><span class="params">(input_tensor, dropout_prob, name=None)</span>:</span></span><br><span class="line">  <span class="string">"""Runs layer normalization followed by dropout."""</span></span><br><span class="line">  output_tensor = layer_norm(input_tensor, name)</span><br><span class="line">  output_tensor = dropout(output_tensor, dropout_prob)</span><br><span class="line">  <span class="keyword">return</span> output_tensor</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_activation</p>
<p>根据名称返回对应的激活函数，支持 “linear” / “relu” / “gelu” / “tanh”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_activation</span><span class="params">(activation_string)</span>:</span></span><br><span class="line">  <span class="string">"""Maps a string to a Python function, e.g., "relu" =&gt; `tf.nn.relu`."""</span></span><br><span class="line">  ...</span><br><span class="line">  act = activation_string.lower()</span><br><span class="line">  <span class="keyword">if</span> act == <span class="string">"linear"</span>:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
</li>
<li><p>gelu</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gelu</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="string">"""Gaussian Error Linear Unit.</span></span><br><span class="line"><span class="string">  Original paper: https://arxiv.org/abs/1606.08415</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  cdf = <span class="number">0.5</span> * (<span class="number">1.0</span> + tf.tanh(</span><br><span class="line">      (np.sqrt(<span class="number">2</span> / np.pi) * (x + <span class="number">0.044715</span> * tf.pow(x, <span class="number">3</span>)))))</span><br><span class="line">  <span class="keyword">return</span> x * cdf</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>BertConfig类</strong><br>关键配置：</p>
<p>​    <script type="math/tex">\text{BERT}_\text{BASE}</script>  (L=12, H=768, A=12, Total Parameters=110M)  </p>
<p>​    <script type="math/tex">\text{BERT}_\text{LARGE}</script>  (L=24, H=1024, A=16, Total Parameters=340M).</p>
<p>​    L: num_hidden_layers, H: hidden_size, A: num_attention_heads</p>
<p>代码运行逻辑：</p>
<p>​    BertConfig.from_json_file(FLAGS.bert_config_file)  —&gt; cls.from_dict(json.loads(text)) ，在 from_dict 函数中完成 BertConfig 实例化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BertConfig</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Configuration for `BertModel`."""</span></span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, hidden_size=<span class="number">768</span>, num_hidden_layers=<span class="number">12</span>, num_attention_heads=<span class="number">12</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               intermediate_size=<span class="number">3072</span>, hidden_act=<span class="string">"gelu"</span>, hidden_dropout_prob=<span class="number">0.1</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               attention_probs_dropout_prob=<span class="number">0.1</span>, max_position_embeddings=<span class="number">512</span>, type_vocab_size=<span class="number">16</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               initializer_range=<span class="number">0.02</span>)</span>:</span></span><br><span class="line">    <span class="string">"""...</span></span><br><span class="line"><span class="string">      intermediate_size: The size of the "intermediate" (i.e., feed-forward)</span></span><br><span class="line"><span class="string">        layer in the Transformer encoder.</span></span><br><span class="line"><span class="string">      ...</span></span><br><span class="line"><span class="string">      max_position_embeddings: The maximum sequence length that this model might</span></span><br><span class="line"><span class="string">        ever be used with. Typically set this to something large just in case</span></span><br><span class="line"><span class="string">        (e.g., 512 or 1024 or 2048).</span></span><br><span class="line"><span class="string">      ...</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    self.vocab_size = vocab_size</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">from_dict</span><span class="params">(cls, json_object)</span>:</span></span><br><span class="line">    <span class="string">"""Constructs a `BertConfig` from a Python dictionary of parameters."""</span></span><br><span class="line">    config = BertConfig(vocab_size=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> (key, value) <span class="keyword">in</span> six.iteritems(json_object):</span><br><span class="line">      config.__dict__[key] = value</span><br><span class="line">    <span class="keyword">return</span> config</span><br><span class="line"></span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">from_json_file</span><span class="params">(cls, json_file)</span>:</span> <span class="comment"># 例: json_file='/root/bert/uncased_L-12_H-768_A-12/bert_config.json'</span></span><br><span class="line">    <span class="string">"""Constructs a `BertConfig` from a json file of parameters."""</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(json_file, <span class="string">"r"</span>) <span class="keyword">as</span> reader:</span><br><span class="line">      text = reader.read()</span><br><span class="line">    <span class="keyword">return</span> cls.from_dict(json.loads(text))</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">to_dict</span><span class="params">(self)</span>:</span> <span class="comment"># 将对象转成字典</span></span><br><span class="line">    <span class="string">"""Serializes this instance to a Python dictionary."""</span></span><br><span class="line">    output = copy.deepcopy(self.__dict__)</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">to_json_string</span><span class="params">(self)</span>:</span> <span class="comment"># 将对象转成json</span></span><br><span class="line">    <span class="string">"""Serializes this instance to a JSON string."""</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(self.to_dict(), indent=<span class="number">2</span>, sort_keys=<span class="literal">True</span>) + <span class="string">"\n"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>BertModel类</strong></p>
<p>构建输入：</p>
<table><img src="/bert-squad-tf/image-20190702200034350.png" width="70%" align="left"></table>

<p>构造函数的代码逻辑：</p>
<p>获取模型配置 -&gt; 根据是否训练设置dropout -&gt; 检查mask和type -&gt; 计算输入embedding -&gt; # 使用多层 Transformer Block 处理 -&gt; Transformer的输出用于下游任务</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BertModel</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""BERT model ("Bidirectional Encoder Representations from Transformers").</span></span><br><span class="line"><span class="string">  Example usage:</span></span><br><span class="line"><span class="string">    ```python</span></span><br><span class="line"><span class="string">  # Already been converted into WordPiece token ids</span></span><br><span class="line"><span class="string">    input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])</span></span><br><span class="line"><span class="string">  input_mask = tf.constant([[1, 1, 1], [1, 1, 0]])</span></span><br><span class="line"><span class="string">    token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    config = modeling.BertConfig(vocab_size=32000, hidden_size=512,</span></span><br><span class="line"><span class="string">      num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    model = modeling.BertModel(config=config, is_training=True,</span></span><br><span class="line"><span class="string">      input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type_ids)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    label_embeddings = tf.get_variable(...)</span></span><br><span class="line"><span class="string">    pooled_output = model.get_pooled_output()</span></span><br><span class="line"><span class="string">    logits = tf.matmul(pooled_output, label_embeddings)</span></span><br><span class="line"><span class="string">    ...</span></span><br><span class="line"><span class="string">    ```</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                 config, # `BertConfig` 对象</span></span></span><br><span class="line"><span class="function"><span class="params">                 is_training, # bool. 控制是否使用 dropout</span></span></span><br><span class="line"><span class="function"><span class="params">                 input_ids, # int32 Tensor: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                 input_mask=None, # <span class="params">(optional)</span>int32 Tensor: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                 token_type_ids=None, # <span class="params">(optional)</span>int32 Tensor: [batch_size, seq_length]</span></span></span><br><span class="line"><span class="function"><span class="params">                 use_one_hot_embeddings=False, # word embeddings 使用 one-hot embeddings 还是 tf.embedding_lookup<span class="params">()</span></span></span></span><br><span class="line"><span class="function"><span class="params">                 scope=None)</span>:</span></span><br><span class="line">  </span><br><span class="line">      config = copy.deepcopy(config)</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> is_training: <span class="comment"># eval 模式不使用 dropout</span></span><br><span class="line">        config.hidden_dropout_prob = <span class="number">0.0</span></span><br><span class="line">        config.attention_probs_dropout_prob = <span class="number">0.0</span></span><br><span class="line">  </span><br><span class="line">      input_shape = get_shape_list(input_ids, expected_rank=<span class="number">2</span>) <span class="comment"># [12, 384]</span></span><br><span class="line">      batch_size = input_shape[<span class="number">0</span>]</span><br><span class="line">      seq_length = input_shape[<span class="number">1</span>]</span><br><span class="line">  </span><br><span class="line">      <span class="comment"># 检查 mask 和 type</span></span><br><span class="line">      <span class="keyword">if</span> input_mask <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># 没有指定 mask 就认为所有位置都是真实tokens，全部需要 attend</span></span><br><span class="line">        input_mask = tf.ones(shape=[batch_size, seq_length], dtype=tf.int32)</span><br><span class="line">      <span class="keyword">if</span> token_type_ids <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># 没有指定 type 就把整个输入当作一个 type/segment</span></span><br><span class="line">        token_type_ids = tf.zeros(shape=[batch_size, seq_length], dtype=tf.int32)</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(scope, default_name=<span class="string">"bert"</span>):</span><br><span class="line">        <span class="comment"># 计算输入embedding</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"embeddings"</span>):</span><br><span class="line">          <span class="comment"># Perform embedding lookup on the word ids.</span></span><br><span class="line">          (self.embedding_output, self.embedding_table) = embedding_lookup(...)</span><br><span class="line">          <span class="comment"># word embeddings + positional embeddings + token type embeddings</span></span><br><span class="line">          <span class="comment"># 然后 layer normalize &amp; perform dropout.</span></span><br><span class="line">          self.embedding_output = embedding_postprocessor(...)</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 使用多层 Transformer Block 处理</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"encoder"</span>):</span><br><span class="line">          <span class="comment"># 计算在 attention 矩阵中要 mask 掉的位置</span></span><br><span class="line">          attention_mask = create_attention_mask_from_input_mask(input_ids, input_mask)</span><br><span class="line">          <span class="comment"># Run the stacked transformer.</span></span><br><span class="line">          <span class="comment"># `sequence_output` shape = [batch_size, seq_length, hidden_size].</span></span><br><span class="line">          self.all_encoder_layers = transformer_model(...)</span><br><span class="line">  			</span><br><span class="line">        <span class="comment"># Transformer的输出用于下游任务</span></span><br><span class="line">        self.sequence_output = self.all_encoder_layers[<span class="number">-1</span>] <span class="comment"># 最后的 hidden_layer</span></span><br><span class="line">        <span class="comment"># 使用最后hidden_layer 的 [cls] 位置的输出来完成 classification 的下游任务</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"pooler"</span>):</span><br><span class="line">          first_token_tensor = tf.squeeze(self.sequence_output[:, <span class="number">0</span>:<span class="number">1</span>, :], axis=<span class="number">1</span>)</span><br><span class="line">          self.pooled_output = tf.layers.dense(</span><br><span class="line">              first_token_tensor,</span><br><span class="line">              config.hidden_size,</span><br><span class="line">              activation=tf.tanh,</span><br><span class="line">              kernel_initializer=create_initializer(config.initializer_range))</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 返回 [CLS] 位置的向量用于下游任务</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pooled_output</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.pooled_output</span><br><span class="line">  	<span class="comment"># 返回最后的 hidden_layer 的每个位置的输出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_sequence_output</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="string">"""Gets final hidden layer of encoder: [batch_size, seq_length, hidden_size]"""</span></span><br><span class="line">      <span class="keyword">return</span> self.sequence_output</span><br><span class="line">  	<span class="comment"># 参数设置返回所有层的每个位置的输出，或最后的 hidden_layer 的每个位置的输出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_encoder_layers</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.all_encoder_layers</span><br><span class="line">  	<span class="comment"># 返回输入embedding</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_embedding_output</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.embedding_output</span><br><span class="line">  	<span class="comment"># 返回embedding_table</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_embedding_table</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> self.embedding_table</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h6 id="optimization-py"><a href="#optimization-py" class="headerlink" title="optimization.py"></a>optimization.py</h6><p><img src="/bert-squad-tf/image-20190703184633330.png" alt="image-20190703184633330"></p>
<ul>
<li><p>create_optimizer</p>
<p>BERT 论文里：We use Adam with learning rate of 1e-4, <script type="math/tex">β_1</script> = 0.9, <script type="math/tex">β_2</script> = 0.999, L2 weight decay of 0.01, learning rate warm-up over the first 10,000 steps, and linear decay of the learning rate. </p>
<p>该函数的流程为：计算学习率（先 warm_up 后 线性衰减） -&gt; 创建优化器 -&gt; 计算梯度 -&gt; 裁剪梯度 -&gt; 更新参数和global_step</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_optimizer</span><span class="params">(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu)</span>:</span></span><br><span class="line">  <span class="string">"""Creates an optimizer training op."""</span></span><br><span class="line">  global_step = tf.train.get_or_create_global_step()</span><br><span class="line"></span><br><span class="line">  learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 线性衰减学习率 `power` = 1.0</span></span><br><span class="line">  <span class="comment"># global_step = min(global_step, decay_steps)</span></span><br><span class="line">	<span class="comment"># decayed_learning_rate = (learning_rate - end_learning_rate) *</span></span><br><span class="line">  <span class="comment">#                      (1 - global_step / decay_steps) ^ (power) +</span></span><br><span class="line">  <span class="comment">#                      end_learning_rate</span></span><br><span class="line">  learning_rate = tf.train.polynomial_decay(...) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># Implements linear warmup. I.e., if global_step &lt; num_warmup_steps, the</span></span><br><span class="line">  <span class="comment"># learning rate will be `global_step/num_warmup_steps * init_lr`.</span></span><br><span class="line">  <span class="keyword">if</span> num_warmup_steps:</span><br><span class="line">    global_steps_int = tf.cast(global_step, tf.int32)</span><br><span class="line">    warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    global_steps_float = tf.cast(global_steps_int, tf.float32)</span><br><span class="line">    warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)</span><br><span class="line"></span><br><span class="line">    warmup_percent_done = global_steps_float / warmup_steps_float</span><br><span class="line">    warmup_learning_rate = init_lr * warmup_percent_done</span><br><span class="line">		<span class="comment"># 根据 global_steps 选择是 warmup 阶段 还是 decay 阶段</span></span><br><span class="line">    is_warmup = tf.cast(global_steps_int &lt; warmup_steps_int, tf.float32)</span><br><span class="line">    learning_rate = (</span><br><span class="line">        (<span class="number">1.0</span> - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 推荐在 fine-tune 阶段使用这个 optimizer (保持一致性)</span></span><br><span class="line">  <span class="comment"># Adam m/v variables **不** 从 init_checkpoint 加载</span></span><br><span class="line">  optimizer = AdamWeightDecayOptimizer(...)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># CrossShardOptimizer 与本地训练不兼容，要在本地和 Cloud TPU 上运行相同代码，请添加：</span></span><br><span class="line">  <span class="keyword">if</span> use_tpu: </span><br><span class="line">    <span class="comment"># 这个接口似乎有 bug，目前官方文档中已经 404</span></span><br><span class="line">    <span class="comment"># 使用 allreduce 聚合梯度并将结果广播到各个分片（每个 TPU 核）</span></span><br><span class="line">    optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)</span><br><span class="line">	</span><br><span class="line">  <span class="comment"># 对可训练变量计算梯度</span></span><br><span class="line">  tvars = tf.trainable_variables()</span><br><span class="line">  grads = tf.gradients(loss, tvars)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 梯度截断使用 clip_by_global_norm(t_list, clip_norm, ...)</span></span><br><span class="line">  <span class="comment"># global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))</span></span><br><span class="line">  <span class="comment"># t_list[i] * clip_norm / max(global_norm, clip_norm)</span></span><br><span class="line">  <span class="comment"># 参考 http://arxiv.org/pdf/1211.5063.pdf</span></span><br><span class="line">  (grads, _) = tf.clip_by_global_norm(grads, clip_norm=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">  train_op = optimizer.apply_gradients(</span><br><span class="line">      zip(grads, tvars), global_step=global_step) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># 通常在 apply_gradients 中更新 global_step，我们在这里更新</span></span><br><span class="line">  new_global_step = global_step + <span class="number">1</span></span><br><span class="line">  train_op = tf.group(train_op, [global_step.assign(new_global_step)])</span><br><span class="line">  <span class="keyword">return</span> train_op</span><br></pre></td></tr></table></figure>
</li>
<li><p>AdamWeightDecayOptimizer</p>
<p>Adam 优化器：</p>
<ul>
<li><p>Initialization: </p>
<script type="math/tex; mode=display">\begin{array}{c}{m_{0} :=0(\text { Initialize initial } 1 \text { st moment vector })} \\ {v_{0} :=0(\text { Initialize initial } 2 \text { nd moment vector })} \\ {t :=0(\text { Initialize timestep })}\end{array}</script></li>
<li><p>update rule:</p>
<script type="math/tex; mode=display">\begin{array}{c}{t :=t+1} \\ {l r_{t} :=\text { learning_rate } * \sqrt{1-\text { beta}_{2}^{t}} /\left(1-\text { beta}_{1}^{t}\right)} \\ {m_{t} :=b e t a_{1} * m_{t-1}+\left(1-b e t a_{1}\right) * g} \\ {v_{t} :=b e t a_{2} * v_{t-1}+\left(1-\text { bet } a_{2}\right) * g * g} \\ {\text {variable} :=\text {variable}-l r_{t} * m_{t} /\left(\sqrt{v_{t}}+\epsilon\right)}\\\end{array}</script><ul>
<li><script type="math/tex">m_t</script> 是一阶动量，<script type="math/tex">v_t</script> 是二阶动量，<script type="math/tex">g</script> 是梯度</li>
</ul>
<p>参考论文 &lt;<a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1412.6980.pdf</a></p>
</li>
</ul>
<p>Adam 的 weight decay：bert训练采用的优化方法就是adamw，对除了layernorm，bias项之外的模型参数做weight decay。</p>
<ul>
<li>将权重的平方和加到损失函数中<strong>不是</strong>正确的 Adam 的 weight decay。</li>
<li>这种方式等价于 SGD 的 L2 regularization。<br>可以参见ICLR 2019这篇文章 <a href="https://arxiv.org/pdf/1711.05101.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.05101.pdf</a> 或者 通俗版 <a href="https://zhuanlan.zhihu.com/p/63982470" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63982470</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdamWeightDecayOptimizer</span><span class="params">(tf.train.Optimizer)</span>:</span></span><br><span class="line">  <span class="string">"""A basic Adam optimizer that includes "correct" L2 weight decay."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">               learning_rate,</span></span></span><br><span class="line"><span class="function"><span class="params">               weight_decay_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               beta_1=<span class="number">0.9</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               beta_2=<span class="number">0.999</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               epsilon=<span class="number">1e-6</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               exclude_from_weight_decay=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               name=<span class="string">"AdamWeightDecayOptimizer"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Constructs a AdamWeightDecayOptimizer."""</span></span><br><span class="line">    super(AdamWeightDecayOptimizer, self).__init__(<span class="literal">False</span>, name)</span><br><span class="line">    self.learning_rate = learning_rate</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 更新参数</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply_gradients</span><span class="params">(self, grads_and_vars, global_step=None, name=None)</span>:</span></span><br><span class="line">    <span class="string">"""See base class."""</span></span><br><span class="line">    assignments = []</span><br><span class="line">    <span class="keyword">for</span> (grad, param) <span class="keyword">in</span> grads_and_vars:</span><br><span class="line">      <span class="keyword">if</span> grad <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> param <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">      param_name = self._get_variable_name(param.name)</span><br><span class="line">			</span><br><span class="line">      <span class="comment"># 一阶动量</span></span><br><span class="line">      m = tf.get_variable(</span><br><span class="line">          name=param_name + <span class="string">"/adam_m"</span>,</span><br><span class="line">          shape=param.shape.as_list(),</span><br><span class="line">          dtype=tf.float32,</span><br><span class="line">          trainable=<span class="literal">False</span>,</span><br><span class="line">          initializer=tf.zeros_initializer())</span><br><span class="line">      <span class="comment"># 二阶动量</span></span><br><span class="line">      v = tf.get_variable(</span><br><span class="line">          name=param_name + <span class="string">"/adam_v"</span>,</span><br><span class="line">          shape=param.shape.as_list(),</span><br><span class="line">          dtype=tf.float32,</span><br><span class="line">          trainable=<span class="literal">False</span>,</span><br><span class="line">          initializer=tf.zeros_initializer())</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Standard Adam update.</span></span><br><span class="line">      next_m = (</span><br><span class="line">          tf.multiply(self.beta_1, m) + tf.multiply(<span class="number">1.0</span> - self.beta_1, grad))</span><br><span class="line">      next_v = (</span><br><span class="line">          tf.multiply(self.beta_2, v) + tf.multiply(<span class="number">1.0</span> - self.beta_2,</span><br><span class="line">                                                    tf.square(grad)))</span><br><span class="line">      update = next_m / (tf.sqrt(next_v) + self.epsilon)</span><br><span class="line">			</span><br><span class="line">      <span class="comment"># Adam 的正确 weight decay 方式</span></span><br><span class="line">      <span class="keyword">if</span> self._do_use_weight_decay(param_name):</span><br><span class="line">        update += self.weight_decay_rate * param</span><br><span class="line"></span><br><span class="line">      update_with_lr = self.learning_rate * update</span><br><span class="line"></span><br><span class="line">      next_param = param - update_with_lr</span><br><span class="line"></span><br><span class="line">      assignments.extend(</span><br><span class="line">          [param.assign(next_param),</span><br><span class="line">           m.assign(next_m),</span><br><span class="line">           v.assign(next_v)])</span><br><span class="line">    <span class="keyword">return</span> tf.group(*assignments, name=name)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_do_use_weight_decay</span><span class="params">(self, param_name)</span>:</span></span><br><span class="line">    <span class="string">"""Whether to use L2 weight decay for `param_name`."""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.weight_decay_rate:</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> self.exclude_from_weight_decay: <span class="comment"># 本例中 ['LayerNorm', 'layer_norm', 'bias']</span></span><br><span class="line">      <span class="keyword">for</span> r <span class="keyword">in</span> self.exclude_from_weight_decay:</span><br><span class="line">        <span class="keyword">if</span> re.search(r, param_name) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_get_variable_name</span><span class="params">(self, param_name)</span>:</span></span><br><span class="line">    <span class="string">"""Get the variable name from the tensor name."""</span></span><br><span class="line">    m = re.match(<span class="string">"^(.*):\\d+$$"</span>, param_name)</span><br><span class="line">    <span class="keyword">if</span> m <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      param_name = m.group(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> param_name</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h6 id="run-squad-py"><a href="#run-squad-py" class="headerlink" title="run_squad.py"></a>run_squad.py</h6><p><img src="/bert-squad-tf/image-20190704121235449.png" alt="image-20190704121235449"></p>
<p>这是 Bert 运行 Squad 任务的主程序，使用了 Estimator 高级 API 实现，可以参考 <a href="https://www.tensorflow.org/guide/custom_estimators" target="_blank" rel="noopener">https://www.tensorflow.org/guide/custom_estimators</a> 详细了解特性和实现。</p>
<p>要根据预创建的 Estimator 编写 TensorFlow 程序，您必须执行下列任务：</p>
<ol>
<li><p>创建一个或多个输入函数。</p>
</li>
<li><p>定义模型的特征列。</p>
</li>
<li><p>实例化 Estimator，指定特征列和各种超参数。</p>
</li>
<li><p>在 Estimator 对象上调用一个或多个方法，传递适当的输入函数作为数据的来源。</p>
</li>
</ol>
<ul>
<li><p>import &amp; FLAGS</p>
<p>FLAGS 与运行参数对应：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">python run_squad.py \</span><br><span class="line">  --vocab_file=$$BERT_BASE_DIR/vocab.txt \</span><br><span class="line">  --bert_config_file=$$BERT_BASE_DIR/bert_config.json \</span><br><span class="line">  --init_checkpoint=$$BERT_BASE_DIR/bert_model.ckpt \</span><br><span class="line">  --do_train=True \</span><br><span class="line">  --train_file=$$SQUAD_DIR/train-v1.1.json \</span><br><span class="line">  --do_predict=True \</span><br><span class="line">  --predict_file=$$SQUAD_DIR/dev-v1.1.json \</span><br><span class="line">  --train_batch_size=12 \</span><br><span class="line">  --learning_rate=3e-5 \</span><br><span class="line">  --num_train_epochs=2.0 \</span><br><span class="line">  --max_seq_length=384 \</span><br><span class="line">  --doc_stride=128 \</span><br><span class="line">  --output_dir=/tmp/squad_base/</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line">...</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line">...</span><br><span class="line">flags = tf.flags</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"><span class="comment">## Required parameters</span></span><br><span class="line">flags.DEFINE_string(</span><br><span class="line">    <span class="string">"bert_config_file"</span>, <span class="literal">None</span>,</span><br><span class="line">    <span class="string">"The config json file corresponding to the pre-trained BERT model. "</span></span><br><span class="line">    <span class="string">"This specifies the model architecture."</span>)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>validate_flags_or_throw</p>
<p>对传入的部分参数进行检查：</p>
<p>​    检查指定大小写敏感是否和待加载模型相一致</p>
<p>​    检查运行模式，train / predict 至少一种，在每种模式下检查输输入文件</p>
<p>​    检查输入最大长度，不超过最大位置嵌入长度，不小于query最大长度+3</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate_flags_or_throw</span><span class="params">(bert_config)</span>:</span></span><br><span class="line">  <span class="comment"># 检查指定大小写敏感是否和待加载模型相一致</span></span><br><span class="line">  tokenization.validate_case_matches_checkpoint(FLAGS.do_lower_case, FLAGS.init_checkpoint)</span><br><span class="line">  <span class="comment"># 检查运行模式，train / predict 至少一种，在每种模式下检查输输入文件</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> FLAGS.do_train <span class="keyword">and</span> <span class="keyword">not</span> FLAGS.do_predict:</span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_train <span class="keyword">and</span> <span class="keyword">not</span> FLAGS.train_file:</span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_predict <span class="keyword">and</span> <span class="keyword">not</span> FLAGS.predict_file:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(...)</span><br><span class="line">	<span class="comment"># 检查输入最大长度，不超过最大位置嵌入长度，不小于query最大长度+3</span></span><br><span class="line">  <span class="keyword">if</span> FLAGS.max_seq_length &gt; bert_config.max_position_embeddings:</span><br><span class="line">  <span class="keyword">if</span> FLAGS.max_seq_length &lt;= FLAGS.max_query_length + <span class="number">3</span>: <span class="comment"># [cls]...[sep]...[sep] 占用三个位置</span></span><br><span class="line">    <span class="keyword">raise</span> ValueError(...)</span><br></pre></td></tr></table></figure>
</li>
<li><p>_compute_softmax</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_softmax</span><span class="params">(scores)</span>:</span></span><br><span class="line">  <span class="string">"""Compute softmax probability over raw logits."""</span></span><br><span class="line">  ...</span><br><span class="line">  max_score = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">for</span> score <span class="keyword">in</span> scores:</span><br><span class="line">    <span class="keyword">if</span> max_score <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> score &gt; max_score:</span><br><span class="line">      max_score = score</span><br><span class="line"></span><br><span class="line">  exp_scores = []</span><br><span class="line">  total_sum = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> score <span class="keyword">in</span> scores:</span><br><span class="line">    x = math.exp(score - max_score) <span class="comment"># 防止溢出</span></span><br><span class="line">    exp_scores.append(x)</span><br><span class="line">    total_sum += x</span><br><span class="line"></span><br><span class="line">  probs = []</span><br><span class="line">  <span class="keyword">for</span> score <span class="keyword">in</span> exp_scores:</span><br><span class="line">    probs.append(score / total_sum)</span><br><span class="line">  <span class="keyword">return</span> probs</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Squad输入</strong></p>
<ul>
<li><p><strong>SquadExample 类</strong></p>
<p>用于 Squad 任务的单个 example，主要包含四部分</p>
<p>​    context: doc_tokens</p>
<p>​    id: qas_id</p>
<p>​    question: question_text</p>
<p>​    answer: orig_answer_text / start_position / end_position / is_impossible</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SquadExample</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="comment"># 对于 answer 不存在的 example，start_position = end_position = -1</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">               qas_id,</span></span></span><br><span class="line"><span class="function"><span class="params">               question_text,</span></span></span><br><span class="line"><span class="function"><span class="params">               doc_tokens,</span></span></span><br><span class="line"><span class="function"><span class="params">               orig_answer_text=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               start_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               end_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               is_impossible=False)</span>:</span></span><br><span class="line">    self.qas_id = qas_id</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 用于显示的方法</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.__repr__()</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">    s = <span class="string">""</span></span><br><span class="line">    s += <span class="string">"qas_id: %s"</span> % (tokenization.printable_text(self.qas_id))</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>InputFeatures 类</strong></p>
<p>定义输入特征集合数据结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InputFeatures</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""A single set of features of data."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">               unique_id,</span></span></span><br><span class="line"><span class="function"><span class="params">               example_index,</span></span></span><br><span class="line"><span class="function"><span class="params">               doc_span_index,</span></span></span><br><span class="line"><span class="function"><span class="params">               tokens,</span></span></span><br><span class="line"><span class="function"><span class="params">               token_to_orig_map,</span></span></span><br><span class="line"><span class="function"><span class="params">               token_is_max_context,</span></span></span><br><span class="line"><span class="function"><span class="params">               input_ids,</span></span></span><br><span class="line"><span class="function"><span class="params">               input_mask,</span></span></span><br><span class="line"><span class="function"><span class="params">               segment_ids,</span></span></span><br><span class="line"><span class="function"><span class="params">               start_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               end_position=None,</span></span></span><br><span class="line"><span class="function"><span class="params">               is_impossible=None)</span>:</span></span><br><span class="line">    self.unique_id = unique_id</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
</li>
<li><p>read_squad_examples</p>
<p>从 .json 格式文件读取输入，解析成 SquadExample 结构</p>
<p>处理流程：load_json 文件 -&gt; 使用 whitespace 来对 context 分词得到 doc_tokens，并构建char到word的映射关系 -&gt; 解析道 qas_id 和 question_text -&gt; 处理 answer，得到 orig_answer_text / start_position / end_position / is_impossible -&gt;  SquadExample 结构</p>
<ul>
<li>这时候 start_position 和 end_position 已经是 词级别的了</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_squad_examples</span><span class="params">(input_file, is_training)</span>:</span></span><br><span class="line">  <span class="string">"""Read a SQuAD json file into a list of SquadExample."""</span></span><br><span class="line">  <span class="keyword">with</span> tf.gfile.Open(input_file, <span class="string">"r"</span>) <span class="keyword">as</span> reader:</span><br><span class="line">    input_data = json.load(reader)[<span class="string">"data"</span>] <span class="comment"># dict&#123;"data":..., "version":...&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">is_whitespace</span><span class="params">(c)</span>:</span> <span class="comment"># 疑问：ord(c) == 0x202F 和 tokenization.whitespace_tokenize 存在不一致，不会有问题？</span></span><br><span class="line">    <span class="keyword">if</span> c == <span class="string">" "</span> <span class="keyword">or</span> c == <span class="string">"\t"</span> <span class="keyword">or</span> c == <span class="string">"\r"</span> <span class="keyword">or</span> c == <span class="string">"\n"</span> <span class="keyword">or</span> ord(c) == <span class="number">0x202F</span>: <span class="comment"># ord(c) 返回字符c的unicode数值，0x202F 表示 NARROW NO-BREAK SPACE</span></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">  </span><br><span class="line">	<span class="string">""" input_data 数据结构</span></span><br><span class="line"><span class="string">	- input_data: [&#123;&#125;,...,&#123;&#125;]</span></span><br><span class="line"><span class="string">		- 'title': str</span></span><br><span class="line"><span class="string">		- 'paragraphs': [&#123;&#125;,...,&#123;&#125;]</span></span><br><span class="line"><span class="string">			- 'context': str</span></span><br><span class="line"><span class="string">			- 'qas': [&#123;&#125;,...,&#123;&#125;]</span></span><br><span class="line"><span class="string">				- 'id': str</span></span><br><span class="line"><span class="string">				- 'question': str</span></span><br><span class="line"><span class="string">				- 'answers': [&#123;&#125;] # __len__ = 1</span></span><br><span class="line"><span class="string">					- 'answer_start': int</span></span><br><span class="line"><span class="string">					- 'text': 'str</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">  examples = []</span><br><span class="line">  <span class="keyword">for</span> entry <span class="keyword">in</span> input_data: </span><br><span class="line">    <span class="keyword">for</span> paragraph <span class="keyword">in</span> entry[<span class="string">"paragraphs"</span>]:</span><br><span class="line">      <span class="comment"># 处理 context</span></span><br><span class="line">      paragraph_text = paragraph[<span class="string">"context"</span>]</span><br><span class="line">      doc_tokens = [] <span class="comment"># 一个 paragraph["context"] 中的所有 tokens</span></span><br><span class="line">      char_to_word_offset = [] <span class="comment"># 每个字符属于第几个 token</span></span><br><span class="line">      prev_is_whitespace = <span class="literal">True</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 以 whitespace 为 context 分词</span></span><br><span class="line">      <span class="keyword">for</span> c <span class="keyword">in</span> paragraph_text:</span><br><span class="line">        <span class="keyword">if</span> is_whitespace(c): <span class="comment"># whitespace 不保存，用来做 tokenize</span></span><br><span class="line">          prev_is_whitespace = <span class="literal">True</span> </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">if</span> prev_is_whitespace: <span class="comment"># whitespace 后面是一个新的 token</span></span><br><span class="line">            doc_tokens.append(c)</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            doc_tokens[<span class="number">-1</span>] += c <span class="comment"># 加入到当前 token</span></span><br><span class="line">          prev_is_whitespace = <span class="literal">False</span></span><br><span class="line">        char_to_word_offset.append(len(doc_tokens) - <span class="number">1</span>) <span class="comment"># 当前字符属于第几个 token</span></span><br><span class="line">			</span><br><span class="line">      <span class="comment"># 处理 question 和 answer</span></span><br><span class="line">      <span class="keyword">for</span> qa <span class="keyword">in</span> paragraph[<span class="string">"qas"</span>]:</span><br><span class="line">        qas_id = qa[<span class="string">"id"</span>]</span><br><span class="line">        question_text = qa[<span class="string">"question"</span>]</span><br><span class="line">        start_position = <span class="literal">None</span> <span class="comment"># answer 的开始位置</span></span><br><span class="line">        end_position = <span class="literal">None</span> <span class="comment"># answer 的结束位置</span></span><br><span class="line">        orig_answer_text = <span class="literal">None</span> <span class="comment"># 原始答案text</span></span><br><span class="line">        is_impossible = <span class="literal">False</span> <span class="comment"># 对于squad 2.0，存在没有 answer 的问题</span></span><br><span class="line">        <span class="keyword">if</span> is_training: <span class="comment"># 在 predict 阶段，json 文件中没有 answer</span></span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">            is_impossible = qa[<span class="string">"is_impossible"</span>]</span><br><span class="line">          <span class="keyword">if</span> (len(qa[<span class="string">"answers"</span>]) != <span class="number">1</span>) <span class="keyword">and</span> (<span class="keyword">not</span> is_impossible): <span class="comment"># 有 answer 的问题唯一解</span></span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">"For training, each question should have exactly 1 answer."</span>)</span><br><span class="line">          <span class="keyword">if</span> <span class="keyword">not</span> is_impossible: <span class="comment"># 有 answer</span></span><br><span class="line">            answer = qa[<span class="string">"answers"</span>][<span class="number">0</span>] <span class="comment"># 唯一解</span></span><br><span class="line">            orig_answer_text = answer[<span class="string">"text"</span>]</span><br><span class="line">            answer_offset = answer[<span class="string">"answer_start"</span>] <span class="comment"># 在 context 中 answer 的 char 级别的 offset</span></span><br><span class="line">            answer_length = len(orig_answer_text) <span class="comment"># answer 覆盖的 char 数目 </span></span><br><span class="line">            start_position = char_to_word_offset[answer_offset] <span class="comment"># char 级别的 offset 转换成 tokens 中的位置</span></span><br><span class="line">            end_position = char_to_word_offset[answer_offset + answer_length - <span class="number">1</span>] </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 去除可能由编码问题导致 answer 不能在原文找到</span></span><br><span class="line">            actual_text = <span class="string">" "</span>.join(</span><br><span class="line">                doc_tokens[start_position:(end_position + <span class="number">1</span>)])</span><br><span class="line">            cleaned_answer_text = <span class="string">" "</span>.join(</span><br><span class="line">                tokenization.whitespace_tokenize(orig_answer_text))</span><br><span class="line">            <span class="keyword">if</span> actual_text.find(cleaned_answer_text) == <span class="number">-1</span>:</span><br><span class="line">              tf.logging.warning(...)</span><br><span class="line">              <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">else</span>: <span class="comment"># 没有 answer 的问题，特殊处理</span></span><br><span class="line">            start_position = <span class="number">-1</span></span><br><span class="line">            end_position = <span class="number">-1</span></span><br><span class="line">            orig_answer_text = <span class="string">""</span></span><br><span class="line"></span><br><span class="line">        example = SquadExample(...)</span><br><span class="line">        examples.append(example)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>
</li>
<li><p>convert_examples_to_features</p>
<p>将 SquadExample 解析成 一个或多个 InputFeatures</p>
<p>流程：unique_id,example_index -&gt; 对 question_text 分词得到 query_tokens -&gt; 对 doc_tokens 进一步分词得到 all_doc_tokens，并建立两种 tokens 之间的映射关系 -&gt; 更新 answer 在 all_doc_tokens 中的 tok_start_position 和  tok_start_position -&gt; 使用滑动窗口机制处理 all_doc_tokens，每个 doc_span = [[‘CLS’] query_tokens [‘SEP’] doc_span_text [‘SEP’]] -&gt; 对其 answer 在当前 doc_span 中的起始位置 start_position 和  start_position  -&gt;  InputFeatures 结构 -&gt; 通过 FeatureWriter 写入到 TFRecord 文件中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_examples_to_features</span><span class="params">(examples, tokenizer, max_seq_length,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 doc_stride, max_query_length, is_training,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 output_fn)</span>:</span></span><br><span class="line">  unique_id = <span class="number">1000000000</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (example_index, example) <span class="keyword">in</span> enumerate(examples):</span><br><span class="line">    <span class="comment"># question_text 分词，使用 FullTokenizer.tokenize</span></span><br><span class="line">    query_tokens = tokenizer.tokenize(example.question_text) </span><br><span class="line">    <span class="keyword">if</span> len(query_tokens) &gt; max_query_length:</span><br><span class="line">      query_tokens = query_tokens[<span class="number">0</span>:max_query_length]</span><br><span class="line">      </span><br><span class="line">		<span class="comment"># FullTokenizer分词后的token在对应的 example.doc_tokens 里面的索引</span></span><br><span class="line">    <span class="comment"># 样例：&lt;class 'list'&gt;: [0, 0, 0, 1, 2, 3, 4, 4, ...]</span></span><br><span class="line">    tok_to_orig_index = [] </span><br><span class="line">    <span class="comment"># tok_to_orig_index 的逆，样例：&lt;class 'list'&gt;: [0, 3, 4, 5, ...]</span></span><br><span class="line">    orig_to_tok_index = []</span><br><span class="line">    </span><br><span class="line">    all_doc_tokens = []</span><br><span class="line">    <span class="keyword">for</span> (i, token) <span class="keyword">in</span> enumerate(example.doc_tokens):</span><br><span class="line">      orig_to_tok_index.append(len(all_doc_tokens))</span><br><span class="line">      sub_tokens = tokenizer.tokenize(token)</span><br><span class="line">      <span class="keyword">for</span> sub_token <span class="keyword">in</span> sub_tokens:</span><br><span class="line">        tok_to_orig_index.append(i)</span><br><span class="line">        all_doc_tokens.append(sub_token)</span><br><span class="line"></span><br><span class="line">    tok_start_position = <span class="literal">None</span></span><br><span class="line">    tok_end_position = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> is_training <span class="keyword">and</span> example.is_impossible: <span class="comment"># squad v2.0</span></span><br><span class="line">      tok_start_position = <span class="number">-1</span></span><br><span class="line">      tok_end_position = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">if</span> is_training <span class="keyword">and</span> <span class="keyword">not</span> example.is_impossible:</span><br><span class="line">      tok_start_position = orig_to_tok_index[example.start_position]</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 例如：ori[end_position] = "unaffable", tok = [..., "un", "##aff", "##able", ...]</span></span><br><span class="line">      <span class="comment"># orig_to_tok_index[end_position] 位置在 tok 中对应的是 "un"</span></span><br><span class="line">      <span class="comment"># orig_to_tok_index[end_position + 1] - 1 位置在 tok 中对应的是 "##able"</span></span><br><span class="line">      <span class="keyword">if</span> example.end_position &lt; len(example.doc_tokens) - <span class="number">1</span>:</span><br><span class="line">        tok_end_position = orig_to_tok_index[example.end_position + <span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">      <span class="comment"># 如果是 ori 中最后一个 token</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        tok_end_position = len(all_doc_tokens) - <span class="number">1</span></span><br><span class="line">      <span class="comment"># 得到更精准的 answer 的始末位置</span></span><br><span class="line">      (tok_start_position, tok_end_position) = _improve_answer_span(</span><br><span class="line">          all_doc_tokens, tok_start_position, tok_end_position, tokenizer,</span><br><span class="line">          example.orig_answer_text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The -3 accounts for [CLS], [SEP] and [SEP]</span></span><br><span class="line">    max_tokens_for_doc = max_seq_length - len(query_tokens) - <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为了处理超长的文本，使用 滑动窗口 机制</span></span><br><span class="line">    <span class="comment"># 每次滑动 doc_stride 的长度，窗口区间为 min(length, max_tokens_for_doc)</span></span><br><span class="line">    <span class="comment"># 相邻的 doc_span 之间会有重叠</span></span><br><span class="line">    _DocSpan = collections.namedtuple(<span class="string">"DocSpan"</span>, [<span class="string">"start"</span>, <span class="string">"length"</span>])</span><br><span class="line">    doc_spans = []</span><br><span class="line">    start_offset = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> start_offset &lt; len(all_doc_tokens):</span><br><span class="line">      length = len(all_doc_tokens) - start_offset <span class="comment"># 剩余未划分成 doc_span 的 tokens 长度</span></span><br><span class="line">      <span class="keyword">if</span> length &gt; max_tokens_for_doc:</span><br><span class="line">        length = max_tokens_for_doc</span><br><span class="line">      doc_spans.append(_DocSpan(start=start_offset, length=length))</span><br><span class="line">      <span class="keyword">if</span> start_offset + length == len(all_doc_tokens):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      start_offset += min(length, doc_stride) </span><br><span class="line">		</span><br><span class="line">    <span class="comment"># 对于每个窗口 doc_span，构建拼接的输入 [['CLS'] query_tokens ['SEP'] doc_span_text ['SEP']] </span></span><br><span class="line">    <span class="keyword">for</span> (doc_span_index, doc_span) <span class="keyword">in</span> enumerate(doc_spans):</span><br><span class="line">      tokens = []</span><br><span class="line">      token_to_orig_map = &#123;&#125;</span><br><span class="line">      token_is_max_context = &#123;&#125;</span><br><span class="line">      segment_ids = []</span><br><span class="line">      <span class="comment"># '[CLS]' query '[SEP]'</span></span><br><span class="line">      tokens.append(<span class="string">"[CLS]"</span>)</span><br><span class="line">      segment_ids.append(<span class="number">0</span>)</span><br><span class="line">      <span class="keyword">for</span> token <span class="keyword">in</span> query_tokens:</span><br><span class="line">        tokens.append(token)</span><br><span class="line">        segment_ids.append(<span class="number">0</span>)</span><br><span class="line">      tokens.append(<span class="string">"[SEP]"</span>)</span><br><span class="line">      segment_ids.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> range(doc_span.length):</span><br><span class="line">        split_token_index = doc_span.start + i <span class="comment"># 当前 token 在 all_doc_tokens[] 中的位置</span></span><br><span class="line">        token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]</span><br><span class="line"></span><br><span class="line">        is_max_context = _check_is_max_context(doc_spans, doc_span_index,</span><br><span class="line">                                               split_token_index)</span><br><span class="line">        token_is_max_context[len(tokens)] = is_max_context <span class="comment"># 当前 span 是否是当前 token 的最佳 context</span></span><br><span class="line">        tokens.append(all_doc_tokens[split_token_index])</span><br><span class="line">        segment_ids.append(<span class="number">1</span>)</span><br><span class="line">      tokens.append(<span class="string">"[SEP]"</span>)</span><br><span class="line">      segment_ids.append(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      input_ids = tokenizer.convert_tokens_to_ids(tokens) </span><br><span class="line"></span><br><span class="line">      <span class="comment"># mask=1 表示真实 token，需要被 attend 到</span></span><br><span class="line">      input_mask = [<span class="number">1</span>] * len(input_ids)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Zero-pad up to the sequence length.</span></span><br><span class="line">      <span class="keyword">while</span> len(input_ids) &lt; max_seq_length:</span><br><span class="line">        input_ids.append(<span class="number">0</span>)</span><br><span class="line">        input_mask.append(<span class="number">0</span>)</span><br><span class="line">        segment_ids.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">assert</span> len(input_ids) == max_seq_length</span><br><span class="line">      <span class="keyword">assert</span> len(input_mask) == max_seq_length</span><br><span class="line">      <span class="keyword">assert</span> len(segment_ids) == max_seq_length</span><br><span class="line"></span><br><span class="line">      start_position = <span class="literal">None</span></span><br><span class="line">      end_position = <span class="literal">None</span></span><br><span class="line">      <span class="keyword">if</span> is_training <span class="keyword">and</span> <span class="keyword">not</span> example.is_impossible:</span><br><span class="line">        <span class="comment"># For training, if our document chunk does not contain an annotation</span></span><br><span class="line">        <span class="comment"># we throw it out, since there is nothing to predict.</span></span><br><span class="line">        doc_start = doc_span.start</span><br><span class="line">        doc_end = doc_span.start + doc_span.length - <span class="number">1</span></span><br><span class="line">        out_of_span = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># answer 没有被完整包含在当前 span 中</span></span><br><span class="line">        <span class="comment"># 会不会 answer 在相邻 doc_span 中都恰好没有完全包含？？</span></span><br><span class="line">        <span class="comment"># 应该需要 doc_stride &lt;&lt; max_tokens_for_doc</span></span><br><span class="line">        <span class="comment"># 例如：answer = [token1 token2 token3]</span></span><br><span class="line">        <span class="comment"># 当前的span: [... token1 token2] token3 token4...</span></span><br><span class="line">        <span class="comment"># 下一个span: ... token1 [token2 token3 token4...] ...</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> (tok_start_position &gt;= doc_start <span class="keyword">and</span></span><br><span class="line">                tok_end_position &lt;= doc_end):</span><br><span class="line">          out_of_span = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> out_of_span:</span><br><span class="line">          start_position = <span class="number">0</span></span><br><span class="line">          end_position = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          doc_offset = len(query_tokens) + <span class="number">2</span> <span class="comment"># '[CLS]' query '[SEP]'</span></span><br><span class="line">          start_position = tok_start_position - doc_start + doc_offset <span class="comment"># 在当前拼接的输入中的位置</span></span><br><span class="line">          end_position = tok_end_position - doc_start + doc_offset</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> is_training <span class="keyword">and</span> example.is_impossible: <span class="comment"># squad v2.0</span></span><br><span class="line">        start_position = <span class="number">0</span></span><br><span class="line">        end_position = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> example_index &lt; <span class="number">20</span>:</span><br><span class="line">        tf.logging.info(...)</span><br><span class="line"></span><br><span class="line">      feature = InputFeatures(...)</span><br><span class="line">      <span class="comment"># 回调函数，通过 FeatureWriter 写入到 TFRecord 文件中</span></span><br><span class="line">      output_fn(feature)</span><br><span class="line"></span><br><span class="line">      unique_id += <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>_improve_answer_span</p>
<p>经过 WordPiece 分词后，可以得到更精准的答案起始位置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_improve_answer_span</span><span class="params">(doc_tokens, input_start, input_end, tokenizer,</span></span></span><br><span class="line"><span class="function"><span class="params">                         orig_answer_text)</span>:</span></span><br><span class="line">  <span class="string">"""Returns tokenized answer spans that better match the annotated answer."""</span></span><br><span class="line">  <span class="comment">#   Question: What year was John Smith born?</span></span><br><span class="line">  <span class="comment">#   Context: The leader was John Smith (1895-1943).</span></span><br><span class="line">  <span class="comment">#   Answer: 1895</span></span><br><span class="line">  <span class="comment"># orig_answer_text 可能只是Context中 token 的一部分，经过 WordPiece 分词后，可以有更精准的位置</span></span><br><span class="line">  </span><br><span class="line">  tok_answer_text = <span class="string">" "</span>.join(tokenizer.tokenize(orig_answer_text))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> new_start <span class="keyword">in</span> range(input_start, input_end + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> new_end <span class="keyword">in</span> range(input_end, new_start - <span class="number">1</span>, <span class="number">-1</span>):</span><br><span class="line">      text_span = <span class="string">" "</span>.join(doc_tokens[new_start:(new_end + <span class="number">1</span>)])</span><br><span class="line">      <span class="keyword">if</span> text_span == tok_answer_text:</span><br><span class="line">        <span class="keyword">return</span> (new_start, new_end)</span><br><span class="line">  </span><br><span class="line">	<span class="keyword">return</span> (input_start, input_end)</span><br></pre></td></tr></table></figure>
</li>
<li><p>FeatureWriter</p>
<p>将 InputFeature 写入到 TFRecords 文件，需要将每一个样本数据封装为tf.train.Example格式，再将Example逐个写入文件。</p>
<p>tf.train.Feature()的参数是BytesList, FloatList, Int64List三种。</p>
<p>tf.train.Features: 它的参数是一个字典，k-v对中 v 的类型是Feature，对应每一个字段。</p>
<p>流程：将每一个字段映射 Feature -&gt; 多个Feature组成Features -&gt; 将其封装为 tf.train.Example 就可以写入 tfrecords二进制文件了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureWriter</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Writes InputFeature to TF example file."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename, is_training)</span>:</span></span><br><span class="line">    self.filename = filename</span><br><span class="line">    self.is_training = is_training</span><br><span class="line">    self.num_features = <span class="number">0</span></span><br><span class="line">    self._writer = tf.python_io.TFRecordWriter(filename) <span class="comment"># 将 records 写入到 TFRecords 文件</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 将 InputFeature 解析成 tf.train.Example 写入到 tfrecords 文件</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">process_feature</span><span class="params">(self, feature)</span>:</span></span><br><span class="line">    <span class="string">"""Write a InputFeature to the TFRecordWriter as a tf.train.Example."""</span></span><br><span class="line">    self.num_features += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_int_feature</span><span class="params">(values)</span>:</span></span><br><span class="line">      <span class="comment"># 三种基础数据类型：bytes，float，int64</span></span><br><span class="line">			<span class="comment"># 对应tf.train中三种类型：BytesList(字符串列表), FloatList(浮点数列表), Int64List(64位整数列表)</span></span><br><span class="line">      feature = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))</span><br><span class="line">      <span class="keyword">return</span> feature</span><br><span class="line"></span><br><span class="line">    features = collections.OrderedDict()</span><br><span class="line">    features[<span class="string">"unique_ids"</span>] = create_int_feature([feature.unique_id])</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=features))</span><br><span class="line">    self._writer.write(tf_example.SerializeToString())</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">    self._writer.close()</span><br></pre></td></tr></table></figure>
</li>
<li><p>_check_is_max_context</p>
<p>检查当前 doc_span 是不是某个 position 的左&amp;右context 最丰富的 span</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_check_is_max_context</span><span class="params">(doc_spans, cur_span_index, position)</span>:</span></span><br><span class="line">  <span class="string">"""Check if this is the 'max context' doc span for the token."""</span></span><br><span class="line">	<span class="comment"># 用来给当前 position 选择出 左&amp;右context 最丰富的 span</span></span><br><span class="line">  <span class="comment"># Because of the sliding window approach taken to scoring documents, a single</span></span><br><span class="line">  <span class="comment"># token can appear in multiple documents. E.g.</span></span><br><span class="line">  <span class="comment">#  Doc: the man went to the store and bought a gallon of milk</span></span><br><span class="line">  <span class="comment">#  Span A: the man went to the</span></span><br><span class="line">  <span class="comment">#  Span B: to the store and bought</span></span><br><span class="line">  <span class="comment">#  Span C: and bought a gallon of</span></span><br><span class="line">  <span class="comment">#  ...</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># Now the word 'bought' will have two scores from spans B and C. We only</span></span><br><span class="line">  <span class="comment"># want to consider the score with "maximum context", which we define as</span></span><br><span class="line">  <span class="comment"># the *minimum* of its left and right context (the *sum* of left and</span></span><br><span class="line">  <span class="comment"># right context will always be the same, of course).</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># In the example the maximum context for 'bought' would be span C since</span></span><br><span class="line">  <span class="comment"># it has 1 left context and 3 right context, while span B has 4 left context</span></span><br><span class="line">  <span class="comment"># and 0 right context.</span></span><br><span class="line"> </span><br><span class="line">  best_score = <span class="literal">None</span></span><br><span class="line">  best_span_index = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">for</span> (span_index, doc_span) <span class="keyword">in</span> enumerate(doc_spans):</span><br><span class="line">    end = doc_span.start + doc_span.length - <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> position &lt; doc_span.start:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> position &gt; end:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    num_left_context = position - doc_span.start</span><br><span class="line">    num_right_context = end - position</span><br><span class="line">    <span class="comment"># 加平滑项，倾向于选择长 span，context 更丰富</span></span><br><span class="line">    score = min(num_left_context, num_right_context) + <span class="number">0.01</span> * doc_span.length </span><br><span class="line">    <span class="keyword">if</span> best_score <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> score &gt; best_score:</span><br><span class="line">      best_score = score</span><br><span class="line">      best_span_index = span_index</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> cur_span_index == best_span_index</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Estimator</strong></p>
<ul>
<li><p>create_model</p>
<p> 创建序列分类模型</p>
<p>引入 start vector <script type="math/tex">S \in \mathbb{R}^{H}</script>，paragraph 中第 <script type="math/tex">i</script> 个位置是 start_position 的概率为 <script type="math/tex">P_{i}=\frac{e^{S \cdot T_{i}}}{\sum_{j} e^{S \cdot T_{j}}}</script>，end_position 同理。</p>
<p>本函数使用 BERT 最后 hidden 层输出，映射为 start vector 和 end vector 两个向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(bert_config, is_training, input_ids, input_mask, segment_ids,</span></span></span><br><span class="line"><span class="function"><span class="params">                 use_one_hot_embeddings)</span>:</span></span><br><span class="line">  </span><br><span class="line">  model = modeling.BertModel(...)</span><br><span class="line"></span><br><span class="line">  final_hidden = model.get_sequence_output() <span class="comment"># BERT 最后 hidden 层输出</span></span><br><span class="line"></span><br><span class="line">  final_hidden_shape = modeling.get_shape_list(final_hidden, expected_rank=<span class="number">3</span>)</span><br><span class="line">  (batch_size, seq_length, hidden_size) = final_hidden_shape</span><br><span class="line"></span><br><span class="line">  output_weights = tf.get_variable(</span><br><span class="line">      <span class="string">"cls/squad/output_weights"</span>, [<span class="number">2</span>, hidden_size], <span class="comment"># start vector 和 end vector 两个向量</span></span><br><span class="line">      initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.02</span>))</span><br><span class="line">  output_bias = tf.get_variable(</span><br><span class="line">      <span class="string">"cls/squad/output_bias"</span>, [<span class="number">2</span>], initializer=tf.zeros_initializer())</span><br><span class="line"></span><br><span class="line">  final_hidden_matrix = tf.reshape(final_hidden,</span><br><span class="line">                                   [batch_size * seq_length, hidden_size])</span><br><span class="line">  logits = tf.matmul(final_hidden_matrix, output_weights, transpose_b=<span class="literal">True</span>)</span><br><span class="line">  logits = tf.nn.bias_add(logits, output_bias) <span class="comment"># [batch_size * seq_length, 2]</span></span><br><span class="line"></span><br><span class="line">  logits = tf.reshape(logits, [batch_size, seq_length, <span class="number">2</span>]) <span class="comment"># [batch_size, seq_length, 2]</span></span><br><span class="line">  logits = tf.transpose(logits, [<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]) <span class="comment"># # [2, batch_size * seq_length]</span></span><br><span class="line">	</span><br><span class="line">  <span class="comment"># start vector: [batch_size * seq_length]</span></span><br><span class="line">  <span class="comment"># end vector: [batch_size * seq_length]</span></span><br><span class="line">  unstacked_logits = tf.unstack(logits, axis=<span class="number">0</span>)</span><br><span class="line">  (start_logits, end_logits) = (unstacked_logits[<span class="number">0</span>], unstacked_logits[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (start_logits, end_logits)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>model_fn_builder</p>
<p>创建模型函数</p>
<table><img src="/bert-squad-tf/image-20190703085937162.png" width="70%" align="left"></table>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn_builder</span><span class="params">(bert_config, </span></span></span><br><span class="line"><span class="function"><span class="params">                     init_checkpoint, </span></span></span><br><span class="line"><span class="function"><span class="params">                     learning_rate,</span></span></span><br><span class="line"><span class="function"><span class="params">                     num_train_steps, </span></span></span><br><span class="line"><span class="function"><span class="params">                     num_warmup_steps, </span></span></span><br><span class="line"><span class="function"><span class="params">                     use_tpu,</span></span></span><br><span class="line"><span class="function"><span class="params">                     use_one_hot_embeddings)</span>:</span></span><br><span class="line">  <span class="string">"""Returns `model_fn` closure for TPUEstimator."""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 前两个参数是从输入函数中返回的特征和标签batch</span></span><br><span class="line">  <span class="comment"># mode 参数表示调用程序是请求训练、预测还是评估</span></span><br><span class="line">  <span class="comment"># params: 额外参数。调用程序可以将 params 传递给 Estimator 的构造函数。</span></span><br><span class="line">  <span class="comment"># 传递给构造函数的所有 params 转而又传递给 model_fn。</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  def my_model_fn(</span></span><br><span class="line"><span class="string">          features, # This is batch_features from input_fn</span></span><br><span class="line"><span class="string">          labels,   # This is batch_labels from input_fn</span></span><br><span class="line"><span class="string">          mode,     # An instance of tf.estimator.ModeKeys, see below</span></span><br><span class="line"><span class="string">          params):  # Additional configuration</span></span><br><span class="line"><span class="string">  当有人调用 train()、evaluate() 或 predict() 时，Estimator 框架会 调用模型函数 并将 mode 参数设置为如下所示的值：</span></span><br><span class="line"><span class="string">    Estimator方法	Estimator 模式  	返回</span></span><br><span class="line"><span class="string">    train()			 ModeKeys.TRAIN		 EstimatorSpec(mode, loss, train_op)</span></span><br><span class="line"><span class="string">    evaluate()	 ModeKeys.EVAL		 EstimatorSpec(mode, loss, eval_metric_ops)</span></span><br><span class="line"><span class="string">    predict()		 ModeKeys.PREDICT	 EstimatorSpec(mode, predictions)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  对于每个 mode 值，都必须返回 tf.estimator.EstimatorSpec 的一个实例，其中包含调用程序所需的信息。</span></span><br><span class="line"><span class="string">  EstimatorSpec：Ops and objects returned from a model_fn and passed to an Estimator</span></span><br><span class="line"><span class="string">  EstimatorSpec **fully** defines the model to be run by an Estimator.</span></span><br><span class="line"><span class="string">  tf.summary.scalar 会在 TRAIN 和 EVAL 模式下向 TensorBoard 提供准确率</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># 根据运行模式，创建并返回不同的 EstimatorSpec </span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode, params)</span>:</span>   <span class="comment"># params example: &#123;'batch_size': 12, 'use_tpu': False&#125;</span></span><br><span class="line">    <span class="string">"""The `model_fn` for TPUEstimator."""</span></span><br><span class="line">    ...</span><br><span class="line">    unique_ids = features[<span class="string">"unique_ids"</span>] <span class="comment"># Tensor("IteratorGetNext:5", shape=(12,), dtype=int32)</span></span><br><span class="line">    input_ids = features[<span class="string">"input_ids"</span>] <span class="comment"># Tensor("IteratorGetNext:1", shape=(12, 384), dtype=int32)</span></span><br><span class="line">    input_mask = features[<span class="string">"input_mask"</span>] <span class="comment"># Tensor("IteratorGetNext:2", shape=(12, 384), dtype=int32)</span></span><br><span class="line">    segment_ids = features[<span class="string">"segment_ids"</span>] <span class="comment"># Tensor("IteratorGetNext:3", shape=(12, 384), dtype=int32)</span></span><br><span class="line"></span><br><span class="line">    is_training = (mode == tf.estimator.ModeKeys.TRAIN) <span class="comment"># 运行模式</span></span><br><span class="line"></span><br><span class="line">    (start_logits, end_logits) = create_model(...)</span><br><span class="line"></span><br><span class="line">    tvars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">    initialized_variable_names = &#123;&#125;</span><br><span class="line">    <span class="comment"># 通过 tf.Scaffold 自定义 variable initialization</span></span><br><span class="line">    <span class="comment"># 作为 Scaffold 参数传给 EstimatorSpec 的构造函数</span></span><br><span class="line">    scaffold_fn = <span class="literal">None</span> </span><br><span class="line">    <span class="keyword">if</span> init_checkpoint:</span><br><span class="line">      (assignment_map, initialized_variable_names</span><br><span class="line">      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)</span><br><span class="line">      <span class="keyword">if</span> use_tpu:</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">tpu_scaffold</span><span class="params">()</span>:</span></span><br><span class="line">          <span class="comment"># Replaces tf.Variable initializers so they load from a checkpoint file.</span></span><br><span class="line">          tf.train.init_from_checkpoint(init_checkpoint, assignment_map) <span class="comment"># </span></span><br><span class="line">          <span class="keyword">return</span> tf.train.Scaffold()</span><br><span class="line"></span><br><span class="line">        scaffold_fn = tpu_scaffold</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)</span><br><span class="line"></span><br><span class="line">    tf.logging.info(<span class="string">"**** Trainable Variables ****"</span>)</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    output_spec = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> mode == tf.estimator.ModeKeys.TRAIN:</span><br><span class="line">      seq_length = modeling.get_shape_list(input_ids)[<span class="number">1</span>]</span><br><span class="line">			</span><br><span class="line">      <span class="comment"># 使用 cross-entropy / negative-log-likelihood 计算 loss</span></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span><span class="params">(logits, positions)</span>:</span></span><br><span class="line">        one_hot_positions = tf.one_hot(</span><br><span class="line">            positions, depth=seq_length, dtype=tf.float32)</span><br><span class="line">        log_probs = tf.nn.log_softmax(logits, axis=<span class="number">-1</span>)</span><br><span class="line">        loss = -tf.reduce_mean(</span><br><span class="line">            tf.reduce_sum(one_hot_positions * log_probs, axis=<span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">      start_positions = features[<span class="string">"start_positions"</span>]</span><br><span class="line">      end_positions = features[<span class="string">"end_positions"</span>]</span><br><span class="line">			<span class="comment"># 计算 loss</span></span><br><span class="line">      start_loss = compute_loss(start_logits, start_positions)</span><br><span class="line">      end_loss = compute_loss(end_logits, end_positions)</span><br><span class="line">      total_loss = (start_loss + end_loss) / <span class="number">2.0</span></span><br><span class="line">			<span class="comment"># Creates an optimizer training op</span></span><br><span class="line">      train_op = optimization.create_optimizer( </span><br><span class="line">          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)</span><br><span class="line"></span><br><span class="line">      output_spec = tf.contrib.tpu.TPUEstimatorSpec(</span><br><span class="line">          mode=mode,</span><br><span class="line">          loss=total_loss,</span><br><span class="line">          train_op=train_op,</span><br><span class="line">          scaffold_fn=scaffold_fn)</span><br><span class="line">    <span class="keyword">elif</span> mode == tf.estimator.ModeKeys.PREDICT: <span class="comment"># 预测</span></span><br><span class="line">      predictions = &#123;</span><br><span class="line">          <span class="string">"unique_ids"</span>: unique_ids,</span><br><span class="line">          <span class="string">"start_logits"</span>: start_logits,</span><br><span class="line">          <span class="string">"end_logits"</span>: end_logits,</span><br><span class="line">      &#125;</span><br><span class="line">      output_spec = tf.contrib.tpu.TPUEstimatorSpec(</span><br><span class="line">          mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(</span><br><span class="line">          <span class="string">"Only TRAIN and PREDICT modes are supported: %s"</span> % (mode))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output_spec</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model_fn</span><br></pre></td></tr></table></figure>
</li>
<li><p>input_fn_builder</p>
<p>创建输入函数</p>
<p>Tensorflow 的 Dataset API 包含下列类：</p>
<table>
<img src="/bert-squad-tf/image-20190702102852057.png" width="50%" align="left">
</table>

<ul>
<li><code>Dataset</code> - 包含创建和转换数据集的方法的基类。您还可以通过该类从内存中的数据或 Python 生成器初始化数据集。</li>
</ul>
</li>
<li><code>TextLineDataset</code> - 从文本文件中读取行。<ul>
<li><code>TFRecordDataset</code> - 从 TFRecord 文件中读取记录。（我们这里使用）</li>
</ul>
</li>
<li><p><code>FixedLengthRecordDataset</code> - 从二进制文件中读取具有固定大小的记录。</p>
<ul>
<li><code>Iterator</code> - 提供一次访问一个数据集元素的方法</li>
</ul>
<p>创建输入函数流程：</p>
<p>​    定义待map的 features -&gt; 实例化TFRecordDataset对象，从TFRecord 文件中读取记录 -&gt; repeat &amp; shuffle -&gt; 将 record map到 features，构建batch</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn_builder</span><span class="params">(input_file, seq_length, is_training, drop_remainder)</span>:</span></span><br><span class="line">  <span class="string">"""Creates an `input_fn` closure to be passed to TPUEstimator."""</span></span><br><span class="line"></span><br><span class="line">  name_to_features = &#123;</span><br><span class="line">  	<span class="comment"># tf.FixedLenFeature: Configuration for parsing a fixed-length input feature.</span></span><br><span class="line">    	<span class="comment"># 返回一个定长的tensor</span></span><br><span class="line">    <span class="string">"unique_ids"</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">      <span class="string">"input_ids"</span>: tf.FixedLenFeature([seq_length], tf.int64),</span><br><span class="line">    <span class="string">"input_mask"</span>: tf.FixedLenFeature([seq_length], tf.int64),</span><br><span class="line">      <span class="string">"segment_ids"</span>: tf.FixedLenFeature([seq_length], tf.int64),</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> is_training:</span><br><span class="line">    name_to_features[<span class="string">"start_positions"</span>] = tf.FixedLenFeature([], tf.int64)</span><br><span class="line">    name_to_features[<span class="string">"end_positions"</span>] = tf.FixedLenFeature([], tf.int64)</span><br><span class="line">	</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_decode_record</span><span class="params">(record, name_to_features)</span>:</span></span><br><span class="line">    <span class="string">"""Decodes a record to a TensorFlow example."""</span></span><br><span class="line">    <span class="comment"># 返回一个 feature keys 到 `Tensor`的 dict</span></span><br><span class="line">    example = tf.parse_single_example(record, name_to_features)</span><br><span class="line">    ... <span class="comment"># tf.int64 -&gt; tf.int32，实现TPU 兼容</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(params)</span>:</span></span><br><span class="line">    <span class="string">"""The actual input function."""</span></span><br><span class="line">    batch_size = params[<span class="string">"batch_size"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For training, we want a lot of parallel reading and shuffling.</span></span><br><span class="line">    <span class="comment"># For eval, we want no shuffling and parallel reading doesn't matter.</span></span><br><span class="line">    d = tf.data.TFRecordDataset(input_file) <span class="comment"># 从 TFRecord 文件中读取记录</span></span><br><span class="line">    <span class="keyword">if</span> is_training:</span><br><span class="line">      d = d.repeat()</span><br><span class="line">      d = d.shuffle(buffer_size=<span class="number">100</span>)</span><br><span class="line">		</span><br><span class="line">    <span class="comment"># tf.data.Dataset.apply(transformation_func)</span></span><br><span class="line">    <span class="comment"># 将用户自定义的转换函数应用于当前数据集</span></span><br><span class="line">    <span class="comment"># tf.contrib.data.map_and_batch 对数据集的 batch_size 个连续元素，先 map 后 batch</span></span><br><span class="line">    d = d.apply(</span><br><span class="line">        tf.contrib.data.map_and_batch(</span><br><span class="line">            <span class="keyword">lambda</span> record: _decode_record(record, name_to_features),</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            drop_remainder=drop_remainder)) <span class="comment"># 默认 False，最后一个 batch 长度小于 batch_size 不丢弃</span></span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> input_fn</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>write_predictions </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_predictions</span><span class="params">(all_examples, all_features, all_results, n_best_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                      max_answer_length, do_lower_case, output_prediction_file,</span></span></span><br><span class="line"><span class="function"><span class="params">                      output_nbest_file, output_null_log_odds_file)</span>:</span></span><br><span class="line">  <span class="string">"""Write final predictions to the json file and log-odds of null if needed."""</span></span><br><span class="line"></span><br><span class="line">  example_index_to_features = collections.defaultdict(list)</span><br><span class="line">  <span class="keyword">for</span> feature <span class="keyword">in</span> all_features: <span class="comment"># InputFeatures</span></span><br><span class="line">    example_index_to_features[feature.example_index].append(feature)</span><br><span class="line"></span><br><span class="line">  unique_id_to_result = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> result <span class="keyword">in</span> all_results: <span class="comment"># RawResult(unique_id,start_logits,end_logits)</span></span><br><span class="line">    unique_id_to_result[result.unique_id] = result</span><br><span class="line"></span><br><span class="line">  _PrelimPrediction = collections.namedtuple(</span><br><span class="line">      <span class="string">"PrelimPrediction"</span>,</span><br><span class="line">      [<span class="string">"feature_index"</span>, <span class="string">"start_index"</span>, <span class="string">"end_index"</span>, <span class="string">"start_logit"</span>, <span class="string">"end_logit"</span>])</span><br><span class="line"></span><br><span class="line">  all_predictions = collections.OrderedDict()</span><br><span class="line">  all_nbest_json = collections.OrderedDict()</span><br><span class="line">  scores_diff_json = collections.OrderedDict()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (example_index, example) <span class="keyword">in</span> enumerate(all_examples): <span class="comment"># SquadExample</span></span><br><span class="line">    features = example_index_to_features[example_index] <span class="comment"># 当前 SquadExample 对应的 features</span></span><br><span class="line"></span><br><span class="line">    prelim_predictions = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 跟踪 answer 不存在的时候的最小 socre</span></span><br><span class="line">    score_null = <span class="number">1000000</span>  <span class="comment"># large and positive</span></span><br><span class="line">    min_null_feature_index = <span class="number">0</span>  <span class="comment"># the paragraph slice with min mull score</span></span><br><span class="line">    null_start_logit = <span class="number">0</span>  <span class="comment"># the start logit at the slice with min null score</span></span><br><span class="line">    null_end_logit = <span class="number">0</span>  <span class="comment"># the end logit at the slice with min null score</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (feature_index, feature) <span class="keyword">in</span> enumerate(features): <span class="comment"># 一个 SquadExample 可以解析出一个或多个 features</span></span><br><span class="line">      result = unique_id_to_result[feature.unique_id]</span><br><span class="line">      start_indexes = _get_best_indexes(result.start_logits, n_best_size)</span><br><span class="line">      end_indexes = _get_best_indexes(result.end_logits, n_best_size)</span><br><span class="line">      <span class="comment"># if we could have irrelevant answers, get the min score of irrelevant</span></span><br><span class="line">      <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">        <span class="comment"># 对于 v2，answer 不存在时，start_position = end_position = 0</span></span><br><span class="line">        feature_null_score = result.start_logits[<span class="number">0</span>] + result.end_logits[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> feature_null_score &lt; score_null:</span><br><span class="line">          score_null = feature_null_score</span><br><span class="line">          min_null_feature_index = feature_index</span><br><span class="line">          null_start_logit = result.start_logits[<span class="number">0</span>]</span><br><span class="line">          null_end_logit = result.end_logits[<span class="number">0</span>]</span><br><span class="line">      <span class="keyword">for</span> start_index <span class="keyword">in</span> start_indexes:</span><br><span class="line">        <span class="keyword">for</span> end_index <span class="keyword">in</span> end_indexes:</span><br><span class="line">          <span class="comment"># 丢弃无效的 index 的情况：</span></span><br><span class="line">          <span class="comment"># 预测到了 pad 位置、预测到了 非context 的位置</span></span><br><span class="line">          <span class="keyword">if</span> start_index &gt;= len(feature.tokens):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> end_index &gt;= len(feature.tokens):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> start_index <span class="keyword">not</span> <span class="keyword">in</span> feature.token_to_orig_map:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> end_index <span class="keyword">not</span> <span class="keyword">in</span> feature.token_to_orig_map:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="comment"># 当前span不是 start_index 的最大上下文 （？为什么不处理end_index）</span></span><br><span class="line">          <span class="keyword">if</span> <span class="keyword">not</span> feature.token_is_max_context.get(start_index, <span class="literal">False</span>): </span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          <span class="keyword">if</span> end_index &lt; start_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          length = end_index - start_index + <span class="number">1</span></span><br><span class="line">          <span class="keyword">if</span> length &gt; max_answer_length:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">          prelim_predictions.append( <span class="comment"># 暂存可能的 [start, end] 组合</span></span><br><span class="line">              _PrelimPrediction(...))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">      prelim_predictions.append(</span><br><span class="line">          _PrelimPrediction(</span><br><span class="line">              feature_index=min_null_feature_index,</span><br><span class="line">              start_index=<span class="number">0</span>,</span><br><span class="line">              end_index=<span class="number">0</span>,</span><br><span class="line">              start_logit=null_start_logit,</span><br><span class="line">              end_logit=null_end_logit))</span><br><span class="line">    <span class="comment"># 对所有可能的 [start, end] 组合排序</span></span><br><span class="line">    <span class="comment"># logit 的大小会用于 softmax 计算概率</span></span><br><span class="line">    <span class="comment"># e^start_logit * e^end_logit = e^(start_logit+end_logit) </span></span><br><span class="line">    prelim_predictions = sorted( </span><br><span class="line">        prelim_predictions,</span><br><span class="line">        key=<span class="keyword">lambda</span> x: (x.start_logit + x.end_logit),</span><br><span class="line">        reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    _NbestPrediction = collections.namedtuple(  <span class="comment"># pylint: disable=invalid-name</span></span><br><span class="line">        <span class="string">"NbestPrediction"</span>, [<span class="string">"text"</span>, <span class="string">"start_logit"</span>, <span class="string">"end_logit"</span>])</span><br><span class="line"></span><br><span class="line">    seen_predictions = &#123;&#125;</span><br><span class="line">    nbest = []</span><br><span class="line">    <span class="comment"># 选出前 n_best_size 得分的 [start, end] 组合</span></span><br><span class="line">    <span class="keyword">for</span> pred <span class="keyword">in</span> prelim_predictions:</span><br><span class="line">      <span class="keyword">if</span> len(nbest) &gt;= n_best_size:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      feature = features[pred.feature_index]</span><br><span class="line">      <span class="comment"># 对于 non-null 的 answer，从 tokens 恢复出 text</span></span><br><span class="line">      <span class="keyword">if</span> pred.start_index &gt; <span class="number">0</span>:  <span class="comment"># this is a non-null prediction</span></span><br><span class="line">        tok_tokens = feature.tokens[pred.start_index:(pred.end_index + <span class="number">1</span>)]</span><br><span class="line">        orig_doc_start = feature.token_to_orig_map[pred.start_index]</span><br><span class="line">        orig_doc_end = feature.token_to_orig_map[pred.end_index]</span><br><span class="line">        orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + <span class="number">1</span>)]</span><br><span class="line">        tok_text = <span class="string">" "</span>.join(tok_tokens)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># De-tokenize WordPieces 得到的是 BasicTokenizer 分词后的格式</span></span><br><span class="line">        tok_text = tok_text.replace(<span class="string">" ##"</span>, <span class="string">""</span>)</span><br><span class="line">        tok_text = tok_text.replace(<span class="string">"##"</span>, <span class="string">""</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Clean whitespace</span></span><br><span class="line">        tok_text = tok_text.strip()</span><br><span class="line">        tok_text = <span class="string">" "</span>.join(tok_text.split()) <span class="comment"># wordpiece tokens 恢复出的 answer</span></span><br><span class="line">        orig_text = <span class="string">" "</span>.join(orig_tokens) <span class="comment"># 原文的 answer，如：'(NFL) for the 2015 season. The American'</span></span><br><span class="line"></span><br><span class="line">        final_text = get_final_text(tok_text, orig_text, do_lower_case)</span><br><span class="line">        <span class="keyword">if</span> final_text <span class="keyword">in</span> seen_predictions:</span><br><span class="line">          <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        seen_predictions[final_text] = <span class="literal">True</span></span><br><span class="line">      <span class="comment"># 对于 null， answer =""</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        final_text = <span class="string">""</span></span><br><span class="line">        seen_predictions[final_text] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">      nbest.append(</span><br><span class="line">          _NbestPrediction(</span><br><span class="line">              text=final_text,</span><br><span class="line">              start_logit=pred.start_logit,</span><br><span class="line">              end_logit=pred.end_logit))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># if we didn't inlude the empty option in the n-best, inlcude it</span></span><br><span class="line">    <span class="keyword">if</span> FLAGS.version_2_with_negative:</span><br><span class="line">      <span class="keyword">if</span> <span class="string">""</span> <span class="keyword">not</span> <span class="keyword">in</span> seen_predictions:</span><br><span class="line">        nbest.append(</span><br><span class="line">            _NbestPrediction(</span><br><span class="line">                text=<span class="string">""</span>, start_logit=null_start_logit,</span><br><span class="line">                end_logit=null_end_logit))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># In very rare edge cases we could have no valid predictions. So we</span></span><br><span class="line">    <span class="comment"># just create a nonce prediction in this case to avoid failure.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> nbest:</span><br><span class="line">      nbest.append(</span><br><span class="line">          _NbestPrediction(text=<span class="string">"empty"</span>, start_logit=<span class="number">0.0</span>, end_logit=<span class="number">0.0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> len(nbest) &gt;= <span class="number">1</span></span><br><span class="line">		</span><br><span class="line">    <span class="comment"># 计算每个 [start, end] 组合的概率</span></span><br><span class="line">    total_scores = []</span><br><span class="line">    best_non_null_entry = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> entry <span class="keyword">in</span> nbest:</span><br><span class="line">      total_scores.append(entry.start_logit + entry.end_logit)</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> best_non_null_entry:</span><br><span class="line">        <span class="keyword">if</span> entry.text:</span><br><span class="line">          best_non_null_entry = entry</span><br><span class="line"></span><br><span class="line">    probs = _compute_softmax(total_scores)</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">		</span><br><span class="line">    <span class="comment"># 对于 v1，始终存在 answer，直接将得分最高的作为输出</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> FLAGS.version_2_with_negative:</span><br><span class="line">      all_predictions[example.qas_id] = nbest_json[<span class="number">0</span>][<span class="string">"text"</span>]</span><br><span class="line">    <span class="comment"># 对于 v2，可能存在找不到 answer，根据以下公式是否成立来确定输出</span></span><br><span class="line">    <span class="comment"># null score - the score of best non-null &gt; threshold</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      score_diff = score_null - best_non_null_entry.start_logit - (</span><br><span class="line">          best_non_null_entry.end_logit)</span><br><span class="line">      scores_diff_json[example.qas_id] = score_diff</span><br><span class="line">      <span class="keyword">if</span> score_diff &gt; FLAGS.null_score_diff_threshold:</span><br><span class="line">        all_predictions[example.qas_id] = <span class="string">""</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        all_predictions[example.qas_id] = best_non_null_entry.text</span><br><span class="line"></span><br><span class="line">    all_nbest_json[example.qas_id] = nbest_json</span><br><span class="line"></span><br><span class="line">  ... 写入文件</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_final_text</p>
<p>我们可以同时得到两种 answer 表示，一种是原文中的 tokens 直接恢复出来的 orig_text，另一种是 wordPiece 的 subtokens 可以恢复出的更精确的 pred_text。 如果 pred_text 能在 orig_text 中定位/对齐到，那么输出更精确的 pred_text。如果因为分词过程带来的差异，导致pred_text 在原文中恢复不出来，那么直接输出 pred_text。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_final_text</span><span class="params">(pred_text, orig_text, do_lower_case)</span>:</span></span><br><span class="line">  <span class="string">"""Project the tokenized prediction back to the original text."""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># When we created the data, we kept track of the alignment between original</span></span><br><span class="line">  <span class="comment"># (whitespace tokenized) tokens and our WordPiece tokenized tokens. So</span></span><br><span class="line">  <span class="comment"># now `orig_text` contains the span of our original text corresponding to the</span></span><br><span class="line">  <span class="comment"># span that we predicted.</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># However, `orig_text` may contain extra characters that we don't want in</span></span><br><span class="line">  <span class="comment"># our prediction.</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># For example, let's say:</span></span><br><span class="line">  <span class="comment">#   pred_text = steve smith</span></span><br><span class="line">  <span class="comment">#   orig_text = Steve Smith's</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># We don't want to return `orig_text` because it contains the extra "'s".</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># We don't want to return `pred_text` because it's already been normalized</span></span><br><span class="line">  <span class="comment"># (the SQuAD eval script also does punctuation stripping/lower casing but</span></span><br><span class="line">  <span class="comment"># our tokenizer does additional normalization like stripping accent</span></span><br><span class="line">  <span class="comment"># characters).</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># What we really want to return is "Steve Smith".</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># Therefore, we have to apply a semi-complicated alignment heruistic between</span></span><br><span class="line">  <span class="comment"># `pred_text` and `orig_text` to get a character-to-charcter alignment. This</span></span><br><span class="line">  <span class="comment"># can fail in certain cases in which case we just return `orig_text`.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 将字符串 s 中的空格去掉得到 ns，并且建立 ns 索引到 s 索引的映射</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_strip_spaces</span><span class="params">(text)</span>:</span></span><br><span class="line">    ns_chars = []</span><br><span class="line">    ns_to_s_map = collections.OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> (i, c) <span class="keyword">in</span> enumerate(text):</span><br><span class="line">      <span class="keyword">if</span> c == <span class="string">" "</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      ns_to_s_map[len(ns_chars)] = i</span><br><span class="line">      ns_chars.append(c)</span><br><span class="line">    ns_text = <span class="string">""</span>.join(ns_chars)</span><br><span class="line">    <span class="keyword">return</span> (ns_text, ns_to_s_map)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># We first tokenize `orig_text`, strip whitespace from the result</span></span><br><span class="line">  <span class="comment"># and `pred_text`, and check if they are the same length. If they are</span></span><br><span class="line">  <span class="comment"># NOT the same length, the heuristic has failed. If they are the same</span></span><br><span class="line">  <span class="comment"># length, we assume the characters are one-to-one aligned.</span></span><br><span class="line">  tokenizer = tokenization.BasicTokenizer(do_lower_case=do_lower_case)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 举例：orig_text = '(NFL) for the 2015 season. The American'</span></span><br><span class="line">  <span class="comment">#       tok_text = '( nfl ) for the 2015 season . the american'</span></span><br><span class="line">  <span class="comment">#      pred_text = ') for the 2015 season . the american'</span></span><br><span class="line">  tok_text = <span class="string">" "</span>.join(tokenizer.tokenize(orig_text))</span><br><span class="line"></span><br><span class="line">  start_position = tok_text.find(pred_text)</span><br><span class="line">  <span class="comment"># pred_text 不在 BasicTokenizer 处理后的 orig_text 中</span></span><br><span class="line">  <span class="comment"># pred_text 中有 '[UNK]'这样的情况需要返回 orig_text</span></span><br><span class="line">  <span class="comment"># 举例：orig_text = '(/tᵻˈnɒfərə/; singular ctenophore,'</span></span><br><span class="line">  <span class="comment">#       tok_text = '( / tᵻˈnɒfərə / ; singular ctenophore ,'</span></span><br><span class="line">  <span class="comment">#      pred_text = '[UNK] / ; singular cteno'</span></span><br><span class="line">  <span class="keyword">if</span> start_position == <span class="number">-1</span>:</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(</span><br><span class="line">          <span class="string">"Unable to find text: '%s' in '%s'"</span> % (pred_text, orig_text))</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line">  </span><br><span class="line">  end_position = start_position + len(pred_text) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text) <span class="comment"># 例 '(NFL)forthe2015season.TheAmerican'</span></span><br><span class="line">  (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text) <span class="comment"># 例 '(nfl)forthe2015season.theamerican'</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># BasicTokenizer 会去掉一些音节之类的符号，导致 orig_ns_text 和 tok_ns_text 不对齐</span></span><br><span class="line">  <span class="comment"># 举例： </span></span><br><span class="line">  <span class="comment"># orig_ns_text = 'dust".)ItofferedaclassiccurriculumontheEnglishuniversitymodel—​​manyleadersinthecolonyhadattendedtheUniversityofCambridge—​​butconformedPuritanism.'</span></span><br><span class="line">  <span class="comment"># tok_ns_text = 'dust".)itofferedaclassiccurriculumontheenglishuniversitymodel—manyleadersinthecolonyhadattendedtheuniversityofcambridge—butconformedpuritanism.'</span></span><br><span class="line">  <span class="keyword">if</span> len(orig_ns_text) != len(tok_ns_text):</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(<span class="string">"Length not equal after stripping spaces: '%s' vs '%s'"</span>,</span><br><span class="line">                      orig_ns_text, tok_ns_text)</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 将 pred_text 定位/对齐到 orig_text 中</span></span><br><span class="line">  <span class="comment"># We then project the characters in `pred_text` back to `orig_text` using</span></span><br><span class="line">  <span class="comment"># the character-to-character alignment.</span></span><br><span class="line">  tok_s_to_ns_map = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> (i, tok_index) <span class="keyword">in</span> six.iteritems(tok_ns_to_s_map):</span><br><span class="line">    tok_s_to_ns_map[tok_index] = i</span><br><span class="line"></span><br><span class="line">  orig_start_position = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">if</span> start_position <span class="keyword">in</span> tok_s_to_ns_map:</span><br><span class="line">    ns_start_position = tok_s_to_ns_map[start_position]</span><br><span class="line">    <span class="keyword">if</span> ns_start_position <span class="keyword">in</span> orig_ns_to_s_map:</span><br><span class="line">      orig_start_position = orig_ns_to_s_map[ns_start_position]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> orig_start_position <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(<span class="string">"Couldn't map start position"</span>)</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line"></span><br><span class="line">  orig_end_position = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">if</span> end_position <span class="keyword">in</span> tok_s_to_ns_map:</span><br><span class="line">    ns_end_position = tok_s_to_ns_map[end_position]</span><br><span class="line">    <span class="keyword">if</span> ns_end_position <span class="keyword">in</span> orig_ns_to_s_map:</span><br><span class="line">      orig_end_position = orig_ns_to_s_map[ns_end_position]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> orig_end_position <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> FLAGS.verbose_logging:</span><br><span class="line">      tf.logging.info(<span class="string">"Couldn't map end position"</span>)</span><br><span class="line">    <span class="keyword">return</span> orig_text</span><br><span class="line"></span><br><span class="line">  output_text = orig_text[orig_start_position:(orig_end_position + <span class="number">1</span>)]</span><br><span class="line">  <span class="keyword">return</span> output_text</span><br></pre></td></tr></table></figure>
</li>
<li><p>_get_best_indexes</p>
<p>将一个 logits 按照逆序排序，取出前 n 个值的索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_best_indexes</span><span class="params">(logits, n_best_size)</span>:</span></span><br><span class="line">  <span class="string">"""Get the n-best logits from a list."""</span></span><br><span class="line">  index_and_score = sorted(enumerate(logits), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  best_indexes = []</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(len(index_and_score)):</span><br><span class="line">    <span class="keyword">if</span> i &gt;= n_best_size:</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">    best_indexes.append(index_and_score[i][<span class="number">0</span>])</span><br><span class="line">  <span class="keyword">return</span> best_indexes</span><br></pre></td></tr></table></figure>
</li>
<li><p>main</p>
<p>主程序😄 终于到终点啦，不过这也是运行的起点～</p>
<p>流程：加载并检查模型配置 -&gt; 创建Tokenizer -&gt; 配置TPU</p>
<ul>
<li><strong>train</strong>:        -&gt; 读取训练输入文件并shuffle -&gt; 创建模型函数 -&gt; 创建 estimator -&gt; 处理输入并创建输入函数 -&gt;  estimator.train</li>
<li><strong>predict</strong>:    -&gt; 读取预测输入文件 -&gt; 创建模型函数 -&gt; 创建 estimator -&gt; 处理输入并创建输入函数 -&gt;  estimator.predict -&gt; output<ul>
<li>（为了方便对比，稍微调整了下 predict 的过程）</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(_)</span>:</span></span><br><span class="line">  tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line"></span><br><span class="line">  bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)</span><br><span class="line">  validate_flags_or_throw(bert_config)</span><br><span class="line"></span><br><span class="line">  tf.gfile.MakeDirs(FLAGS.output_dir)</span><br><span class="line"></span><br><span class="line">  tokenizer = tokenization.FullTokenizer(</span><br><span class="line">      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)</span><br><span class="line"></span><br><span class="line">  ... tpu 相关 ...</span><br><span class="line">  run_config = tf.contrib.tpu.RunConfig(...) <span class="comment"># 必须将 tf.contrib.tpu.RunConfig 传递给构造函数</span></span><br><span class="line"></span><br><span class="line">  train_examples = <span class="literal">None</span></span><br><span class="line">  num_train_steps = <span class="literal">None</span></span><br><span class="line">  num_warmup_steps = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_train:</span><br><span class="line">    train_examples = read_squad_examples(</span><br><span class="line">        input_file=FLAGS.train_file, is_training=<span class="literal">True</span>)</span><br><span class="line">    num_train_steps = int(len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)</span><br><span class="line">    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion) <span class="comment"># 和学习率有关</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pre-shuffle the input to avoid having to make a very large shuffle</span></span><br><span class="line">    <span class="comment"># buffer in in the `input_fn`.</span></span><br><span class="line">    rng = random.Random(<span class="number">12345</span>)</span><br><span class="line">    rng.shuffle(train_examples)</span><br><span class="line"></span><br><span class="line">  model_fn = model_fn_builder(</span><br><span class="line">      bert_config=bert_config,</span><br><span class="line">      init_checkpoint=FLAGS.init_checkpoint,</span><br><span class="line">      learning_rate=FLAGS.learning_rate,</span><br><span class="line">      num_train_steps=num_train_steps,</span><br><span class="line">      num_warmup_steps=num_warmup_steps,</span><br><span class="line">      use_tpu=FLAGS.use_tpu,</span><br><span class="line">      use_one_hot_embeddings=FLAGS.use_tpu)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># If TPU is not available, this will fall back to normal Estimator on CPU or GPU.</span></span><br><span class="line">  <span class="comment"># TPUEstimator 类与 Estimator 类有所不同。</span></span><br><span class="line">	<span class="comment"># 要维护可在 CPU/GPU 或 Cloud TPU 上运行的模型，最简单的方式是将模型的推理阶段（从输入到预测）定义在 model_fn 之外。</span></span><br><span class="line">	<span class="comment"># 然后，确保 Estimator 设置和 model_fn 的单独实现，二者均包含此推理步骤。</span></span><br><span class="line">  <span class="comment"># 在本地计算机上使用 tf.contrib.tpu.TPUEstimator 所需的更改相对较少。将构造函数中的 use_tpu 参数设为 False，并将 			</span></span><br><span class="line">  <span class="comment"># tf.contrib.tpu.RunConfig 以 config 参数的形式传递。</span></span><br><span class="line">  estimator = tf.contrib.tpu.TPUEstimator(</span><br><span class="line">      use_tpu=FLAGS.use_tpu,</span><br><span class="line">      model_fn=model_fn,</span><br><span class="line">      config=run_config,</span><br><span class="line">      train_batch_size=FLAGS.train_batch_size,</span><br><span class="line">      predict_batch_size=FLAGS.predict_batch_size)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_train:</span><br><span class="line">    <span class="comment"># We write to a temporary file to avoid storing very large constant tensors</span></span><br><span class="line">    <span class="comment"># in memory.</span></span><br><span class="line">    train_writer = FeatureWriter(</span><br><span class="line">        filename=os.path.join(FLAGS.output_dir, <span class="string">"train.tf_record"</span>),</span><br><span class="line">        is_training=<span class="literal">True</span>)</span><br><span class="line">    convert_examples_to_features(</span><br><span class="line">        examples=train_examples,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        max_seq_length=FLAGS.max_seq_length,</span><br><span class="line">        doc_stride=FLAGS.doc_stride,</span><br><span class="line">        max_query_length=FLAGS.max_query_length,</span><br><span class="line">        is_training=<span class="literal">True</span>,</span><br><span class="line">        output_fn=train_writer.process_feature)</span><br><span class="line">    train_writer.close()</span><br><span class="line">    </span><br><span class="line">		tf.logging.info(<span class="string">"***** Running training *****"</span>)</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">del</span> train_examples</span><br><span class="line"></span><br><span class="line">    train_input_fn = input_fn_builder(</span><br><span class="line">        input_file=train_writer.filename,</span><br><span class="line">        seq_length=FLAGS.max_seq_length,</span><br><span class="line">        is_training=<span class="literal">True</span>,</span><br><span class="line">        drop_remainder=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 每当有人调用 Estimator 的 train、evaluate 或 predict 方法时，就会调用模型函数。</span></span><br><span class="line">    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> FLAGS.do_predict:</span><br><span class="line">    eval_examples = read_squad_examples(</span><br><span class="line">        input_file=FLAGS.predict_file, is_training=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    eval_writer = FeatureWriter(</span><br><span class="line">        filename=os.path.join(FLAGS.output_dir, <span class="string">"eval.tf_record"</span>),</span><br><span class="line">        is_training=<span class="literal">False</span>)</span><br><span class="line">    eval_features = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">append_feature</span><span class="params">(feature)</span>:</span></span><br><span class="line">      eval_features.append(feature) <span class="comment">#</span></span><br><span class="line">      eval_writer.process_feature(feature)</span><br><span class="line"></span><br><span class="line">    convert_examples_to_features(..., output_fn=append_feature)</span><br><span class="line">    eval_writer.close()</span><br><span class="line">    </span><br><span class="line">		tf.logging.info(<span class="string">"***** Running predictions *****"</span>)</span><br><span class="line">    ...</span><br><span class="line">    all_results = []</span><br><span class="line"></span><br><span class="line">    predict_input_fn = input_fn_builder(...)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If running eval on the TPU, you will need to specify the number of</span></span><br><span class="line">    <span class="comment"># steps.</span></span><br><span class="line">    all_results = []</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> estimator.predict(</span><br><span class="line">        predict_input_fn, yield_single_examples=<span class="literal">True</span>):</span><br><span class="line">      <span class="keyword">if</span> len(all_results) % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        tf.logging.info(<span class="string">"Processing example: %d"</span> % (len(all_results)))</span><br><span class="line">      unique_id = int(result[<span class="string">"unique_ids"</span>])</span><br><span class="line">      start_logits = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> result[<span class="string">"start_logits"</span>].flat]</span><br><span class="line">      end_logits = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> result[<span class="string">"end_logits"</span>].flat]</span><br><span class="line">      all_results.append(</span><br><span class="line">          RawResult(</span><br><span class="line">              unique_id=unique_id,</span><br><span class="line">              start_logits=start_logits,</span><br><span class="line">              end_logits=end_logits))</span><br><span class="line"></span><br><span class="line">    output_prediction_file = os.path.join(FLAGS.output_dir, <span class="string">"predictions.json"</span>)</span><br><span class="line">    output_nbest_file = os.path.join(FLAGS.output_dir, <span class="string">"nbest_predictions.json"</span>)</span><br><span class="line">    output_null_log_odds_file = os.path.join(FLAGS.output_dir, <span class="string">"null_odds.json"</span>)</span><br><span class="line"></span><br><span class="line">    write_predictions(eval_examples, eval_features, all_results,</span><br><span class="line">                      FLAGS.n_best_size, FLAGS.max_answer_length,</span><br><span class="line">                      FLAGS.do_lower_case, output_prediction_file,</span><br><span class="line">                      output_nbest_file, output_null_log_odds_file)</span><br></pre></td></tr></table></figure>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hexo/" rel="tag"># Hexo</a>
          
            <a href="/tags/Typora/" rel="tag"># Typora</a>
          
        </div>
      

      
      
      

      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-6"><a class="nav-link" href="#tokenization-py"><span class="nav-number">1.</span> <span class="nav-text">tokenization.py</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#modeling-py"><span class="nav-number">2.</span> <span class="nav-text">modeling.py</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#optimization-py"><span class="nav-number">3.</span> <span class="nav-text">optimization.py</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#run-squad-py"><span class="nav-number">4.</span> <span class="nav-text">run_squad.py</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
